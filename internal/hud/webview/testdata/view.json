{
  "Log": "confluent-c…┊ \tsasl.login.callback.handler.class = null\nconfluent-c…┊ \tsasl.login.class = null\nconfluent-c…┊ \tsasl.login.refresh.buffer.seconds = 300\nconfluent-c…┊ \tsasl.login.refresh.min.period.seconds = 60\nconfluent-c…┊ \tsasl.login.refresh.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.refresh.window.jitter = 0.05\nconfluent-c…┊ \tsasl.mechanism = GSSAPI\nconfluent-c…┊ \tsecurity.protocol = PLAINTEXT\nconfluent-c…┊ \tsend.buffer.bytes = 131072\nconfluent-c…┊ \tssl.cipher.suites = null\nconfluent-c…┊ \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = https\nconfluent-c…┊ \tssl.key.password = null\nconfluent-c…┊ \tssl.keymanager.algorithm = SunX509\nconfluent-c…┊ \tssl.keystore.location = null\nconfluent-c…┊ \tssl.keystore.password = null\nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tssl.provider = null\nconfluent-c…┊ \tssl.secure.random.implementation = null\nconfluent-c…┊ \tssl.trustmanager.algorithm = PKIX\nconfluent-c…┊ \tssl.truststore.location = null\nconfluent-c…┊ \tssl.truststore.password = null\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊ \ttransaction.timeout.ms = 60000\nconfluent-c…┊ \ttransactional.id = null\nconfluent-c…┊ \tvalue.serializer = class io.confluent.serializers.ProtoSerde\nconfluent-c…┊  (org.apache.kafka.clients.producer.ProducerConfig)\nconfluent-c…┊ [2019-10-18 14:36:23,981] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:36:23,981] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/db_impl/db_impl_readonly.o\nconfluent-c…┊ [2019-10-18 14:36:24,634] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\nconfluent-c…┊ [2019-10-18 14:36:25,064] INFO RestConfig values: \nconfluent-c…┊ \tmetric.reporters = []\nconfluent-c…┊ \tssl.client.auth = false\nconfluent-c…┊ \trest.servlet.initializor.classes = []\nconfluent-c…┊ \tresponse.mediatype.default = application/json\nconfluent-c…┊ \twebsocket.path.prefix = /ws\nconfluent-c…┊ \tresource.extension.classes = []\nconfluent-c…┊ \tauthentication.realm = \nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.trustmanager.algorithm = \nconfluent-c…┊ \tauthentication.method = NONE\nconfluent-c…┊ \tmetrics.jmx.prefix = rest-utils\nconfluent-c…┊ \trequest.logger.name = io.confluent.rest-utils.requests\nconfluent-c…┊ \tssl.key.password = [hidden]\nconfluent-c…┊ \tssl.truststore.password = [hidden]\nconfluent-c…┊ \tauthentication.roles = [*]\nconfluent-c…┊ \tmetrics.num.samples = 2\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = \nconfluent-c…┊ \tcompression.enable = true\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tdebug = false\nconfluent-c…┊ \tlisteners = []\nconfluent-c…┊ \tssl.provider = \nconfluent-c…┊ \tssl.enabled.protocols = []\nconfluent-c…┊ \tshutdown.graceful.ms = 1000\nconfluent-c…┊ \tssl.keystore.location = \nconfluent-c…┊ \tresponse.mediatype.preferred = [application/json]\nconfluent-c…┊ \tssl.cipher.suites = []\nconfluent-c…┊ \tauthentication.skip.paths = []\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊ \twebsocket.servlet.initializor.classes = []\nconfluent-c…┊ \taccess.control.allow.methods = \nconfluent-c…┊ \taccess.control.allow.origin = \nconfluent-c…┊ \tssl.truststore.location = \nconfluent-c…┊ \tssl.keystore.password = [hidden]\nconfluent-c…┊ \tssl.keymanager.algorithm = \nconfluent-c…┊ \tport = 9021\nconfluent-c…┊ \taccess.control.allow.headers = \nconfluent-c…┊ \tmetrics.sample.window.ms = 30000\nconfluent-c…┊ \tmetrics.tag.map = {}\nconfluent-c…┊  (io.confluent.rest.RestConfig)\nconfluent-c…┊ [2019-10-18 14:36:27,147] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:27,437] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:27,448] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:27,477] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:27,909] INFO intermediateTopics=[_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:28,421] INFO CONTROL CENTER UI\nconfluent-c…┊ \nconfluent-c…┊ By using Control Center, subject to any license you may have with Confluent, you agree to the Confluent Data Protection Agreement.  In particular, please note that the version check feature of Control Center is enabled.\nconfluent-c…┊ \nconfluent-c…┊ With this enabled, this instance is configured to collect and report certain data (version information, time stamped session IDs, instance ID, instance uptime, license key for subscription customers, IP address, and other product data)  to Confluent, Inc. (\"Confluent\") or its parent, subsidiaries, affiliates or service providers every hour.  By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer and use of Version information by Confluent. You can turn the version check feature off by setting `confluent.support.metrics.enable=false` in the Control Center configuration and restarting Control Center.  See the Confluent Enterprise documentation for further information.\nconfluent-c…┊  (io.confluent.controlcenter.healthcheck.HealthCheck)\nconfluent-c…┊ [2019-10-18 14:36:28,703] INFO Starting Control Center version=5.2.0 (io.confluent.controlcenter.ControlCenter)\nconfluent-c…┊ [2019-10-18 14:36:28,801] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:28,825] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:28,856] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:28,875] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:29,007] INFO intermediateTopics=[_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)\nconfluent-c…┊ [2019-10-18 14:36:29,031] INFO AdminClientConfig values: \nconfluent-c…┊ \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\nconfluent-c…┊ \tclient.dns.lookup = default\nconfluent-c…┊ \tclient.id = \nconfluent-c…┊ \tconnections.max.idle.ms = 300000\nconfluent-c…┊ \tmetadata.max.age.ms = 300000\nconfluent-c…┊ \tmetric.reporters = []\nconfluent-c…┊ \tmetrics.num.samples = 2\nconfluent-c…┊ \tmetrics.recording.level = INFO\nconfluent-c…┊ \tmetrics.sample.window.ms = 30000\nconfluent-c…┊ \treceive.buffer.bytes = 65536\nconfluent-c…┊ \treconnect.backoff.max.ms = 1000\nconfluent-c…┊ \treconnect.backoff.ms = 50\nconfluent-c…┊ \trequest.timeout.ms = 120000\nconfluent-c…┊ \tretries = 2147483647\nconfluent-c…┊ \tretry.backoff.ms = 100\nconfluent-c…┊ \tsasl.client.callback.handler.class = null\nconfluent-c…┊ \tsasl.jaas.config = null\nconfluent-c…┊ \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\nconfluent-c…┊ \tsasl.kerberos.min.time.before.relogin = 60000\nconfluent-c…┊ \tsasl.kerberos.service.name = null\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.jitter = 0.05\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.callback.handler.class = null\nconfluent-c…┊ \tsasl.login.class = null\nconfluent-c…┊ \tsasl.login.refresh.buffer.seconds = 300\nconfluent-c…┊ \tsasl.login.refresh.min.period.seconds = 60\nconfluent-c…┊ \tsasl.login.refresh.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.refresh.window.jitter = 0.05\nconfluent-c…┊ \tsasl.mechanism = GSSAPI\nconfluent-c…┊ \tsecurity.protocol = PLAINTEXT\nconfluent-c…┊ \tsend.buffer.bytes = 131072\nconfluent-c…┊ \tssl.cipher.suites = null\nconfluent-c…┊ \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = https\nconfluent-c…┊ \tssl.key.password = null\nconfluent-c…┊ \tssl.keymanager.algorithm = SunX509\nconfluent-c…┊ \tssl.keystore.location = null\nconfluent-c…┊ \tssl.keystore.password = null\nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tssl.provider = null\nconfluent-c…┊ \tssl.secure.random.implementation = null\nconfluent-c…┊ \tssl.trustmanager.algorithm = PKIX\nconfluent-c…┊ \tssl.truststore.location = null\nconfluent-c…┊ \tssl.truststore.password = null\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊  (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,336] WARN The configuration 'consumer.session.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,359] WARN The configuration 'producer.linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,397] WARN The configuration 'producer.delivery.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,411] WARN The configuration 'producer.max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,433] WARN The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,459] WARN The configuration 'producer.retries' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,482] WARN The configuration 'producer.compression.type' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,483] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,499] WARN The configuration 'num.stream.threads' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:36:29,499] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:36:29,499] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:36:30,386] INFO topicListings=[] (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:36:30,415] INFO missingTopics=[_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-metrics, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-command, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-monitoring, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:36:30,507] INFO extantTopics=[] (io.confluent.controlcenter.KafkaHelper)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/db_impl/db_impl_secondary.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:34,774] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-storage-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:34,789] INFO Loading plugin from: /usr/share/java/kafka-connect-jms (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:36,358] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jms/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:36,387] INFO Added plugin 'io.confluent.connect.jms.JmsSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:36,403] INFO Loading plugin from: /usr/share/java/kafka-connect-activemq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,805] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-activemq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,832] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,834] INFO Added plugin 'io.confluent.connect.activemq.ActiveMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,841] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,851] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,854] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,861] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,866] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,868] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,894] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,921] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,924] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,925] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,925] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,926] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,926] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,934] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,937] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:48,937] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,095] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,100] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,105] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,106] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,109] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,109] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Loading plugin from: /usr/share/java/kafka-connect-elasticsearch (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/db_impl/db_impl_write.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:51,281] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-elasticsearch/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:51,281] INFO Added plugin 'io.confluent.connect.elasticsearch.ElasticsearchSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:51,282] INFO Loading plugin from: /usr/share/java/kafka-connect-ibmmq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [2019-10-18 14:36:54,863] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ java.util.concurrent.TimeoutException\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\nconfluent-c…┊ \tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:57,689] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-ibmmq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:57,689] INFO Added plugin 'io.confluent.connect.ibm.mq.IbmMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:57,723] INFO Loading plugin from: /usr/share/java/kafka-connect-jdbc (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/db_info_dumper.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:59,284] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jdbc/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:59,291] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:59,292] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:36:59,401] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/db_iter.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:37:02,110] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:37:02,193] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/dbformat.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/error_handler.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:37:16,462] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:37:16,472] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/event_helpers.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/experimental.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/external_sst_file_ingestion_job.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/file_indexer.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/flush_job.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/flush_scheduler.o\nconfluent-c…┊ [2019-10-18 14:39:01,432] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ java.util.concurrent.TimeoutException\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\nconfluent-c…┊ \tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/forward_iterator.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:03,145] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:03,163] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:03,191] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:03,234] INFO Added plugin 'io.confluent.kafka.secretregistry.client.config.provider.SecretConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:03,234] INFO Added plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:03,256] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:08,335] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:08,517] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/import_column_family_job.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:14,715] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:14,751] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:19,289] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:39:19,294] INFO Loading plugin from: /usr/share/java/confluent-rebalancer (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/internal_stats.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/logs_with_prep_tracker.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/log_reader.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/log_writer.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/malloc_stats.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/memtable.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:18,923] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-rebalancer/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:18,928] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [2019-10-18 14:40:19,263] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ java.util.concurrent.TimeoutException\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\nconfluent-c…┊ \tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:19,540] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:19,567] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/memtable_list.o\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:28,178] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:28,186] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/merge_helper.o\nconfluent-c…┊ [2019-10-18 14:41:43,325] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-cluster-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ java.util.concurrent.TimeoutException\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\nconfluent-c…┊ \tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/merge_operator.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/range_del_aggregator.o\nW1018 10:41:52.607794   10009 reflector.go:299] github.com/windmilleng/tilt/internal/k8s/watch.go:200: watch of *v1.Service ended with: too old resource version: 759 (1555)\nW1018 10:41:52.607794   10009 reflector.go:299] github.com/windmilleng/tilt/internal/k8s/watch.go:200: watch of *v1.Service ended with: too old resource version: 759 (1555)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/range_tombstone_fragmenter.o\nconfluent-c…┊ [2019-10-18 14:41:59,231] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-stream-extension-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ java.util.concurrent.TimeoutException\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\nconfluent-c…┊ \tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\nconfluent-c…┊ \tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\nconfluent-c…┊ \tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\nconfluent-c…┊ [2019-10-18 14:41:59,277] INFO describing topics=[_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-metrics, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-command, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-monitoring, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,877] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,919] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,920] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,920] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,921] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,921] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,923] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:41:59,987] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,009] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,030] INFO create=success topic=TopicInfo{name=_confluent-metrics, partitions=12, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,091] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,096] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,096] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,210] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-command, partitions=1, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,212] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,214] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,215] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,254] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,258] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,259] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,260] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,271] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,275] INFO create=success topic=TopicInfo{name=_confluent-monitoring, partitions=12, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,287] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,291] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,296] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-cluster-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,300] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-stream-extension-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:00,453] INFO ConsumerConfig values: \nconfluent-c…┊ \tauto.commit.interval.ms = 5000\nconfluent-c…┊ \tauto.offset.reset = latest\nconfluent-c…┊ \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\nconfluent-c…┊ \tcheck.crcs = true\nconfluent-c…┊ \tclient.dns.lookup = default\nconfluent-c…┊ \tclient.id = will-delete-this\nconfluent-c…┊ \tconnections.max.idle.ms = 540000\nconfluent-c…┊ \tdefault.api.timeout.ms = 60000\nconfluent-c…┊ \tenable.auto.commit = false\nconfluent-c…┊ \texclude.internal.topics = true\nconfluent-c…┊ \tfetch.max.bytes = 52428800\nconfluent-c…┊ \tfetch.max.wait.ms = 500\nconfluent-c…┊ \tfetch.min.bytes = 1\nconfluent-c…┊ \tgroup.id = _confluent-controlcenter-5-2-0-1\nconfluent-c…┊ \theartbeat.interval.ms = 3000\nconfluent-c…┊ \tinterceptor.classes = []\nconfluent-c…┊ \tinternal.leave.group.on.close = false\nconfluent-c…┊ \tisolation.level = read_uncommitted\nconfluent-c…┊ \tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\nconfluent-c…┊ \tmax.partition.fetch.bytes = 1048576\nconfluent-c…┊ \tmax.poll.interval.ms = 21600000\nconfluent-c…┊ \tmax.poll.records = 100\nconfluent-c…┊ \tmetadata.max.age.ms = 300000\nconfluent-c…┊ \tmetric.reporters = []\nconfluent-c…┊ \tmetrics.num.samples = 2\nconfluent-c…┊ \tmetrics.recording.level = INFO\nconfluent-c…┊ \tmetrics.sample.window.ms = 30000\nconfluent-c…┊ \tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\nconfluent-c…┊ \treceive.buffer.bytes = 65536\nconfluent-c…┊ \treconnect.backoff.max.ms = 1000\nconfluent-c…┊ \treconnect.backoff.ms = 50\nconfluent-c…┊ \trequest.timeout.ms = 30000\nconfluent-c…┊ \tretry.backoff.ms = 100\nconfluent-c…┊ \tsasl.client.callback.handler.class = null\nconfluent-c…┊ \tsasl.jaas.config = null\nconfluent-c…┊ \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\nconfluent-c…┊ \tsasl.kerberos.min.time.before.relogin = 60000\nconfluent-c…┊ \tsasl.kerberos.service.name = null\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.jitter = 0.05\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.callback.handler.class = null\nconfluent-c…┊ \tsasl.login.class = null\nconfluent-c…┊ \tsasl.login.refresh.buffer.seconds = 300\nconfluent-c…┊ \tsasl.login.refresh.min.period.seconds = 60\nconfluent-c…┊ \tsasl.login.refresh.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.refresh.window.jitter = 0.05\nconfluent-c…┊ \tsasl.mechanism = GSSAPI\nconfluent-c…┊ \tsecurity.protocol = PLAINTEXT\nconfluent-c…┊ \tsend.buffer.bytes = 131072\nconfluent-c…┊ \tsession.timeout.ms = 60000\nconfluent-c…┊ \tssl.cipher.suites = null\nconfluent-c…┊ \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = https\nconfluent-c…┊ \tssl.key.password = null\nconfluent-c…┊ \tssl.keymanager.algorithm = SunX509\nconfluent-c…┊ \tssl.keystore.location = null\nconfluent-c…┊ \tssl.keystore.password = null\nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tssl.provider = null\nconfluent-c…┊ \tssl.secure.random.implementation = null\nconfluent-c…┊ \tssl.trustmanager.algorithm = PKIX\nconfluent-c…┊ \tssl.truststore.location = null\nconfluent-c…┊ \tssl.truststore.password = null\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊ \tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\nconfluent-c…┊  (org.apache.kafka.clients.consumer.ConsumerConfig)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/repair.o\nconfluent-c…┊ [2019-10-18 14:42:00,869] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:42:00,870] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:42:00,981] INFO Setting offsets for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:01,315] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\nconfluent-c…┊ [2019-10-18 14:42:01,529] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Subscribed to partition(s): _confluent-monitoring-11, _confluent-monitoring-10, _confluent-monitoring-9, _confluent-monitoring-8, _confluent-monitoring-3, _confluent-monitoring-2, _confluent-monitoring-1, _confluent-monitoring-0, _confluent-monitoring-7, _confluent-monitoring-6, _confluent-monitoring-5, _confluent-monitoring-4 (org.apache.kafka.clients.consumer.KafkaConsumer)\nconfluent-c…┊ [2019-10-18 14:42:01,753] INFO found 12 topicPartitions for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:02,599] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-11 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,620] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-10 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,630] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-9 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,631] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-8 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,631] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-3 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,641] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-2 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,647] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-1 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,650] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,650] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-7 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,652] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-6 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,656] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-5 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:02,657] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-4 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:42:03,175] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Discovered group coordinator confluent-cp-kafka-0.confluent-cp-kafka-headless.testspace:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\nconfluent-c…┊ [2019-10-18 14:42:03,916] INFO Setting offsets for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [2019-10-18 14:42:04,054] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Subscribed to partition(s): _confluent-metrics-11, _confluent-metrics-9, _confluent-metrics-10, _confluent-metrics-7, _confluent-metrics-8, _confluent-metrics-5, _confluent-metrics-6, _confluent-metrics-3, _confluent-metrics-4, _confluent-metrics-1, _confluent-metrics-2, _confluent-metrics-0 (org.apache.kafka.clients.consumer.KafkaConsumer)\nconfluent-c…┊ [2019-10-18 14:42:04,094] INFO found 12 topicPartitions for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:42:04,776] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:42:04,788] INFO Loading plugin from: /usr/share/confluent-hub-components/confluentinc-kafka-connect-gcs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [2019-10-18 14:42:05,843] INFO action=starting topology=command (io.confluent.controlcenter.ControlCenter)\nconfluent-c…┊ [2019-10-18 14:42:06,193] INFO stream-client [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams)\nconfluent-c…┊ [2019-10-18 14:42:06,234] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:42:06,266] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:42:06,329] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:42:06,495] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Subscribed to pattern: '_confluent-command' (org.apache.kafka.clients.consumer.KafkaConsumer)\nconfluent-c…┊ rpc error: code = DeadlineExceeded desc = context deadline exceeded[prometheus-jmx-exporter] rpc error: code = DeadlineExceeded desc = context deadline exceeded[cp-kafka-connect-server] rpc error: code = DeadlineExceeded desc = context deadline exceeded    ╎   →   CC       shared-objects/db/snapshot_impl.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/table_cache.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/table_properties_collector.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/transaction_log_impl.o\nrelease-nam…┊     ╎   →   CC       shared-objects/db/trim_history_scheduler.o\nconfluent-c…┊ [2019-10-18 14:46:32,591] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:33,703] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:34,710] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:35,719] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:36,189] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\nconfluent-c…┊ [2019-10-18 14:46:36,200] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Discovered group coordinator confluent-cp-kafka-0.confluent-cp-kafka-headless.testspace:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\nconfluent-c…┊ [2019-10-18 14:46:36,709] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:37,665] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\nconfluent-c…┊ [2019-10-18 14:46:37,675] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:46:37,705] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\nconfluent-c…┊ [2019-10-18 14:46:37,708] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] partition revocation took 27 ms.\nconfluent-c…┊ \tsuspended active tasks: []\nconfluent-c…┊ \tsuspended standby tasks: [] (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:46:37,708] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\nconfluent-c…┊ [2019-10-18 14:46:37,715] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:46,056] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:46,079] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\nconfluent-c…┊ [2019-10-18 14:46:47,059] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:48,061] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:49,102] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:50,259] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:50,359] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer] Assigned tasks to clients as {2fade159-3e58-4692-9df6-f6c0d5ac390b=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor)\nconfluent-c…┊ [2019-10-18 14:46:51,521] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:51,624] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\nconfluent-c…┊ [2019-10-18 14:46:52,194] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Setting newly assigned partitions: _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\nconfluent-c…┊ [2019-10-18 14:46:52,209] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:46:52,785] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:53,810] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:53,976] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] partition assignment took 1767 ms.\nconfluent-c…┊ \tcurrent active tasks: [0_0]\nconfluent-c…┊ \tcurrent standby tasks: []\nconfluent-c…┊ \tprevious active tasks: []\nconfluent-c…┊  (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:46:54,859] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:55,859] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:56,947] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:57,480] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/version_builder.o\nconfluent-c…┊ [2019-10-18 14:46:57,965] INFO unable to get command store (io.confluent.command.CommandStore)\nconfluent-c…┊ [2019-10-18 14:46:58,156] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\nconfluent-c…┊ [2019-10-18 14:46:58,302] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\nconfluent-c…┊ [2019-10-18 14:46:58,322] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:46:58,428] INFO stream-client [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams)\nconfluent-c…┊ [2019-10-18 14:46:58,531] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Setting topic '_confluent-command' to consume from earliest offset (org.apache.kafka.streams.processor.internals.StreamThread)\nconfluent-c…┊ [2019-10-18 14:46:58,570] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:46:59,709] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/confluent-hub-components/confluentinc-kafka-connect-gcs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [cp-kafka-connect-server] [2019-10-18 14:46:59,728] INFO Added plugin 'io.confluent.connect.gcs.GcsSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\nconfluent-c…┊ [2019-10-18 14:47:00,009] INFO action=started topology=command (io.confluent.controlcenter.ControlCenter)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/version_edit.o\nconfluent-c…┊ [2019-10-18 14:47:11,003] INFO RestConfig values: \nconfluent-c…┊ \tmetric.reporters = []\nconfluent-c…┊ \tssl.client.auth = false\nconfluent-c…┊ \trest.servlet.initializor.classes = []\nconfluent-c…┊ \tresponse.mediatype.default = application/json\nconfluent-c…┊ \twebsocket.path.prefix = /ws\nconfluent-c…┊ \tresource.extension.classes = []\nconfluent-c…┊ \tauthentication.realm = \nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.trustmanager.algorithm = \nconfluent-c…┊ \tauthentication.method = NONE\nconfluent-c…┊ \tmetrics.jmx.prefix = rest-utils\nconfluent-c…┊ \trequest.logger.name = io.confluent.rest-utils.requests\nconfluent-c…┊ \tssl.key.password = [hidden]\nconfluent-c…┊ \tssl.truststore.password = [hidden]\nconfluent-c…┊ \tauthentication.roles = [*]\nconfluent-c…┊ \tmetrics.num.samples = 2\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = \nconfluent-c…┊ \tcompression.enable = true\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tdebug = false\nconfluent-c…┊ \tlisteners = []\nconfluent-c…┊ \tssl.provider = \nconfluent-c…┊ \tssl.enabled.protocols = []\nconfluent-c…┊ \tshutdown.graceful.ms = 1000\nconfluent-c…┊ \tssl.keystore.location = \nconfluent-c…┊ \tresponse.mediatype.preferred = [application/json]\nconfluent-c…┊ \tssl.cipher.suites = []\nconfluent-c…┊ \tauthentication.skip.paths = []\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊ \twebsocket.servlet.initializor.classes = []\nconfluent-c…┊ \taccess.control.allow.methods = \nconfluent-c…┊ \taccess.control.allow.origin = \nconfluent-c…┊ \tssl.truststore.location = \nconfluent-c…┊ \tssl.keystore.password = [hidden]\nconfluent-c…┊ \tssl.keymanager.algorithm = \nconfluent-c…┊ \tport = 9021\nconfluent-c…┊ \taccess.control.allow.headers = \nconfluent-c…┊ \tmetrics.sample.window.ms = 30000\nconfluent-c…┊ \tmetrics.tag.map = {}\nconfluent-c…┊  (io.confluent.rest.RestConfig)\nconfluent-c…┊ [2019-10-18 14:47:11,098] WARN Configuration 'confluent.controlcenter.ksql.url' is deprecated. Configure new ksql clusters with 'confluent.controlcenter.ksql.<name>.url'. Please see documentation for more details. (io.confluent.controlcenter.ksql.KsqlClusterMetadata)\nrelease-nam…┊     ╎   →   CC       shared-objects/db/version_set.o\nconfluent-c…┊ [2019-10-18 14:47:18,247] INFO Starting License Store (io.confluent.license.LicenseStore)\nconfluent-c…┊ [2019-10-18 14:47:18,254] INFO Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\nconfluent-c…┊ [2019-10-18 14:47:18,413] INFO AdminClientConfig values: \nconfluent-c…┊ \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\nconfluent-c…┊ \tclient.dns.lookup = default\nconfluent-c…┊ \tclient.id = _confluent-controlcenter-license-manager-5-2-0-1\nconfluent-c…┊ \tconnections.max.idle.ms = 300000\nconfluent-c…┊ \tmetadata.max.age.ms = 300000\nconfluent-c…┊ \tmetric.reporters = []\nconfluent-c…┊ \tmetrics.num.samples = 2\nconfluent-c…┊ \tmetrics.recording.level = INFO\nconfluent-c…┊ \tmetrics.sample.window.ms = 30000\nconfluent-c…┊ \treceive.buffer.bytes = 65536\nconfluent-c…┊ \treconnect.backoff.max.ms = 1000\nconfluent-c…┊ \treconnect.backoff.ms = 50\nconfluent-c…┊ \trequest.timeout.ms = 120000\nconfluent-c…┊ \tretries = 2147483647\nconfluent-c…┊ \tretry.backoff.ms = 100\nconfluent-c…┊ \tsasl.client.callback.handler.class = null\nconfluent-c…┊ \tsasl.jaas.config = null\nconfluent-c…┊ \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\nconfluent-c…┊ \tsasl.kerberos.min.time.before.relogin = 60000\nconfluent-c…┊ \tsasl.kerberos.service.name = null\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.jitter = 0.05\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.callback.handler.class = null\nconfluent-c…┊ \tsasl.login.class = null\nconfluent-c…┊ \tsasl.login.refresh.buffer.seconds = 300\nconfluent-c…┊ \tsasl.login.refresh.min.period.seconds = 60\nconfluent-c…┊ \tsasl.login.refresh.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.refresh.window.jitter = 0.05\nconfluent-c…┊ \tsasl.mechanism = GSSAPI\nconfluent-c…┊ \tsecurity.protocol = PLAINTEXT\nconfluent-c…┊ \tsend.buffer.bytes = 131072\nconfluent-c…┊ \tssl.cipher.suites = null\nconfluent-c…┊ \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = https\nconfluent-c…┊ \tssl.key.password = null\nconfluent-c…┊ \tssl.keymanager.algorithm = SunX509\nconfluent-c…┊ \tssl.keystore.location = null\nconfluent-c…┊ \tssl.keystore.password = null\nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tssl.provider = null\nconfluent-c…┊ \tssl.secure.random.implementation = null\nconfluent-c…┊ \tssl.trustmanager.algorithm = PKIX\nconfluent-c…┊ \tssl.truststore.location = null\nconfluent-c…┊ \tssl.truststore.password = null\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊  (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:47:18,539] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\nconfluent-c…┊ [2019-10-18 14:47:18,641] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:47:18,641] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:47:19,682] INFO ProducerConfig values: \nconfluent-c…┊ \tacks = all\nconfluent-c…┊ \tbatch.size = 16384\nconfluent-c…┊ \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\nconfluent-c…┊ \tbuffer.memory = 33554432\nconfluent-c…┊ \tclient.dns.lookup = default\nconfluent-c…┊ \tclient.id = _confluent-controlcenter-license-manager-5-2-0-1\nconfluent-c…┊ \tcompression.type = lz4\nconfluent-c…┊ \tconnections.max.idle.ms = 540000\nconfluent-c…┊ \tdelivery.timeout.ms = 2147483647\nconfluent-c…┊ \tenable.idempotence = false\nconfluent-c…┊ \tinterceptor.classes = []\nconfluent-c…┊ \tkey.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde\nconfluent-c…┊ \tlinger.ms = 500\nconfluent-c…┊ \tmax.block.ms = 9223372036854775807\nconfluent-c…┊ \tmax.in.flight.requests.per.connection = 1\nconfluent-c…┊ \tmax.request.size = 10485760\nconfluent-c…┊ \tmetadata.max.age.ms = 300000\nconfluent-c…┊ \tmetric.reporters = []\nconfluent-c…┊ \tmetrics.num.samples = 2\nconfluent-c…┊ \tmetrics.recording.level = INFO\nconfluent-c…┊ \tmetrics.sample.window.ms = 30000\nconfluent-c…┊ \tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\nconfluent-c…┊ \treceive.buffer.bytes = 32768\nconfluent-c…┊ \treconnect.backoff.max.ms = 1000\nconfluent-c…┊ \treconnect.backoff.ms = 50\nconfluent-c…┊ \trequest.timeout.ms = 30000\nconfluent-c…┊ \tretries = 2147483647\nconfluent-c…┊ \tretry.backoff.ms = 100\nconfluent-c…┊ \tsasl.client.callback.handler.class = null\nconfluent-c…┊ \tsasl.jaas.config = null\nconfluent-c…┊ \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\nconfluent-c…┊ \tsasl.kerberos.min.time.before.relogin = 60000\nconfluent-c…┊ \tsasl.kerberos.service.name = null\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.jitter = 0.05\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.callback.handler.class = null\nconfluent-c…┊ \tsasl.login.class = null\nconfluent-c…┊ \tsasl.login.refresh.buffer.seconds = 300\nconfluent-c…┊ \tsasl.login.refresh.min.period.seconds = 60\nconfluent-c…┊ \tsasl.login.refresh.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.refresh.window.jitter = 0.05\nconfluent-c…┊ \tsasl.mechanism = GSSAPI\nconfluent-c…┊ \tsecurity.protocol = PLAINTEXT\nconfluent-c…┊ \tsend.buffer.bytes = 131072\nconfluent-c…┊ \tssl.cipher.suites = null\nconfluent-c…┊ \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = https\nconfluent-c…┊ \tssl.key.password = null\nconfluent-c…┊ \tssl.keymanager.algorithm = SunX509\nconfluent-c…┊ \tssl.keystore.location = null\nconfluent-c…┊ \tssl.keystore.password = null\nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tssl.provider = null\nconfluent-c…┊ \tssl.secure.random.implementation = null\nconfluent-c…┊ \tssl.trustmanager.algorithm = PKIX\nconfluent-c…┊ \tssl.truststore.location = null\nconfluent-c…┊ \tssl.truststore.password = null\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊ \ttransaction.timeout.ms = 60000\nconfluent-c…┊ \ttransactional.id = null\nconfluent-c…┊ \tvalue.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde\nconfluent-c…┊  (org.apache.kafka.clients.producer.ProducerConfig)\nconfluent-c…┊ [2019-10-18 14:47:20,067] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:47:20,067] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:47:20,072] INFO ConsumerConfig values: \nconfluent-c…┊ \tauto.commit.interval.ms = 5000\nconfluent-c…┊ \tauto.offset.reset = earliest\nconfluent-c…┊ \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\nconfluent-c…┊ \tcheck.crcs = true\nconfluent-c…┊ \tclient.dns.lookup = default\nconfluent-c…┊ \tclient.id = _confluent-controlcenter-license-manager-5-2-0-1-global-consumer\nconfluent-c…┊ \tconnections.max.idle.ms = 540000\nconfluent-c…┊ \tdefault.api.timeout.ms = 60000\nconfluent-c…┊ \tenable.auto.commit = false\nconfluent-c…┊ \texclude.internal.topics = true\nconfluent-c…┊ \tfetch.max.bytes = 52428800\nconfluent-c…┊ \tfetch.max.wait.ms = 500\nconfluent-c…┊ \tfetch.min.bytes = 1\nconfluent-c…┊ \tgroup.id = null\nconfluent-c…┊ \theartbeat.interval.ms = 3000\nconfluent-c…┊ \tinterceptor.classes = []\nconfluent-c…┊ \tinternal.leave.group.on.close = false\nconfluent-c…┊ \tisolation.level = read_uncommitted\nconfluent-c…┊ \tkey.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde\nconfluent-c…┊ \tmax.partition.fetch.bytes = 1048576\nconfluent-c…┊ \tmax.poll.interval.ms = 21600000\nconfluent-c…┊ \tmax.poll.records = 100\nconfluent-c…┊ \tmetadata.max.age.ms = 300000\nconfluent-c…┊ \tmetric.reporters = []\nconfluent-c…┊ \tmetrics.num.samples = 2\nconfluent-c…┊ \tmetrics.recording.level = INFO\nconfluent-c…┊ \tmetrics.sample.window.ms = 30000\nconfluent-c…┊ \tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\nconfluent-c…┊ \treceive.buffer.bytes = 65536\nconfluent-c…┊ \treconnect.backoff.max.ms = 1000\nconfluent-c…┊ \treconnect.backoff.ms = 50\nconfluent-c…┊ \trequest.timeout.ms = 30000\nconfluent-c…┊ \tretry.backoff.ms = 100\nconfluent-c…┊ \tsasl.client.callback.handler.class = null\nconfluent-c…┊ \tsasl.jaas.config = null\nconfluent-c…┊ \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\nconfluent-c…┊ \tsasl.kerberos.min.time.before.relogin = 60000\nconfluent-c…┊ \tsasl.kerberos.service.name = null\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.jitter = 0.05\nconfluent-c…┊ \tsasl.kerberos.ticket.renew.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.callback.handler.class = null\nconfluent-c…┊ \tsasl.login.class = null\nconfluent-c…┊ \tsasl.login.refresh.buffer.seconds = 300\nconfluent-c…┊ \tsasl.login.refresh.min.period.seconds = 60\nconfluent-c…┊ \tsasl.login.refresh.window.factor = 0.8\nconfluent-c…┊ \tsasl.login.refresh.window.jitter = 0.05\nconfluent-c…┊ \tsasl.mechanism = GSSAPI\nconfluent-c…┊ \tsecurity.protocol = PLAINTEXT\nconfluent-c…┊ \tsend.buffer.bytes = 131072\nconfluent-c…┊ \tsession.timeout.ms = 60000\nconfluent-c…┊ \tssl.cipher.suites = null\nconfluent-c…┊ \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\nconfluent-c…┊ \tssl.endpoint.identification.algorithm = https\nconfluent-c…┊ \tssl.key.password = null\nconfluent-c…┊ \tssl.keymanager.algorithm = SunX509\nconfluent-c…┊ \tssl.keystore.location = null\nconfluent-c…┊ \tssl.keystore.password = null\nconfluent-c…┊ \tssl.keystore.type = JKS\nconfluent-c…┊ \tssl.protocol = TLS\nconfluent-c…┊ \tssl.provider = null\nconfluent-c…┊ \tssl.secure.random.implementation = null\nconfluent-c…┊ \tssl.trustmanager.algorithm = PKIX\nconfluent-c…┊ \tssl.truststore.location = null\nconfluent-c…┊ \tssl.truststore.password = null\nconfluent-c…┊ \tssl.truststore.type = JKS\nconfluent-c…┊ \tvalue.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde\nconfluent-c…┊  (org.apache.kafka.clients.consumer.ConsumerConfig)\nconfluent-c…┊ [2019-10-18 14:47:20,284] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:47:20,284] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\nconfluent-c…┊ [2019-10-18 14:47:20,321] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\nconfluent-c…┊ [2019-10-18 14:47:20,576] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\nconfluent-c…┊ [2019-10-18 14:47:20,890] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-2-0-1-global-consumer, groupId=null] Subscribed to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer)\nconfluent-c…┊ [2019-10-18 14:47:22,951] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-2-0-1-global-consumer, groupId=null] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\nconfluent-c…┊ [2019-10-18 14:47:22,992] INFO Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\nconfluent-c…┊ [2019-10-18 14:47:22,993] INFO Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\nconfluent-c…┊ [2019-10-18 14:47:22,994] INFO Started License Store (io.confluent.license.LicenseStore)\n",
  "Resources": [
    {
      "Name": "(Tiltfile)",
      "DirectoriesWatched": null,
      "PathsWatched": null,
      "LastDeployTime": "2019-10-18T10:29:25.240833-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": [
            "Tiltfile"
          ],
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:24.62433-04:00",
          "FinishTime": "2019-10-18T10:29:25.240833-04:00",
          "Log": "Beginning Tiltfile execution\nlocal: git clone https://github.com/confluentinc/cp-helm-charts.git deployment/cp-helm-charts | true\n → fatal: destination path 'deployment/cp-helm-charts' already exists and is not an empty directory.\nlocal: helm template --namespace johntest -f ./deployment/faustdemo-values.yml ./deployment/faustdemo\n → ---\n → # Source: faustdemo/templates/quota.yaml\n → apiVersion: v1\n → kind: ResourceQuota\n → metadata:\n →   name: quota\n → spec:\n →   hard:\n →     limits.memory: 2Gi\n →     requests.memory: 2Gi\n →     requests.cpu: 2\n → \n → ---\n → # Source: faustdemo/templates/faustdemo-pod.yaml\n → apiVersion: v1\n → kind: Pod\n → metadata:\n →   name: release-name-faustdemo\n →   namespace: testspace\n →   labels:\n →     # The \"app.kubernetes.io/managed-by\" label is used to track which tool deployed a given chart.\n →     # It is useful for admins who want to see what releases a particular tool\n →     # is responsible for.\n →     app.kubernetes.io/managed-by: Tiller\n →     # The \"app.kubernetes.io/instance\" convention makes it easy to tie a release to all of the\n →     # Kubernetes resources that were created as part of that release.\n →     app.kubernetes.io/instance: \"release-name\"\n →     app.kubernetes.io/version: \"3.3\"\n →     # This makes it easy to audit chart usage.\n →     helm.sh/chart: faustdemo-0.1.0\n →     app.kubernetes.io/name: faustdemo\n → spec:\n →   # This shows how to use a simple value. This will look for a passed-in value called restartPolicy.\n →   restartPolicy: Never\n →   containers:\n →   - name: faustdemo\n →     image: \"faustdemo:latest\"\n →     imagePullPolicy: Always\n →     command: [./run.sh]\n →     # disabled readiness probe as tilt needs service available\n →     #readinessProbe:\n →     #  httpGet:\n →     #    path: \"/ready/\"\n →     #    port: 8088\n →     ports:\n →       - containerPort: 8088\n →     resources:\n →       limits:\n →         memory: 1Gi\n →       requests:\n →         cpu: 1\n →         memory: 1Gi\n →     env:\n →     \n →     - name: FAUST_DATADIR\n →       value: \".data1\"\n →     \n →     - name: KAFKA_BROKER\n →       value: \"confluent-cp-kafka.testspace.svc.cluster.local\"\n →     \n →     - name: SIMPLE_SETTINGS\n →       value: \"faustdemo.settings\"\nSuccessfully loaded Tiltfile\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "",
      "RuntimeStatus": "ok",
      "IsTiltfile": true,
      "ShowBuildStatus": false,
      "CombinedLog": "Beginning Tiltfile execution\nlocal: git clone https://github.com/confluentinc/cp-helm-charts.git deployment/cp-helm-charts | true\n → fatal: destination path 'deployment/cp-helm-charts' already exists and is not an empty directory.\nlocal: helm template --namespace johntest -f ./deployment/faustdemo-values.yml ./deployment/faustdemo\n → ---\n → # Source: faustdemo/templates/quota.yaml\n → apiVersion: v1\n → kind: ResourceQuota\n → metadata:\n →   name: quota\n → spec:\n →   hard:\n →     limits.memory: 2Gi\n →     requests.memory: 2Gi\n →     requests.cpu: 2\n → \n → ---\n → # Source: faustdemo/templates/faustdemo-pod.yaml\n → apiVersion: v1\n → kind: Pod\n → metadata:\n →   name: release-name-faustdemo\n →   namespace: testspace\n →   labels:\n →     # The \"app.kubernetes.io/managed-by\" label is used to track which tool deployed a given chart.\n →     # It is useful for admins who want to see what releases a particular tool\n →     # is responsible for.\n →     app.kubernetes.io/managed-by: Tiller\n →     # The \"app.kubernetes.io/instance\" convention makes it easy to tie a release to all of the\n →     # Kubernetes resources that were created as part of that release.\n →     app.kubernetes.io/instance: \"release-name\"\n →     app.kubernetes.io/version: \"3.3\"\n →     # This makes it easy to audit chart usage.\n →     helm.sh/chart: faustdemo-0.1.0\n →     app.kubernetes.io/name: faustdemo\n → spec:\n →   # This shows how to use a simple value. This will look for a passed-in value called restartPolicy.\n →   restartPolicy: Never\n →   containers:\n →   - name: faustdemo\n →     image: \"faustdemo:latest\"\n →     imagePullPolicy: Always\n →     command: [./run.sh]\n →     # disabled readiness probe as tilt needs service available\n →     #readinessProbe:\n →     #  httpGet:\n →     #    path: \"/ready/\"\n →     #    port: 8088\n →     ports:\n →       - containerPort: 8088\n →     resources:\n →       limits:\n →         memory: 1Gi\n →       requests:\n →         cpu: 1\n →         memory: 1Gi\n →     env:\n →     \n →     - name: FAUST_DATADIR\n →       value: \".data1\"\n →     \n →     - name: KAFKA_BROKER\n →       value: \"confluent-cp-kafka.testspace.svc.cluster.local\"\n →     \n →     - name: SIMPLE_SETTINGS\n →       value: \"faustdemo.settings\"\nSuccessfully loaded Tiltfile\n",
      "CrashLog": ""
    },
    {
      "Name": "confluent-cp-control-center",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:26.68337-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:26.262749-04:00",
          "FinishTime": "2019-10-18T10:29:26.683367-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-control-center\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-control-center:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-control-center:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.419s\n\u001b[34m  │ \u001b[0mDone in: 0.419s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": [
        "http://localhost:9021/"
      ],
      "PodID": "confluent-cp-control-center-965bb95cd-5fndx",
      "K8sResourceInfo": {
        "PodName": "confluent-cp-control-center-965bb95cd-5fndx",
        "PodCreationTime": "2019-10-18T10:29:26-04:00",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "Running",
        "PodStatusMessage": "",
        "AllContainersReady": true,
        "PodRestarts": 0,
        "PodLog": "===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n===> Check if /etc/confluent-control-center is writable ...\n===> Check if /var/lib/confluent-control-center is writable ...\n===> Running preflight checks ... \n===> Check if Kafka is healthy ...\n[main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 5\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n[main] WARN org.apache.kafka.clients.ClientUtils - Couldn't resolve server PLAINTEXT://confluent-cp-kafka-headless:9092 from bootstrap.servers as DNS resolution failed for confluent-cp-kafka-headless\n[main] ERROR io.confluent.admin.utils.cli.KafkaReadyCommand - Error while running kafka-ready.\norg.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:386)\n\tat org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:65)\n\tat io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:138)\n\tat io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:150)\nCaused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:346)\n\t... 3 more\n===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n===> Check if /etc/confluent-control-center is writable ...\n===> Check if /var/lib/confluent-control-center is writable ...\n===> Running preflight checks ... \n===> Check if Kafka is healthy ...\n[main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 5\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.2.0-cp1\n[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 3127056544c01d5a\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n===> Launching ... \n===> Launching control-center ... \n[2019-10-18 14:35:49,425] WARN Invalid value 1 for configuration confluent.controlcenter.internal.topics.replication: Value must be at least 3 (io.confluent.controlcenter.ControlCenterConfig)\n[2019-10-18 14:35:49,478] INFO ControlCenterConfig values: \n\tconfluent.controlcenter.internal.topics.retention.bytes = -1\n\tconfluent.controlcenter.streams.producer.delivery.timeout.ms = 2147483647\n\tconfluent.controlcenter.streams.cache.max.bytes.buffering = 1073741824\n\tconfluent.support.metrics.enable = true\n\tconfluent.controlcenter.command.streams.start.timeout = 300000\n\tconfluent.controlcenter.internal.streams.start.timeout = 21600000\n\tconfluent.controlcenter.connect.timeout.ms = 15000\n\tconfluent.controlcenter.alert.cluster.down.send.rate = 12\n\tconfluent.controlcenter.ksql.advertised.url = [http://confluent-cp-ksql-server:8088]\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tconfluent.controlcenter.rest.advertised.url = \n\tconfluent.controlcenter.streams.producer.linger.ms = 500\n\tconfluent.controlcenter.mail.from = c3@confluent.io\n\tconfluent.controlcenter.internal.topics.retention.ms = 604800000\n\tconfluent.monitoring.interceptor.topic.config.validate = false\n\tconfluent.metrics.topic.config.validate = false\n\tconfluent.controlcenter.connect.cluster = [http://confluent-cp-kafka-connect:8083]\n\tconfluent.metrics.topic.partitions = 12\n\tconfluent.controlcenter.schema.registry.enable = true\n\tconfluent.metrics.topic.retention.bytes = -1\n\tconfluent.monitoring.interceptor.topic.retention.ms = 259200000\n\tconfluent.controlcenter.mail.port = 587\n\tconfluent.metrics.topic.replication = 1\n\tconfluent.monitoring.interceptor.topic = _confluent-monitoring\n\tconfluent.controlcenter.rest.port = 9021\n\tconfluent.controlcenter.id = 1\n\tzookeeper.connect = \n\tconfluent.metrics.topic = _confluent-metrics\n\tconfluent.controlcenter.rest.compression.enable = true\n\tconfluent.controlcenter.command.topic = _confluent-command\n\tconfluent.controlcenter.topic.inspection.enable = true\n\tconfluent.controlcenter.ksql.enable = true\n\tconfluent.controlcenter.internal.topics.replication = 1\n\tconfluent.controlcenter.internal.topics.partitions = 4\n\tconfluent.controlcenter.mail.host.name = localhost\n\tconfluent.controlcenter.alert.max.trigger.events = 1000\n\tconfluent.controlcenter.mail.password = \n\tconfluent.metrics.topic.skip.backlog.minutes = 15\n\tconfluent.controlcenter.schema.registry.url = [http://confluent-cp-schema-registry:8081]\n\tconfluent.controlcenter.data.dir = /var/lib/confluent-control-center\n\tconfluent.license = \n\tconfluent.monitoring.interceptor.topic.skip.backlog.minutes = 15\n\tconfluent.metrics.topic.max.message.bytes = 10485760\n\tconfluent.controlcenter.broker.config.edit.enable = true\n\tconfluent.controlcenter.name = _confluent-controlcenter-5-2-0\n\tconfluent.controlcenter.auth.session.expiration.ms = 0\n\tconfluent.controlcenter.streams.producer.retries = 2147483647\n\tconfluent.controlcenter.mail.enabled = false\n\tconfluent.controlcenter.command.topic.retention.ms = 259200000\n\tconfluent.controlcenter.rest.hsts.enable = true\n\tconfluent.controlcenter.alert.cluster.down.autocreate = false\n\tconfluent.controlcenter.alert.cluster.down.to.email = \n\tconfluent.monitoring.interceptor.topic.retention.bytes = -1\n\tconfluent.controlcenter.streams.producer.retry.backoff.ms = 100\n\tconfluent.controlcenter.streams.producer.max.block.ms = 9223372036854775807\n\tconfluent.controlcenter.internal.topics.changelog.segment.bytes = 134217728\n\tconfluent.controlcenter.mail.username = \n\tconfluent.controlcenter.disk.skew.warning.min.bytes = 1073741824\n\tconfluent.controlcenter.streams.num.stream.threads = 8\n\tconfluent.controlcenter.command.topic.replication = 1\n\tconfluent.controlcenter.mail.ssl.checkserveridentity = false\n\tconfluent.controlcenter.mail.bounce.address = \n\tconfluent.controlcenter.streams.retries = 2147483647\n\tconfluent.controlcenter.license.manager = _confluent-controlcenter-license-manager-5-2-0\n\tconfluent.monitoring.interceptor.topic.replication = 1\n\tconfluent.controlcenter.streams.consumer.session.timeout.ms = 60000\n\tconfluent.metrics.topic.retention.ms = 259200000\n\tconfluent.controlcenter.mail.starttls.required = false\n\tconfluent.support.metrics.customer.id = anonymous\n\tconfluent.controlcenter.auth.restricted.roles = []\n\tconfluent.monitoring.interceptor.topic.partitions = 12\n\tconfluent.controlcenter.streams.producer.compression.type = lz4\n\tconfluent.controlcenter.ksql.url = [http://confluent-cp-ksql-server:8088]\n\tconfluent.controlcenter.license.manager.enable = true\n (io.confluent.controlcenter.ControlCenterConfig)\n[2019-10-18 14:36:02,495] INFO StreamsConfig values: \n\tapplication.id = _confluent-controlcenter-5-2-0-1\n\tapplication.server = \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffered.records.per.partition = 100\n\tcache.max.bytes.buffering = 1073741824\n\tclient.id = \n\tcommit.interval.ms = 30000\n\tconnections.max.idle.ms = 540000\n\tdefault.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndContinueExceptionHandler\n\tdefault.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tdefault.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler\n\tdefault.timestamp.extractor = class io.confluent.controlcenter.streams.WindowExtractor\n\tdefault.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tmax.task.idle.ms = 0\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tnum.standby.replicas = 0\n\tnum.stream.threads = 8\n\tpartition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper\n\tpoll.ms = 100\n\tprocessing.guarantee = at_least_once\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\treplication.factor = 1\n\trequest.timeout.ms = 40000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\trocksdb.config.setter = class io.confluent.controlcenter.streams.RocksDBConfigurator\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tstate.cleanup.delay.ms = 600000\n\tstate.dir = /var/lib/confluent-control-center/1/kafka-streams\n\ttopology.optimization = all\n\tupgrade.from = null\n\twindowstore.changelog.additional.retention.ms = 86400000\n (org.apache.kafka.streams.StreamsConfig)\n[2019-10-18 14:36:08,578] INFO setting topic names _confluent-monitoring (io.confluent.controlcenter.streams.WindowExtractor)\n[2019-10-18 14:36:08,672] INFO transformerStore=MonitoringVerifierStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,761] INFO transformerStore=MonitoringTriggerStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,772] INFO transformerStore=TriggerActionsStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,772] INFO transformerStore=TriggerEventsStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,772] INFO transformerStore=AlertHistoryStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:09,252] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = confluent-control-center-heartbeat-sender-1\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 1\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 10\n\tretry.backoff.ms = 500\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:36:10,909] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:10,922] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:13,013] INFO StreamsConfig values: \n\tapplication.id = _confluent-controlcenter-5-2-0-1-command\n\tapplication.server = \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffered.records.per.partition = 1000\n\tcache.max.bytes.buffering = 0\n\tclient.id = \n\tcommit.interval.ms = 30000\n\tconnections.max.idle.ms = 540000\n\tdefault.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler\n\tdefault.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tdefault.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler\n\tdefault.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp\n\tdefault.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tmax.task.idle.ms = 0\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tnum.standby.replicas = 0\n\tnum.stream.threads = 1\n\tpartition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper\n\tpoll.ms = 100\n\tprocessing.guarantee = at_least_once\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\treplication.factor = 1\n\trequest.timeout.ms = 40000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\trocksdb.config.setter = null\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tstate.cleanup.delay.ms = 600000\n\tstate.dir = /var/lib/confluent-control-center/1/cp-command\n\ttopology.optimization = all\n\tupgrade.from = null\n\twindowstore.changelog.additional.retention.ms = 86400000\n (org.apache.kafka.streams.StreamsConfig)\n[2019-10-18 14:36:15,641] INFO AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-admin\n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:17,876] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:17,876] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:18,103] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:36:18,251] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = none\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 2147483647\n\tmax.poll.records = 1000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:20,661] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:20,661] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:20,708] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:36:20,790] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Creating shared producer client (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:36:20,827] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-producer\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:36:21,108] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:21,108] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:21,668] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:36:21,697] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = none\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = _confluent-controlcenter-5-2-0-1-command\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 2147483647\n\tmax.poll.records = 1000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:23,172] WARN The configuration 'admin.retries' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:23,182] WARN The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:23,187] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:23,188] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:23,513] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:36:23,617] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = c3-command\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class io.confluent.serializers.ProtoSerde\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class io.confluent.serializers.ProtoSerde\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:36:23,981] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:23,981] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:24,634] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:36:25,064] INFO RestConfig values: \n\tmetric.reporters = []\n\tssl.client.auth = false\n\trest.servlet.initializor.classes = []\n\tresponse.mediatype.default = application/json\n\twebsocket.path.prefix = /ws\n\tresource.extension.classes = []\n\tauthentication.realm = \n\tssl.keystore.type = JKS\n\tssl.trustmanager.algorithm = \n\tauthentication.method = NONE\n\tmetrics.jmx.prefix = rest-utils\n\trequest.logger.name = io.confluent.rest-utils.requests\n\tssl.key.password = [hidden]\n\tssl.truststore.password = [hidden]\n\tauthentication.roles = [*]\n\tmetrics.num.samples = 2\n\tssl.endpoint.identification.algorithm = \n\tcompression.enable = true\n\tssl.protocol = TLS\n\tdebug = false\n\tlisteners = []\n\tssl.provider = \n\tssl.enabled.protocols = []\n\tshutdown.graceful.ms = 1000\n\tssl.keystore.location = \n\tresponse.mediatype.preferred = [application/json]\n\tssl.cipher.suites = []\n\tauthentication.skip.paths = []\n\tssl.truststore.type = JKS\n\twebsocket.servlet.initializor.classes = []\n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tssl.truststore.location = \n\tssl.keystore.password = [hidden]\n\tssl.keymanager.algorithm = \n\tport = 9021\n\taccess.control.allow.headers = \n\tmetrics.sample.window.ms = 30000\n\tmetrics.tag.map = {}\n (io.confluent.rest.RestConfig)\n[2019-10-18 14:36:27,147] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,437] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,448] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,477] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,909] INFO intermediateTopics=[_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,421] INFO CONTROL CENTER UI\n\nBy using Control Center, subject to any license you may have with Confluent, you agree to the Confluent Data Protection Agreement.  In particular, please note that the version check feature of Control Center is enabled.\n\nWith this enabled, this instance is configured to collect and report certain data (version information, time stamped session IDs, instance ID, instance uptime, license key for subscription customers, IP address, and other product data)  to Confluent, Inc. (\"Confluent\") or its parent, subsidiaries, affiliates or service providers every hour.  By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer and use of Version information by Confluent. You can turn the version check feature off by setting `confluent.support.metrics.enable=false` in the Control Center configuration and restarting Control Center.  See the Confluent Enterprise documentation for further information.\n (io.confluent.controlcenter.healthcheck.HealthCheck)\n[2019-10-18 14:36:28,703] INFO Starting Control Center version=5.2.0 (io.confluent.controlcenter.ControlCenter)\n[2019-10-18 14:36:28,801] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,825] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,856] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,875] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:29,007] INFO intermediateTopics=[_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:29,031] INFO AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,336] WARN The configuration 'consumer.session.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,359] WARN The configuration 'producer.linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,397] WARN The configuration 'producer.delivery.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,411] WARN The configuration 'producer.max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,433] WARN The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,459] WARN The configuration 'producer.retries' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,482] WARN The configuration 'producer.compression.type' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,483] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,499] WARN The configuration 'num.stream.threads' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,499] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:29,499] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:30,386] INFO topicListings=[] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:36:30,415] INFO missingTopics=[_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-metrics, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-command, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-monitoring, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:36:30,507] INFO extantTopics=[] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:36:54,863] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:39:01,432] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:40:19,263] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:41:43,325] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-cluster-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:41:59,231] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-stream-extension-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:41:59,277] INFO describing topics=[_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-metrics, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-command, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-monitoring, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,877] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,919] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,920] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,920] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,921] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,921] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,923] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,987] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,009] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,030] INFO create=success topic=TopicInfo{name=_confluent-metrics, partitions=12, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,091] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,096] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,096] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,210] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-command, partitions=1, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,212] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,214] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,215] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,254] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,258] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,259] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,260] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,271] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,275] INFO create=success topic=TopicInfo{name=_confluent-monitoring, partitions=12, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,287] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,291] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,296] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-cluster-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,300] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-stream-extension-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,453] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = latest\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = will-delete-this\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = _confluent-controlcenter-5-2-0-1\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 21600000\n\tmax.poll.records = 100\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:42:00,869] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:42:00,870] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:42:00,981] INFO Setting offsets for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:01,315] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:42:01,529] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Subscribed to partition(s): _confluent-monitoring-11, _confluent-monitoring-10, _confluent-monitoring-9, _confluent-monitoring-8, _confluent-monitoring-3, _confluent-monitoring-2, _confluent-monitoring-1, _confluent-monitoring-0, _confluent-monitoring-7, _confluent-monitoring-6, _confluent-monitoring-5, _confluent-monitoring-4 (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:42:01,753] INFO found 12 topicPartitions for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:02,599] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-11 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,620] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-10 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,630] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-9 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,631] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-8 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,631] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-3 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,641] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-2 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,647] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-1 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,650] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,650] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-7 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,652] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-6 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,656] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-5 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,657] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-4 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:03,175] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Discovered group coordinator confluent-cp-kafka-0.confluent-cp-kafka-headless.testspace:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:42:03,916] INFO Setting offsets for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:04,054] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Subscribed to partition(s): _confluent-metrics-11, _confluent-metrics-9, _confluent-metrics-10, _confluent-metrics-7, _confluent-metrics-8, _confluent-metrics-5, _confluent-metrics-6, _confluent-metrics-3, _confluent-metrics-4, _confluent-metrics-1, _confluent-metrics-2, _confluent-metrics-0 (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:42:04,094] INFO found 12 topicPartitions for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:05,843] INFO action=starting topology=command (io.confluent.controlcenter.ControlCenter)\n[2019-10-18 14:42:06,193] INFO stream-client [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams)\n[2019-10-18 14:42:06,234] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:42:06,266] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:42:06,329] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:42:06,495] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Subscribed to pattern: '_confluent-command' (org.apache.kafka.clients.consumer.KafkaConsumer)\nrpc error: code = DeadlineExceeded desc = context deadline exceeded[2019-10-18 14:46:32,591] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:33,703] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:34,710] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:35,719] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:36,189] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:46:36,200] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Discovered group coordinator confluent-cp-kafka-0.confluent-cp-kafka-headless.testspace:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:36,709] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:37,665] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-18 14:46:37,675] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:37,705] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:46:37,708] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] partition revocation took 27 ms.\n\tsuspended active tasks: []\n\tsuspended standby tasks: [] (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:37,708] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:37,715] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:46,056] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:46,079] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:47,059] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:48,061] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:49,102] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:50,259] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:50,359] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer] Assigned tasks to clients as {2fade159-3e58-4692-9df6-f6c0d5ac390b=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor)\n[2019-10-18 14:46:51,521] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:51,624] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:52,194] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Setting newly assigned partitions: _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-18 14:46:52,209] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:52,785] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:53,810] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:53,976] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] partition assignment took 1767 ms.\n\tcurrent active tasks: [0_0]\n\tcurrent standby tasks: []\n\tprevious active tasks: []\n (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:54,859] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:55,859] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:56,947] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:57,480] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:46:57,965] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:58,156] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:46:58,302] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:46:58,322] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:58,428] INFO stream-client [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams)\n[2019-10-18 14:46:58,531] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Setting topic '_confluent-command' to consume from earliest offset (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:58,570] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:47:00,009] INFO action=started topology=command (io.confluent.controlcenter.ControlCenter)\n[2019-10-18 14:47:11,003] INFO RestConfig values: \n\tmetric.reporters = []\n\tssl.client.auth = false\n\trest.servlet.initializor.classes = []\n\tresponse.mediatype.default = application/json\n\twebsocket.path.prefix = /ws\n\tresource.extension.classes = []\n\tauthentication.realm = \n\tssl.keystore.type = JKS\n\tssl.trustmanager.algorithm = \n\tauthentication.method = NONE\n\tmetrics.jmx.prefix = rest-utils\n\trequest.logger.name = io.confluent.rest-utils.requests\n\tssl.key.password = [hidden]\n\tssl.truststore.password = [hidden]\n\tauthentication.roles = [*]\n\tmetrics.num.samples = 2\n\tssl.endpoint.identification.algorithm = \n\tcompression.enable = true\n\tssl.protocol = TLS\n\tdebug = false\n\tlisteners = []\n\tssl.provider = \n\tssl.enabled.protocols = []\n\tshutdown.graceful.ms = 1000\n\tssl.keystore.location = \n\tresponse.mediatype.preferred = [application/json]\n\tssl.cipher.suites = []\n\tauthentication.skip.paths = []\n\tssl.truststore.type = JKS\n\twebsocket.servlet.initializor.classes = []\n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tssl.truststore.location = \n\tssl.keystore.password = [hidden]\n\tssl.keymanager.algorithm = \n\tport = 9021\n\taccess.control.allow.headers = \n\tmetrics.sample.window.ms = 30000\n\tmetrics.tag.map = {}\n (io.confluent.rest.RestConfig)\n[2019-10-18 14:47:11,098] WARN Configuration 'confluent.controlcenter.ksql.url' is deprecated. Configure new ksql clusters with 'confluent.controlcenter.ksql.<name>.url'. Please see documentation for more details. (io.confluent.controlcenter.ksql.KsqlClusterMetadata)\n[2019-10-18 14:47:18,247] INFO Starting License Store (io.confluent.license.LicenseStore)\n[2019-10-18 14:47:18,254] INFO Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\n[2019-10-18 14:47:18,413] INFO AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-license-manager-5-2-0-1\n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:47:18,539] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:47:18,641] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:18,641] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:19,682] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-license-manager-5-2-0-1\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 1\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:47:20,067] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,067] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,072] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = earliest\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-license-manager-5-2-0-1-global-consumer\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 21600000\n\tmax.poll.records = 100\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:47:20,284] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,284] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,321] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:47:20,576] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:47:20,890] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-2-0-1-global-consumer, groupId=null] Subscribed to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:47:22,951] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-2-0-1-global-consumer, groupId=null] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:47:22,992] INFO Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\n[2019-10-18 14:47:22,993] INFO Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\n[2019-10-18 14:47:22,994] INFO Started License Store (io.confluent.license.LicenseStore)\n"
      },
      "RuntimeStatus": "ok",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-control-center\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-control-center:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-control-center:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.419s\n\u001b[34m  │ \u001b[0mDone in: 0.419s \n\n===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n===> Check if /etc/confluent-control-center is writable ...\n===> Check if /var/lib/confluent-control-center is writable ...\n===> Running preflight checks ... \n===> Check if Kafka is healthy ...\n[main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 5\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n[main] WARN org.apache.kafka.clients.ClientUtils - Couldn't resolve server PLAINTEXT://confluent-cp-kafka-headless:9092 from bootstrap.servers as DNS resolution failed for confluent-cp-kafka-headless\n[main] ERROR io.confluent.admin.utils.cli.KafkaReadyCommand - Error while running kafka-ready.\norg.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:386)\n\tat org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:65)\n\tat io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:138)\n\tat io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:150)\nCaused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:346)\n\t... 3 more\n===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n===> Check if /etc/confluent-control-center is writable ...\n===> Check if /var/lib/confluent-control-center is writable ...\n===> Running preflight checks ... \n===> Check if Kafka is healthy ...\n[main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 5\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n[main] WARN org.apache.kafka.clients.ClientUtils - Couldn't resolve server PLAINTEXT://confluent-cp-kafka-headless:9092 from bootstrap.servers as DNS resolution failed for confluent-cp-kafka-headless\n[main] ERROR io.confluent.admin.utils.cli.KafkaReadyCommand - Error while running kafka-ready.\norg.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:386)\n\tat org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:65)\n\tat io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:138)\n\tat io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:150)\nCaused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:346)\n\t... 3 more\n[K8s EVENT: Pod confluent-cp-control-center-965bb95cd-5fndx (ns: testspace)] Back-off restarting failed container\n===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n===> Check if /etc/confluent-control-center is writable ...\n===> Check if /var/lib/confluent-control-center is writable ...\n===> Running preflight checks ... \n===> Check if Kafka is healthy ...\n[main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 5\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.2.0-cp1\n[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 3127056544c01d5a\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n===> Launching ... \n===> Launching control-center ... \n[2019-10-18 14:35:49,425] WARN Invalid value 1 for configuration confluent.controlcenter.internal.topics.replication: Value must be at least 3 (io.confluent.controlcenter.ControlCenterConfig)\n[2019-10-18 14:35:49,478] INFO ControlCenterConfig values: \n\tconfluent.controlcenter.internal.topics.retention.bytes = -1\n\tconfluent.controlcenter.streams.producer.delivery.timeout.ms = 2147483647\n\tconfluent.controlcenter.streams.cache.max.bytes.buffering = 1073741824\n\tconfluent.support.metrics.enable = true\n\tconfluent.controlcenter.command.streams.start.timeout = 300000\n\tconfluent.controlcenter.internal.streams.start.timeout = 21600000\n\tconfluent.controlcenter.connect.timeout.ms = 15000\n\tconfluent.controlcenter.alert.cluster.down.send.rate = 12\n\tconfluent.controlcenter.ksql.advertised.url = [http://confluent-cp-ksql-server:8088]\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tconfluent.controlcenter.rest.advertised.url = \n\tconfluent.controlcenter.streams.producer.linger.ms = 500\n\tconfluent.controlcenter.mail.from = c3@confluent.io\n\tconfluent.controlcenter.internal.topics.retention.ms = 604800000\n\tconfluent.monitoring.interceptor.topic.config.validate = false\n\tconfluent.metrics.topic.config.validate = false\n\tconfluent.controlcenter.connect.cluster = [http://confluent-cp-kafka-connect:8083]\n\tconfluent.metrics.topic.partitions = 12\n\tconfluent.controlcenter.schema.registry.enable = true\n\tconfluent.metrics.topic.retention.bytes = -1\n\tconfluent.monitoring.interceptor.topic.retention.ms = 259200000\n\tconfluent.controlcenter.mail.port = 587\n\tconfluent.metrics.topic.replication = 1\n\tconfluent.monitoring.interceptor.topic = _confluent-monitoring\n\tconfluent.controlcenter.rest.port = 9021\n\tconfluent.controlcenter.id = 1\n\tzookeeper.connect = \n\tconfluent.metrics.topic = _confluent-metrics\n\tconfluent.controlcenter.rest.compression.enable = true\n\tconfluent.controlcenter.command.topic = _confluent-command\n\tconfluent.controlcenter.topic.inspection.enable = true\n\tconfluent.controlcenter.ksql.enable = true\n\tconfluent.controlcenter.internal.topics.replication = 1\n\tconfluent.controlcenter.internal.topics.partitions = 4\n\tconfluent.controlcenter.mail.host.name = localhost\n\tconfluent.controlcenter.alert.max.trigger.events = 1000\n\tconfluent.controlcenter.mail.password = \n\tconfluent.metrics.topic.skip.backlog.minutes = 15\n\tconfluent.controlcenter.schema.registry.url = [http://confluent-cp-schema-registry:8081]\n\tconfluent.controlcenter.data.dir = /var/lib/confluent-control-center\n\tconfluent.license = \n\tconfluent.monitoring.interceptor.topic.skip.backlog.minutes = 15\n\tconfluent.metrics.topic.max.message.bytes = 10485760\n\tconfluent.controlcenter.broker.config.edit.enable = true\n\tconfluent.controlcenter.name = _confluent-controlcenter-5-2-0\n\tconfluent.controlcenter.auth.session.expiration.ms = 0\n\tconfluent.controlcenter.streams.producer.retries = 2147483647\n\tconfluent.controlcenter.mail.enabled = false\n\tconfluent.controlcenter.command.topic.retention.ms = 259200000\n\tconfluent.controlcenter.rest.hsts.enable = true\n\tconfluent.controlcenter.alert.cluster.down.autocreate = false\n\tconfluent.controlcenter.alert.cluster.down.to.email = \n\tconfluent.monitoring.interceptor.topic.retention.bytes = -1\n\tconfluent.controlcenter.streams.producer.retry.backoff.ms = 100\n\tconfluent.controlcenter.streams.producer.max.block.ms = 9223372036854775807\n\tconfluent.controlcenter.internal.topics.changelog.segment.bytes = 134217728\n\tconfluent.controlcenter.mail.username = \n\tconfluent.controlcenter.disk.skew.warning.min.bytes = 1073741824\n\tconfluent.controlcenter.streams.num.stream.threads = 8\n\tconfluent.controlcenter.command.topic.replication = 1\n\tconfluent.controlcenter.mail.ssl.checkserveridentity = false\n\tconfluent.controlcenter.mail.bounce.address = \n\tconfluent.controlcenter.streams.retries = 2147483647\n\tconfluent.controlcenter.license.manager = _confluent-controlcenter-license-manager-5-2-0\n\tconfluent.monitoring.interceptor.topic.replication = 1\n\tconfluent.controlcenter.streams.consumer.session.timeout.ms = 60000\n\tconfluent.metrics.topic.retention.ms = 259200000\n\tconfluent.controlcenter.mail.starttls.required = false\n\tconfluent.support.metrics.customer.id = anonymous\n\tconfluent.controlcenter.auth.restricted.roles = []\n\tconfluent.monitoring.interceptor.topic.partitions = 12\n\tconfluent.controlcenter.streams.producer.compression.type = lz4\n\tconfluent.controlcenter.ksql.url = [http://confluent-cp-ksql-server:8088]\n\tconfluent.controlcenter.license.manager.enable = true\n (io.confluent.controlcenter.ControlCenterConfig)\n[2019-10-18 14:36:02,495] INFO StreamsConfig values: \n\tapplication.id = _confluent-controlcenter-5-2-0-1\n\tapplication.server = \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffered.records.per.partition = 100\n\tcache.max.bytes.buffering = 1073741824\n\tclient.id = \n\tcommit.interval.ms = 30000\n\tconnections.max.idle.ms = 540000\n\tdefault.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndContinueExceptionHandler\n\tdefault.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tdefault.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler\n\tdefault.timestamp.extractor = class io.confluent.controlcenter.streams.WindowExtractor\n\tdefault.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tmax.task.idle.ms = 0\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tnum.standby.replicas = 0\n\tnum.stream.threads = 8\n\tpartition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper\n\tpoll.ms = 100\n\tprocessing.guarantee = at_least_once\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\treplication.factor = 1\n\trequest.timeout.ms = 40000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\trocksdb.config.setter = class io.confluent.controlcenter.streams.RocksDBConfigurator\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tstate.cleanup.delay.ms = 600000\n\tstate.dir = /var/lib/confluent-control-center/1/kafka-streams\n\ttopology.optimization = all\n\tupgrade.from = null\n\twindowstore.changelog.additional.retention.ms = 86400000\n (org.apache.kafka.streams.StreamsConfig)\n[2019-10-18 14:36:08,578] INFO setting topic names _confluent-monitoring (io.confluent.controlcenter.streams.WindowExtractor)\n[2019-10-18 14:36:08,672] INFO transformerStore=MonitoringVerifierStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,761] INFO transformerStore=MonitoringTriggerStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,772] INFO transformerStore=TriggerActionsStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,772] INFO transformerStore=TriggerEventsStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:08,772] INFO transformerStore=AlertHistoryStore (io.confluent.controlcenter.streams.StreamsModule)\n[2019-10-18 14:36:09,252] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = confluent-control-center-heartbeat-sender-1\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 1\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 10\n\tretry.backoff.ms = 500\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:36:10,909] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:10,922] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:13,013] INFO StreamsConfig values: \n\tapplication.id = _confluent-controlcenter-5-2-0-1-command\n\tapplication.server = \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffered.records.per.partition = 1000\n\tcache.max.bytes.buffering = 0\n\tclient.id = \n\tcommit.interval.ms = 30000\n\tconnections.max.idle.ms = 540000\n\tdefault.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler\n\tdefault.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tdefault.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler\n\tdefault.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp\n\tdefault.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde\n\tmax.task.idle.ms = 0\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tnum.standby.replicas = 0\n\tnum.stream.threads = 1\n\tpartition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper\n\tpoll.ms = 100\n\tprocessing.guarantee = at_least_once\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\treplication.factor = 1\n\trequest.timeout.ms = 40000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\trocksdb.config.setter = null\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tstate.cleanup.delay.ms = 600000\n\tstate.dir = /var/lib/confluent-control-center/1/cp-command\n\ttopology.optimization = all\n\tupgrade.from = null\n\twindowstore.changelog.additional.retention.ms = 86400000\n (org.apache.kafka.streams.StreamsConfig)\n[2019-10-18 14:36:15,641] INFO AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-admin\n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:17,876] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:17,876] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:18,103] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:36:18,251] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = none\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 2147483647\n\tmax.poll.records = 1000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:20,661] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:20,661] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:20,708] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:36:20,790] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Creating shared producer client (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:36:20,827] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-producer\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:36:21,108] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:21,108] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:21,668] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:36:21,697] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = none\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = _confluent-controlcenter-5-2-0-1-command\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 2147483647\n\tmax.poll.records = 1000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:23,172] WARN The configuration 'admin.retries' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:23,182] WARN The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:36:23,187] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:23,188] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:23,513] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:36:23,617] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = c3-command\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class io.confluent.serializers.ProtoSerde\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class io.confluent.serializers.ProtoSerde\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:36:23,981] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:23,981] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:24,634] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:36:25,064] INFO RestConfig values: \n\tmetric.reporters = []\n\tssl.client.auth = false\n\trest.servlet.initializor.classes = []\n\tresponse.mediatype.default = application/json\n\twebsocket.path.prefix = /ws\n\tresource.extension.classes = []\n\tauthentication.realm = \n\tssl.keystore.type = JKS\n\tssl.trustmanager.algorithm = \n\tauthentication.method = NONE\n\tmetrics.jmx.prefix = rest-utils\n\trequest.logger.name = io.confluent.rest-utils.requests\n\tssl.key.password = [hidden]\n\tssl.truststore.password = [hidden]\n\tauthentication.roles = [*]\n\tmetrics.num.samples = 2\n\tssl.endpoint.identification.algorithm = \n\tcompression.enable = true\n\tssl.protocol = TLS\n\tdebug = false\n\tlisteners = []\n\tssl.provider = \n\tssl.enabled.protocols = []\n\tshutdown.graceful.ms = 1000\n\tssl.keystore.location = \n\tresponse.mediatype.preferred = [application/json]\n\tssl.cipher.suites = []\n\tauthentication.skip.paths = []\n\tssl.truststore.type = JKS\n\twebsocket.servlet.initializor.classes = []\n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tssl.truststore.location = \n\tssl.keystore.password = [hidden]\n\tssl.keymanager.algorithm = \n\tport = 9021\n\taccess.control.allow.headers = \n\tmetrics.sample.window.ms = 30000\n\tmetrics.tag.map = {}\n (io.confluent.rest.RestConfig)\n[2019-10-18 14:36:27,147] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,437] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,448] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,477] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:27,909] INFO intermediateTopics=[_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,421] INFO CONTROL CENTER UI\n\nBy using Control Center, subject to any license you may have with Confluent, you agree to the Confluent Data Protection Agreement.  In particular, please note that the version check feature of Control Center is enabled.\n\nWith this enabled, this instance is configured to collect and report certain data (version information, time stamped session IDs, instance ID, instance uptime, license key for subscription customers, IP address, and other product data)  to Confluent, Inc. (\"Confluent\") or its parent, subsidiaries, affiliates or service providers every hour.  By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer and use of Version information by Confluent. You can turn the version check feature off by setting `confluent.support.metrics.enable=false` in the Control Center configuration and restarting Control Center.  See the Confluent Enterprise documentation for further information.\n (io.confluent.controlcenter.healthcheck.HealthCheck)\n[2019-10-18 14:36:28,703] INFO Starting Control Center version=5.2.0 (io.confluent.controlcenter.ControlCenter)\n[2019-10-18 14:36:28,801] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,825] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,856] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:28,875] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:29,007] INFO intermediateTopics=[_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)\n[2019-10-18 14:36:29,031] INFO AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,336] WARN The configuration 'consumer.session.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,359] WARN The configuration 'producer.linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,397] WARN The configuration 'producer.delivery.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,411] WARN The configuration 'producer.max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,433] WARN The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,459] WARN The configuration 'producer.retries' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,482] WARN The configuration 'producer.compression.type' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,483] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,499] WARN The configuration 'num.stream.threads' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:36:29,499] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:29,499] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:36:30,386] INFO topicListings=[] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:36:30,415] INFO missingTopics=[_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-metrics, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-command, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-monitoring, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:36:30,507] INFO extantTopics=[] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:36:54,863] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:39:01,432] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:40:19,263] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:41:43,325] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-cluster-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:41:59,231] ERROR attempt=failed to create topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-stream-extension-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\njava.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.confluent.controlcenter.KafkaHelper.checkCreateTopics(KafkaHelper.java:259)\n\tat io.confluent.controlcenter.KafkaHelper.access$200(KafkaHelper.java:56)\n\tat io.confluent.controlcenter.KafkaHelper$ControlCenterPreconditions.call(KafkaHelper.java:694)\n\tat io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:121)\n[2019-10-18 14:41:59,277] INFO describing topics=[_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, _confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-metrics, _confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, _confluent-command, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, _confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, _confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, _confluent-monitoring, _confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-2-0-1-cluster-rekey, _confluent-controlcenter-5-2-0-1-group-stream-extension-rekey] (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,877] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-actual-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,919] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,920] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-aggregate-store-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,920] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-Group-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,921] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringVerifierStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,921] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-metrics-trigger-measurement-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,923] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-TriggerEventsStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:41:59,987] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregate-topic-partition-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,009] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,030] INFO create=success topic=TopicInfo{name=_confluent-metrics, partitions=12, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,091] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MetricsAggregateStore-repartition, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,096] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-aggregate-rekey-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,096] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,210] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-aggregate-store-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringStream-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringTriggerStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,211] INFO create=success topic=TopicInfo{name=_confluent-command, partitions=1, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,212] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,214] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-message-rekey-store, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,215] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringStream-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,254] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-expected-group-consumption-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,258] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,259] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-TriggerActionsStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,260] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-AlertHistoryStore-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,271] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-Group-ONE_MINUTE-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,275] INFO create=success topic=TopicInfo{name=_confluent-monitoring, partitions=12, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,287] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-monitoring-trigger-event-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,291] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,296] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-cluster-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,300] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-2-0-1-group-stream-extension-rekey, partitions=4, replication=1} (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:00,453] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = latest\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = will-delete-this\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = _confluent-controlcenter-5-2-0-1\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 21600000\n\tmax.poll.records = 100\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:42:00,869] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:42:00,870] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:42:00,981] INFO Setting offsets for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:01,315] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:42:01,529] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Subscribed to partition(s): _confluent-monitoring-11, _confluent-monitoring-10, _confluent-monitoring-9, _confluent-monitoring-8, _confluent-monitoring-3, _confluent-monitoring-2, _confluent-monitoring-1, _confluent-monitoring-0, _confluent-monitoring-7, _confluent-monitoring-6, _confluent-monitoring-5, _confluent-monitoring-4 (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:42:01,753] INFO found 12 topicPartitions for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:02,599] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-11 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,620] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-10 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,630] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-9 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,631] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-8 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,631] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-3 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,641] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-2 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,647] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-1 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,650] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,650] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-7 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,652] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-6 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,656] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-5 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:02,657] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Resetting offset for partition _confluent-monitoring-4 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:42:03,175] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Discovered group coordinator confluent-cp-kafka-0.confluent-cp-kafka-headless.testspace:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:42:03,916] INFO Setting offsets for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:04,054] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-2-0-1] Subscribed to partition(s): _confluent-metrics-11, _confluent-metrics-9, _confluent-metrics-10, _confluent-metrics-7, _confluent-metrics-8, _confluent-metrics-5, _confluent-metrics-6, _confluent-metrics-3, _confluent-metrics-4, _confluent-metrics-1, _confluent-metrics-2, _confluent-metrics-0 (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:42:04,094] INFO found 12 topicPartitions for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)\n[2019-10-18 14:42:05,843] INFO action=starting topology=command (io.confluent.controlcenter.ControlCenter)\n[2019-10-18 14:42:06,193] INFO stream-client [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams)\n[2019-10-18 14:42:06,234] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:42:06,266] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:42:06,329] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:42:06,495] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Subscribed to pattern: '_confluent-command' (org.apache.kafka.clients.consumer.KafkaConsumer)\nrpc error: code = DeadlineExceeded desc = context deadline exceeded[2019-10-18 14:46:32,591] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:33,703] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:34,710] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:35,719] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:36,189] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:46:36,200] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Discovered group coordinator confluent-cp-kafka-0.confluent-cp-kafka-headless.testspace:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:36,709] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:37,665] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-18 14:46:37,675] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:37,705] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:46:37,708] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] partition revocation took 27 ms.\n\tsuspended active tasks: []\n\tsuspended standby tasks: [] (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:37,708] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:37,715] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:46,056] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:46,079] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:47,059] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:48,061] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:49,102] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:50,259] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:50,359] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer] Assigned tasks to clients as {2fade159-3e58-4692-9df6-f6c0d5ac390b=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor)\n[2019-10-18 14:46:51,521] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:51,624] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-18 14:46:52,194] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Setting newly assigned partitions: _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-18 14:46:52,209] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:52,785] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:53,810] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:53,976] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] partition assignment took 1767 ms.\n\tcurrent active tasks: [0_0]\n\tcurrent standby tasks: []\n\tprevious active tasks: []\n (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:54,859] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:55,859] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:56,947] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:57,480] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:46:57,965] INFO unable to get command store (io.confluent.command.CommandStore)\n[2019-10-18 14:46:58,156] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:46:58,302] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:46:58,322] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:58,428] INFO stream-client [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams)\n[2019-10-18 14:46:58,531] INFO stream-thread [_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1] Setting topic '_confluent-command' to consume from earliest offset (org.apache.kafka.streams.processor.internals.StreamThread)\n[2019-10-18 14:46:58,570] INFO [Consumer clientId=_confluent-controlcenter-5-2-0-1-command-2fade159-3e58-4692-9df6-f6c0d5ac390b-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-2-0-1-command] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:47:00,009] INFO action=started topology=command (io.confluent.controlcenter.ControlCenter)\n[2019-10-18 14:47:11,003] INFO RestConfig values: \n\tmetric.reporters = []\n\tssl.client.auth = false\n\trest.servlet.initializor.classes = []\n\tresponse.mediatype.default = application/json\n\twebsocket.path.prefix = /ws\n\tresource.extension.classes = []\n\tauthentication.realm = \n\tssl.keystore.type = JKS\n\tssl.trustmanager.algorithm = \n\tauthentication.method = NONE\n\tmetrics.jmx.prefix = rest-utils\n\trequest.logger.name = io.confluent.rest-utils.requests\n\tssl.key.password = [hidden]\n\tssl.truststore.password = [hidden]\n\tauthentication.roles = [*]\n\tmetrics.num.samples = 2\n\tssl.endpoint.identification.algorithm = \n\tcompression.enable = true\n\tssl.protocol = TLS\n\tdebug = false\n\tlisteners = []\n\tssl.provider = \n\tssl.enabled.protocols = []\n\tshutdown.graceful.ms = 1000\n\tssl.keystore.location = \n\tresponse.mediatype.preferred = [application/json]\n\tssl.cipher.suites = []\n\tauthentication.skip.paths = []\n\tssl.truststore.type = JKS\n\twebsocket.servlet.initializor.classes = []\n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tssl.truststore.location = \n\tssl.keystore.password = [hidden]\n\tssl.keymanager.algorithm = \n\tport = 9021\n\taccess.control.allow.headers = \n\tmetrics.sample.window.ms = 30000\n\tmetrics.tag.map = {}\n (io.confluent.rest.RestConfig)\n[2019-10-18 14:47:11,098] WARN Configuration 'confluent.controlcenter.ksql.url' is deprecated. Configure new ksql clusters with 'confluent.controlcenter.ksql.<name>.url'. Please see documentation for more details. (io.confluent.controlcenter.ksql.KsqlClusterMetadata)\n[2019-10-18 14:47:18,247] INFO Starting License Store (io.confluent.license.LicenseStore)\n[2019-10-18 14:47:18,254] INFO Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\n[2019-10-18 14:47:18,413] INFO AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-license-manager-5-2-0-1\n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:47:18,539] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)\n[2019-10-18 14:47:18,641] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:18,641] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:19,682] INFO ProducerConfig values: \n\tacks = all\n\tbatch.size = 16384\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-license-manager-5-2-0-1\n\tcompression.type = lz4\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 2147483647\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde\n\tlinger.ms = 500\n\tmax.block.ms = 9223372036854775807\n\tmax.in.flight.requests.per.connection = 1\n\tmax.request.size = 10485760\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde\n (org.apache.kafka.clients.producer.ProducerConfig)\n[2019-10-18 14:47:20,067] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,067] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,072] INFO ConsumerConfig values: \n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = earliest\n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = default\n\tclient.id = _confluent-controlcenter-license-manager-5-2-0-1-global-consumer\n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 21600000\n\tmax.poll.records = 100\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 60000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde\n (org.apache.kafka.clients.consumer.ConsumerConfig)\n[2019-10-18 14:47:20,284] INFO Kafka version: 2.2.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,284] INFO Kafka commitId: 791cbaddb04cb48c (org.apache.kafka.common.utils.AppInfoParser)\n[2019-10-18 14:47:20,321] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:47:20,576] INFO Cluster ID: YOMds9LYTiq0iESkfr_alg (org.apache.kafka.clients.Metadata)\n[2019-10-18 14:47:20,890] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-2-0-1-global-consumer, groupId=null] Subscribed to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-18 14:47:22,951] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-2-0-1-global-consumer, groupId=null] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-18 14:47:22,992] INFO Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\n[2019-10-18 14:47:22,993] INFO Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)\n[2019-10-18 14:47:22,994] INFO Started License Store (io.confluent.license.LicenseStore)\n",
      "CrashLog": "===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n===> Check if /etc/confluent-control-center is writable ...\n===> Check if /var/lib/confluent-control-center is writable ...\n===> Running preflight checks ... \n===> Check if Kafka is healthy ...\n[main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n\tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n\tclient.dns.lookup = default\n\tclient.id = \n\tconnections.max.idle.ms = 300000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 120000\n\tretries = 5\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.mechanism = GSSAPI\n\tsecurity.protocol = PLAINTEXT\n\tsend.buffer.bytes = 131072\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n\tssl.endpoint.identification.algorithm = https\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLS\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n[main] WARN org.apache.kafka.clients.ClientUtils - Couldn't resolve server PLAINTEXT://confluent-cp-kafka-headless:9092 from bootstrap.servers as DNS resolution failed for confluent-cp-kafka-headless\n[main] ERROR io.confluent.admin.utils.cli.KafkaReadyCommand - Error while running kafka-ready.\norg.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:386)\n\tat org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:65)\n\tat io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:138)\n\tat io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:150)\nCaused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)\n\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:346)\n\t... 3 more\n===> ENV Variables ...\nALLOW_UNSIGNED=false\nCOMPONENT=control-center\nCONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\nCONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\nCONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\nCONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\nCONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\nCONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\nCONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\nCONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\nCONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\nCONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\nCONFLUENT_CP_KAFKA_SERVICE_PORT=9092\nCONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\nCONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\nCONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\nCONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\nCONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\nCONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\nCONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\nCONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\nCONFLUENT_DEB_VERSION=1\nCONFLUENT_MAJOR_VERSION=5\nCONFLUENT_MINOR_VERSION=2\nCONFLUENT_MVN_LABEL=\nCONFLUENT_PATCH_VERSION=0\nCONFLUENT_PLATFORM_LABEL=\nCONFLUENT_VERSION=5.2.0\nCONTROL_CENTER_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\nCONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center\nCONTROL_CENTER_CONNECT_CLUSTER=http://confluent-cp-kafka-connect:8083\nCONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center\nCONTROL_CENTER_KSQL_ADVERTISED_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_KSQL_URL=http://confluent-cp-ksql-server:8088\nCONTROL_CENTER_REPLICATION_FACTOR=1\nCONTROL_CENTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\nCONTROL_CENTER_ZOOKEEPER_CONNECT=\nCUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\nHOME=/root\nHOSTNAME=confluent-cp-control-center-965bb95cd-5fndx\nKAFKA_HEAP_OPTS=-Xms512M -Xmx512M\nKAFKA_VERSION=2.2.0cp1\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nLANG=C.UTF-8\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nPYTHON_PIP_VERSION=8.1.2\nPYTHON_VERSION=2.7.9-1\nSCALA_VERSION=2.11\nSHLVL=1\nZULU_OPENJDK_VERSION=8=8.30.0.1\n_=/usr/bin/env\n===> User\nuid=0(root) gid=0(root) groups=0(root)\n===> Configuring ...\n"
    },
    {
      "Name": "confluent-cp-kafka-connect",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:27.568979-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:26.683439-04:00",
          "FinishTime": "2019-10-18T10:29:27.568976-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-kafka-connect\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-connect:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-connect:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.884s\n\u001b[34m  │ \u001b[0mDone in: 0.884s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "confluent-cp-kafka-connect-df6b4f496-p9rtm",
      "K8sResourceInfo": {
        "PodName": "confluent-cp-kafka-connect-df6b4f496-p9rtm",
        "PodCreationTime": "2019-10-18T10:29:27-04:00",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "Running",
        "PodStatusMessage": "",
        "AllContainersReady": true,
        "PodRestarts": 0,
        "PodLog": "[prometheus-jmx-exporter] VM settings:\n[prometheus-jmx-exporter]     Max. Heap Size (Estimated): 1.74G\n[prometheus-jmx-exporter]     Ergonomics Machine Class: server\n[prometheus-jmx-exporter]     Using VM: OpenJDK 64-Bit Server VM\n[prometheus-jmx-exporter] \n[cp-kafka-connect-server] ===> ENV Variables ...\n[cp-kafka-connect-server] ALLOW_UNSIGNED=false\n[cp-kafka-connect-server] COMPONENT=kafka-connect\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\n[cp-kafka-connect-server] CONFLUENT_DEB_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_MAJOR_VERSION=5\n[cp-kafka-connect-server] CONFLUENT_MINOR_VERSION=3\n[cp-kafka-connect-server] CONFLUENT_MVN_LABEL=\n[cp-kafka-connect-server] CONFLUENT_PATCH_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_PLATFORM_LABEL=\n[cp-kafka-connect-server] CONFLUENT_VERSION=5.3.1\n[cp-kafka-connect-server] CONNECT_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_TOPIC=confluent-cp-kafka-connect-config\n[cp-kafka-connect-server] CONNECT_GROUP_ID=confluent\n[cp-kafka-connect-server] CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_TOPIC=confluent-cp-kafka-connect-offset\n[cp-kafka-connect-server] CONNECT_PLUGIN_PATH=/usr/share/java,/usr/share/confluent-hub-components\n[cp-kafka-connect-server] CONNECT_REST_ADVERTISED_HOST_NAME=10.1.0.6\n[cp-kafka-connect-server] CONNECT_REST_PORT=8083\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_TOPIC=confluent-cp-kafka-connect-status\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\n[cp-kafka-connect-server] HOME=/root\n[cp-kafka-connect-server] HOSTNAME=confluent-cp-kafka-connect-df6b4f496-p9rtm\n[cp-kafka-connect-server] KAFKA_ADVERTISED_LISTENERS=\n[cp-kafka-connect-server] KAFKA_HEAP_OPTS=-Xms512M -Xmx512M\n[cp-kafka-connect-server] KAFKA_JMX_PORT=5555\n[cp-kafka-connect-server] KAFKA_VERSION=5.3.1\n[cp-kafka-connect-server] KAFKA_ZOOKEEPER_CONNECT=\n[cp-kafka-connect-server] KUBERNETES_PORT=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PORT=443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PROTO=tcp\n[cp-kafka-connect-server] KUBERNETES_SERVICE_HOST=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT=443\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT_HTTPS=443\n[cp-kafka-connect-server] LANG=C.UTF-8\n[cp-kafka-connect-server] PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n[cp-kafka-connect-server] PWD=/\n[cp-kafka-connect-server] PYTHON_PIP_VERSION=8.1.2\n[cp-kafka-connect-server] PYTHON_VERSION=2.7.9-1\n[cp-kafka-connect-server] SCALA_VERSION=2.12\n[cp-kafka-connect-server] SHLVL=1\n[cp-kafka-connect-server] ZULU_OPENJDK_VERSION=8=8.38.0.13\n[cp-kafka-connect-server] _=/usr/bin/env\n[cp-kafka-connect-server] ===> User\n[cp-kafka-connect-server] uid=0(root) gid=0(root) groups=0(root)\n[cp-kafka-connect-server] ===> Configuring ...\n[cp-kafka-connect-server] ===> Running preflight checks ... \n[cp-kafka-connect-server] ===> Check if Kafka is healthy ...\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n[cp-kafka-connect-server] \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n[cp-kafka-connect-server] \tclient.dns.lookup = default\n[cp-kafka-connect-server] \tclient.id = \n[cp-kafka-connect-server] \tconnections.max.idle.ms = 300000\n[cp-kafka-connect-server] \tmetadata.max.age.ms = 300000\n[cp-kafka-connect-server] \tmetric.reporters = []\n[cp-kafka-connect-server] \tmetrics.num.samples = 2\n[cp-kafka-connect-server] \tmetrics.recording.level = INFO\n[cp-kafka-connect-server] \tmetrics.sample.window.ms = 30000\n[cp-kafka-connect-server] \treceive.buffer.bytes = 65536\n[cp-kafka-connect-server] \treconnect.backoff.max.ms = 1000\n[cp-kafka-connect-server] \treconnect.backoff.ms = 50\n[cp-kafka-connect-server] \trequest.timeout.ms = 120000\n[cp-kafka-connect-server] \tretries = 5\n[cp-kafka-connect-server] \tretry.backoff.ms = 100\n[cp-kafka-connect-server] \tsasl.client.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.jaas.config = null\n[cp-kafka-connect-server] \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n[cp-kafka-connect-server] \tsasl.kerberos.min.time.before.relogin = 60000\n[cp-kafka-connect-server] \tsasl.kerberos.service.name = null\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.login.class = null\n[cp-kafka-connect-server] \tsasl.login.refresh.buffer.seconds = 300\n[cp-kafka-connect-server] \tsasl.login.refresh.min.period.seconds = 60\n[cp-kafka-connect-server] \tsasl.login.refresh.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.refresh.window.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.mechanism = GSSAPI\n[cp-kafka-connect-server] \tsecurity.protocol = PLAINTEXT\n[cp-kafka-connect-server] \tsend.buffer.bytes = 131072\n[cp-kafka-connect-server] \tssl.cipher.suites = null\n[cp-kafka-connect-server] \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n[cp-kafka-connect-server] \tssl.endpoint.identification.algorithm = https\n[cp-kafka-connect-server] \tssl.key.password = null\n[cp-kafka-connect-server] \tssl.keymanager.algorithm = SunX509\n[cp-kafka-connect-server] \tssl.keystore.location = null\n[cp-kafka-connect-server] \tssl.keystore.password = null\n[cp-kafka-connect-server] \tssl.keystore.type = JKS\n[cp-kafka-connect-server] \tssl.protocol = TLS\n[cp-kafka-connect-server] \tssl.provider = null\n[cp-kafka-connect-server] \tssl.secure.random.implementation = null\n[cp-kafka-connect-server] \tssl.trustmanager.algorithm = PKIX\n[cp-kafka-connect-server] \tssl.truststore.location = null\n[cp-kafka-connect-server] \tssl.truststore.password = null\n[cp-kafka-connect-server] \tssl.truststore.type = JKS\n[cp-kafka-connect-server] \n[cp-kafka-connect-server] [main] WARN org.apache.kafka.clients.ClientUtils - Couldn't resolve server PLAINTEXT://confluent-cp-kafka-headless:9092 from bootstrap.servers as DNS resolution failed for confluent-cp-kafka-headless\n[cp-kafka-connect-server] [main] ERROR io.confluent.admin.utils.cli.KafkaReadyCommand - Error while running kafka-ready.\n[cp-kafka-connect-server] org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:407)\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:65)\n[cp-kafka-connect-server] \tat io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:138)\n[cp-kafka-connect-server] \tat io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:150)\n[cp-kafka-connect-server] Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:88)\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:47)\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:367)\n[cp-kafka-connect-server] \t... 3 more\n[cp-kafka-connect-server] Unable to retrieve container logs for docker://b3fbace1640d851d5d3cf4f083ba88e8fcdba200069ceadddf87d70f4f2cf1ef[cp-kafka-connect-server] ===> ENV Variables ...\n[cp-kafka-connect-server] ALLOW_UNSIGNED=false\n[cp-kafka-connect-server] COMPONENT=kafka-connect\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\n[cp-kafka-connect-server] CONFLUENT_DEB_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_MAJOR_VERSION=5\n[cp-kafka-connect-server] CONFLUENT_MINOR_VERSION=3\n[cp-kafka-connect-server] CONFLUENT_MVN_LABEL=\n[cp-kafka-connect-server] CONFLUENT_PATCH_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_PLATFORM_LABEL=\n[cp-kafka-connect-server] CONFLUENT_VERSION=5.3.1\n[cp-kafka-connect-server] CONNECT_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_TOPIC=confluent-cp-kafka-connect-config\n[cp-kafka-connect-server] CONNECT_GROUP_ID=confluent\n[cp-kafka-connect-server] CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_TOPIC=confluent-cp-kafka-connect-offset\n[cp-kafka-connect-server] CONNECT_PLUGIN_PATH=/usr/share/java,/usr/share/confluent-hub-components\n[cp-kafka-connect-server] CONNECT_REST_ADVERTISED_HOST_NAME=10.1.0.6\n[cp-kafka-connect-server] CONNECT_REST_PORT=8083\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_TOPIC=confluent-cp-kafka-connect-status\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\n[cp-kafka-connect-server] HOME=/root\n[cp-kafka-connect-server] HOSTNAME=confluent-cp-kafka-connect-df6b4f496-p9rtm\n[cp-kafka-connect-server] KAFKA_ADVERTISED_LISTENERS=\n[cp-kafka-connect-server] KAFKA_HEAP_OPTS=-Xms512M -Xmx512M\n[cp-kafka-connect-server] KAFKA_JMX_PORT=5555\n[cp-kafka-connect-server] KAFKA_VERSION=5.3.1\n[cp-kafka-connect-server] KAFKA_ZOOKEEPER_CONNECT=\n[cp-kafka-connect-server] KUBERNETES_PORT=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PORT=443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PROTO=tcp\n[cp-kafka-connect-server] KUBERNETES_SERVICE_HOST=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT=443\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT_HTTPS=443\n[cp-kafka-connect-server] LANG=C.UTF-8\n[cp-kafka-connect-server] PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n[cp-kafka-connect-server] PWD=/\n[cp-kafka-connect-server] PYTHON_PIP_VERSION=8.1.2\n[cp-kafka-connect-server] PYTHON_VERSION=2.7.9-1\n[cp-kafka-connect-server] SCALA_VERSION=2.12\n[cp-kafka-connect-server] SHLVL=1\n[cp-kafka-connect-server] ZULU_OPENJDK_VERSION=8=8.38.0.13\n[cp-kafka-connect-server] _=/usr/bin/env\n[cp-kafka-connect-server] ===> User\n[cp-kafka-connect-server] uid=0(root) gid=0(root) groups=0(root)\n[cp-kafka-connect-server] ===> Configuring ...\n[cp-kafka-connect-server] ===> Running preflight checks ... \n[cp-kafka-connect-server] ===> Check if Kafka is healthy ...\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n[cp-kafka-connect-server] \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n[cp-kafka-connect-server] \tclient.dns.lookup = default\n[cp-kafka-connect-server] \tclient.id = \n[cp-kafka-connect-server] \tconnections.max.idle.ms = 300000\n[cp-kafka-connect-server] \tmetadata.max.age.ms = 300000\n[cp-kafka-connect-server] \tmetric.reporters = []\n[cp-kafka-connect-server] \tmetrics.num.samples = 2\n[cp-kafka-connect-server] \tmetrics.recording.level = INFO\n[cp-kafka-connect-server] \tmetrics.sample.window.ms = 30000\n[cp-kafka-connect-server] \treceive.buffer.bytes = 65536\n[cp-kafka-connect-server] \treconnect.backoff.max.ms = 1000\n[cp-kafka-connect-server] \treconnect.backoff.ms = 50\n[cp-kafka-connect-server] \trequest.timeout.ms = 120000\n[cp-kafka-connect-server] \tretries = 5\n[cp-kafka-connect-server] \tretry.backoff.ms = 100\n[cp-kafka-connect-server] \tsasl.client.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.jaas.config = null\n[cp-kafka-connect-server] \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n[cp-kafka-connect-server] \tsasl.kerberos.min.time.before.relogin = 60000\n[cp-kafka-connect-server] \tsasl.kerberos.service.name = null\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.login.class = null\n[cp-kafka-connect-server] \tsasl.login.refresh.buffer.seconds = 300\n[cp-kafka-connect-server] \tsasl.login.refresh.min.period.seconds = 60\n[cp-kafka-connect-server] \tsasl.login.refresh.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.refresh.window.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.mechanism = GSSAPI\n[cp-kafka-connect-server] \tsecurity.protocol = PLAINTEXT\n[cp-kafka-connect-server] \tsend.buffer.bytes = 131072\n[cp-kafka-connect-server] \tssl.cipher.suites = null\n[cp-kafka-connect-server] \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n[cp-kafka-connect-server] \tssl.endpoint.identification.algorithm = https\n[cp-kafka-connect-server] \tssl.key.password = null\n[cp-kafka-connect-server] \tssl.keymanager.algorithm = SunX509\n[cp-kafka-connect-server] \tssl.keystore.location = null\n[cp-kafka-connect-server] \tssl.keystore.password = null\n[cp-kafka-connect-server] \tssl.keystore.type = JKS\n[cp-kafka-connect-server] \tssl.protocol = TLS\n[cp-kafka-connect-server] \tssl.provider = null\n[cp-kafka-connect-server] \tssl.secure.random.implementation = null\n[cp-kafka-connect-server] \tssl.trustmanager.algorithm = PKIX\n[cp-kafka-connect-server] \tssl.truststore.location = null\n[cp-kafka-connect-server] \tssl.truststore.password = null\n[cp-kafka-connect-server] \tssl.truststore.type = JKS\n[cp-kafka-connect-server] \n[cp-kafka-connect-server] [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1571409302393\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] ===> Launching ... \n[cp-kafka-connect-server] ===> Launching kafka-connect ... \n[cp-kafka-connect-server] [2019-10-18 14:35:33,474] INFO WorkerInfo values: \n[cp-kafka-connect-server] \tjvm.args = -Xms512M, -Xmx512M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Djava.rmi.server.hostname=10.1.0.6, -Dcom.sun.management.jmxremote.local.only=false, -Dcom.sun.management.jmxremote.rmi.port=5555, -Dcom.sun.management.jmxremote.port=5555, -Dcom.sun.management.jmxremote.port=5555, -Dkafka.logs.dir=/var/log/kafka, -Dlog4j.configuration=file:/etc/kafka/connect-log4j.properties\n[cp-kafka-connect-server] \tjvm.spec = Azul Systems, Inc., OpenJDK 64-Bit Server VM, 1.8.0_212, 25.212-b04\n[cp-kafka-connect-server] \tjvm.classpath = /etc/kafka-connect/jars/*:/usr/share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/share/java/kafka/httpclient-4.5.7.jar:/usr/share/java/kafka/audience-annotations-0.5.0.jar:/usr/share/java/kafka/reflections-0.9.11.jar:/usr/share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/share/java/kafka/javassist-3.22.0-CR2.jar:/usr/share/java/kafka/validation-api-2.0.1.Final.jar:/usr/share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/share/java/kafka/jsr305-3.0.2.jar:/usr/share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/share/java/kafka/paranamer-2.8.jar:/usr/share/java/kafka/paranamer-2.7.jar:/usr/share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/share/java/kafka/jersey-server-2.28.jar:/usr/share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/share/java/kafka/hk2-utils-2.5.0.jar:/usr/share/java/kafka/maven-artifact-3.6.1.jar:/usr/share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/share/java/kafka/commons-codec-1.11.jar:/usr/share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/share/java/kafka/hk2-locator-2.5.0.jar:/usr/share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/share/java/kafka/commons-logging-1.2.jar:/usr/share/java/kafka/jopt-simple-5.0.4.jar:/usr/share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/share/java/kafka/zookeeper-3.4.14.jar:/usr/share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/share/java/kafka/httpmime-4.5.7.jar:/usr/share/java/kafka/lz4-java-1.6.0.jar:/usr/share/java/kafka/argparse4j-0.7.0.jar:/usr/share/java/kafka/jersey-client-2.28.jar:/usr/share/java/kafka/jackson-annotations-2.9.9.jar:/usr/share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/share/java/kafka/jersey-hk2-2.28.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/share/java/kafka/avro-1.8.1.jar:/usr/share/java/kafka/slf4j-api-1.7.26.jar:/usr/share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-core-2.9.9.jar:/usr/share/java/kafka/httpcore-4.4.11.jar:/usr/share/java/kafka/plexus-utils-3.2.0.jar:/usr/share/java/kafka/commons-compress-1.8.1.jar:/usr/share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/share/java/kafka/hk2-api-2.5.0.jar:/usr/share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/share/java/kafka/metrics-core-2.2.0.jar:/usr/share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/share/java/kafka/scala-reflect-2.12.8.jar:/usr/share/java/kafka/snappy-java-1.1.7.3.jar:/usr/share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/share/java/kafka/jersey-container-servlet-2.28.jar:/usr/share/java/kafka/zkclient-0.11.jar:/usr/share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/share/java/kafka/kafka.jar:/usr/share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/share/java/kafka/log4j-1.2.17.jar:/usr/share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/share/java/kafka/guava-20.0.jar:/usr/share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/share/java/kafka/commons-lang3-3.8.1.jar:/usr/share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/share/java/kafka/jaxb-api-2.3.0.jar:/usr/share/java/kafka/rocksdbjni-5.18.3.jar:/usr/share/java/kafka/activation-1.1.1.jar:/usr/share/java/kafka/scala-library-2.12.8.jar:/usr/share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/share/java/kafka/xz-1.5.jar:/usr/share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/share/java/kafka/jakarta.inject-2.5.0.jar:/usr/share/java/kafka/jersey-common-2.28.jar:/usr/share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/share/java/confluent-common/common-utils-5.3.1.jar:/usr/share/java/confluent-common/audience-annotations-0.5.0.jar:/usr/share/java/confluent-common/spotbugs-annotations-3.1.8.jar:/usr/share/java/confluent-common/zkclient-0.10.jar:/usr/share/java/confluent-common/jsr305-3.0.2.jar:/usr/share/java/confluent-common/jline-0.9.94.jar:/usr/share/java/confluent-common/netty-3.10.6.Final.jar:/usr/share/java/confluent-common/common-metrics-5.3.1.jar:/usr/share/java/confluent-common/zookeeper-3.4.14.jar:/usr/share/java/confluent-common/slf4j-api-1.7.26.jar:/usr/share/java/confluent-common/build-tools-5.3.1.jar:/usr/share/java/confluent-common/common-config-5.3.1.jar:/usr/share/java/kafka-serde-tools/kafka-avro-serializer-5.3.1.jar:/usr/share/java/kafka-serde-tools/paranamer-2.7.jar:/usr/share/java/kafka-serde-tools/kafka-connect-avro-converter-5.3.1.jar:/usr/share/java/kafka-serde-tools/jackson-annotations-2.9.9.jar:/usr/share/java/kafka-serde-tools/avro-1.8.1.jar:/usr/share/java/kafka-serde-tools/jackson-core-2.9.9.jar:/usr/share/java/kafka-serde-tools/snappy-java-1.1.1.3.jar:/usr/share/java/kafka-serde-tools/commons-compress-1.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-json-serializer-5.3.1.jar:/usr/share/java/kafka-serde-tools/kafka-streams-avro-serde-5.3.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-5.3.1.jar:/usr/share/java/kafka-serde-tools/jackson-mapper-asl-1.9.13.jar:/usr/share/java/kafka-serde-tools/jackson-core-asl-1.9.13.jar:/usr/share/java/kafka-serde-tools/xz-1.5.jar:/usr/share/java/kafka-serde-tools/jackson-databind-2.9.9.3.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-5.3.1.jar:/usr/bin/../share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/httpclient-4.5.7.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/bin/../share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-server-2.28.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/usr/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-codec-1.11.jar:/usr/bin/../share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.14.jar:/usr/bin/../share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/bin/../share/java/kafka/httpmime-4.5.7.jar:/usr/bin/../share/java/kafka/lz4-java-1.6.0.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/jersey-client-2.28.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.28.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.26.jar:/usr/bin/../share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.9.jar:/usr/bin/../share/java/kafka/httpcore-4.4.11.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/scala-reflect-2.12.8.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/usr/bin/../share/java/kafka/zkclient-0.11.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/scala-library-2.12.8.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/usr/bin/../share/java/kafka/jersey-common-2.28.jar:/usr/bin/../share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/bin/../share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/bin/../support-metrics-client/build/dependant-libs-2.12/*:/usr/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/*\n[cp-kafka-connect-server] \tos.spec = Linux, amd64, 4.9.184-linuxkit\n[cp-kafka-connect-server] \tos.vcpus = 1\n[cp-kafka-connect-server]  (org.apache.kafka.connect.runtime.WorkerInfo)\n[cp-kafka-connect-server] [2019-10-18 14:35:33,704] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed)\n[cp-kafka-connect-server] [2019-10-18 14:35:34,208] INFO Loading plugin from: /usr/share/java/kafka-connect-s3 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,695] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-s3/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,782] INFO Added plugin 'io.confluent.connect.storage.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,783] INFO Added plugin 'io.confluent.connect.s3.S3SinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,783] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,783] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,863] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,863] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,863] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:20,242] INFO Loading plugin from: /usr/share/java/kafka-connect-storage-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:34,774] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-storage-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:34,789] INFO Loading plugin from: /usr/share/java/kafka-connect-jms (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:36,358] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jms/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:36,387] INFO Added plugin 'io.confluent.connect.jms.JmsSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:36,403] INFO Loading plugin from: /usr/share/java/kafka-connect-activemq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,805] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-activemq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,832] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,834] INFO Added plugin 'io.confluent.connect.activemq.ActiveMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,841] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,851] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,854] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,861] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,866] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,868] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,894] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,921] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,924] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,925] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,925] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,926] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,926] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,934] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,937] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,937] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,095] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,100] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,105] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,106] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,109] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,109] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Loading plugin from: /usr/share/java/kafka-connect-elasticsearch (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:51,281] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-elasticsearch/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:51,281] INFO Added plugin 'io.confluent.connect.elasticsearch.ElasticsearchSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:51,282] INFO Loading plugin from: /usr/share/java/kafka-connect-ibmmq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:57,689] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-ibmmq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:57,689] INFO Added plugin 'io.confluent.connect.ibm.mq.IbmMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:57,723] INFO Loading plugin from: /usr/share/java/kafka-connect-jdbc (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,284] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jdbc/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,291] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,292] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,401] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:02,110] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:02,193] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:16,462] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:16,472] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,145] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,163] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,191] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,234] INFO Added plugin 'io.confluent.kafka.secretregistry.client.config.provider.SecretConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,234] INFO Added plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,256] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:08,335] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:08,517] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:14,715] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:14,751] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:19,289] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:19,294] INFO Loading plugin from: /usr/share/java/confluent-rebalancer (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:18,923] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-rebalancer/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:18,928] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:19,540] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:19,567] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,178] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,186] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:42:04,776] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:42:04,788] INFO Loading plugin from: /usr/share/confluent-hub-components/confluentinc-kafka-connect-gcs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[prometheus-jmx-exporter] rpc error: code = DeadlineExceeded desc = context deadline exceeded[cp-kafka-connect-server] rpc error: code = DeadlineExceeded desc = context deadline exceeded[cp-kafka-connect-server] [2019-10-18 14:46:59,709] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/confluent-hub-components/confluentinc-kafka-connect-gcs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:46:59,728] INFO Added plugin 'io.confluent.connect.gcs.GcsSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n"
      },
      "RuntimeStatus": "ok",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-kafka-connect\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-connect:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-connect:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.884s\n\u001b[34m  │ \u001b[0mDone in: 0.884s \n\n[prometheus-jmx-exporter] VM settings:\n[prometheus-jmx-exporter]     Max. Heap Size (Estimated): 1.74G\n[prometheus-jmx-exporter]     Ergonomics Machine Class: server\n[prometheus-jmx-exporter]     Using VM: OpenJDK 64-Bit Server VM\n[prometheus-jmx-exporter] \n[cp-kafka-connect-server] ===> ENV Variables ...\n[cp-kafka-connect-server] ALLOW_UNSIGNED=false\n[cp-kafka-connect-server] COMPONENT=kafka-connect\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\n[cp-kafka-connect-server] CONFLUENT_DEB_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_MAJOR_VERSION=5\n[cp-kafka-connect-server] CONFLUENT_MINOR_VERSION=3\n[cp-kafka-connect-server] CONFLUENT_MVN_LABEL=\n[cp-kafka-connect-server] CONFLUENT_PATCH_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_PLATFORM_LABEL=\n[cp-kafka-connect-server] CONFLUENT_VERSION=5.3.1\n[cp-kafka-connect-server] CONNECT_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_TOPIC=confluent-cp-kafka-connect-config\n[cp-kafka-connect-server] CONNECT_GROUP_ID=confluent\n[cp-kafka-connect-server] CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_TOPIC=confluent-cp-kafka-connect-offset\n[cp-kafka-connect-server] CONNECT_PLUGIN_PATH=/usr/share/java,/usr/share/confluent-hub-components\n[cp-kafka-connect-server] CONNECT_REST_ADVERTISED_HOST_NAME=10.1.0.6\n[cp-kafka-connect-server] CONNECT_REST_PORT=8083\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_TOPIC=confluent-cp-kafka-connect-status\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\n[cp-kafka-connect-server] HOME=/root\n[cp-kafka-connect-server] HOSTNAME=confluent-cp-kafka-connect-df6b4f496-p9rtm\n[cp-kafka-connect-server] KAFKA_ADVERTISED_LISTENERS=\n[cp-kafka-connect-server] KAFKA_HEAP_OPTS=-Xms512M -Xmx512M\n[cp-kafka-connect-server] KAFKA_JMX_PORT=5555\n[cp-kafka-connect-server] KAFKA_VERSION=5.3.1\n[cp-kafka-connect-server] KAFKA_ZOOKEEPER_CONNECT=\n[cp-kafka-connect-server] KUBERNETES_PORT=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PORT=443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PROTO=tcp\n[cp-kafka-connect-server] KUBERNETES_SERVICE_HOST=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT=443\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT_HTTPS=443\n[cp-kafka-connect-server] LANG=C.UTF-8\n[cp-kafka-connect-server] PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n[cp-kafka-connect-server] PWD=/\n[cp-kafka-connect-server] PYTHON_PIP_VERSION=8.1.2\n[cp-kafka-connect-server] PYTHON_VERSION=2.7.9-1\n[cp-kafka-connect-server] SCALA_VERSION=2.12\n[cp-kafka-connect-server] SHLVL=1\n[cp-kafka-connect-server] ZULU_OPENJDK_VERSION=8=8.38.0.13\n[cp-kafka-connect-server] _=/usr/bin/env\n[cp-kafka-connect-server] ===> User\n[cp-kafka-connect-server] uid=0(root) gid=0(root) groups=0(root)\n[cp-kafka-connect-server] ===> Configuring ...\n[cp-kafka-connect-server] ===> Running preflight checks ... \n[cp-kafka-connect-server] ===> Check if Kafka is healthy ...\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n[cp-kafka-connect-server] \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n[cp-kafka-connect-server] \tclient.dns.lookup = default\n[cp-kafka-connect-server] \tclient.id = \n[cp-kafka-connect-server] \tconnections.max.idle.ms = 300000\n[cp-kafka-connect-server] \tmetadata.max.age.ms = 300000\n[cp-kafka-connect-server] \tmetric.reporters = []\n[cp-kafka-connect-server] \tmetrics.num.samples = 2\n[cp-kafka-connect-server] \tmetrics.recording.level = INFO\n[cp-kafka-connect-server] \tmetrics.sample.window.ms = 30000\n[cp-kafka-connect-server] \treceive.buffer.bytes = 65536\n[cp-kafka-connect-server] \treconnect.backoff.max.ms = 1000\n[cp-kafka-connect-server] \treconnect.backoff.ms = 50\n[cp-kafka-connect-server] \trequest.timeout.ms = 120000\n[cp-kafka-connect-server] \tretries = 5\n[cp-kafka-connect-server] \tretry.backoff.ms = 100\n[cp-kafka-connect-server] \tsasl.client.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.jaas.config = null\n[cp-kafka-connect-server] \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n[cp-kafka-connect-server] \tsasl.kerberos.min.time.before.relogin = 60000\n[cp-kafka-connect-server] \tsasl.kerberos.service.name = null\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.login.class = null\n[cp-kafka-connect-server] \tsasl.login.refresh.buffer.seconds = 300\n[cp-kafka-connect-server] \tsasl.login.refresh.min.period.seconds = 60\n[cp-kafka-connect-server] \tsasl.login.refresh.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.refresh.window.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.mechanism = GSSAPI\n[cp-kafka-connect-server] \tsecurity.protocol = PLAINTEXT\n[cp-kafka-connect-server] \tsend.buffer.bytes = 131072\n[cp-kafka-connect-server] \tssl.cipher.suites = null\n[cp-kafka-connect-server] \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n[cp-kafka-connect-server] \tssl.endpoint.identification.algorithm = https\n[cp-kafka-connect-server] \tssl.key.password = null\n[cp-kafka-connect-server] \tssl.keymanager.algorithm = SunX509\n[cp-kafka-connect-server] \tssl.keystore.location = null\n[cp-kafka-connect-server] \tssl.keystore.password = null\n[cp-kafka-connect-server] \tssl.keystore.type = JKS\n[cp-kafka-connect-server] \tssl.protocol = TLS\n[cp-kafka-connect-server] \tssl.provider = null\n[cp-kafka-connect-server] \tssl.secure.random.implementation = null\n[cp-kafka-connect-server] \tssl.trustmanager.algorithm = PKIX\n[cp-kafka-connect-server] \tssl.truststore.location = null\n[cp-kafka-connect-server] \tssl.truststore.password = null\n[cp-kafka-connect-server] \tssl.truststore.type = JKS\n[cp-kafka-connect-server] \n[cp-kafka-connect-server] [main] WARN org.apache.kafka.clients.ClientUtils - Couldn't resolve server PLAINTEXT://confluent-cp-kafka-headless:9092 from bootstrap.servers as DNS resolution failed for confluent-cp-kafka-headless\n[cp-kafka-connect-server] [main] ERROR io.confluent.admin.utils.cli.KafkaReadyCommand - Error while running kafka-ready.\n[cp-kafka-connect-server] org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:407)\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:65)\n[cp-kafka-connect-server] \tat io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:138)\n[cp-kafka-connect-server] \tat io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:150)\n[cp-kafka-connect-server] Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:88)\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:47)\n[cp-kafka-connect-server] \tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:367)\n[cp-kafka-connect-server] \t... 3 more\n[cp-kafka-connect-server] Unable to retrieve container logs for docker://b3fbace1640d851d5d3cf4f083ba88e8fcdba200069ceadddf87d70f4f2cf1ef[cp-kafka-connect-server] ===> ENV Variables ...\n[cp-kafka-connect-server] ALLOW_UNSIGNED=false\n[cp-kafka-connect-server] COMPONENT=kafka-connect\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP=tcp://10.96.245.103:9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_ADDR=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_PORT_9021_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_HOST=10.96.245.103\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT=9021\n[cp-kafka-connect-server] CONFLUENT_CP_CONTROL_CENTER_SERVICE_PORT_CC_HTTP=9021\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP=tcp://10.107.243.82:8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_ADDR=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_PORT_8083_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_HOST=10.107.243.82\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_CONNECT_SERVICE_PORT_KAFKA_CONNECT=8083\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP=tcp://10.110.197.204:9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_ADDR=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_PORT_9092_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP=tcp://10.106.47.218:8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_ADDR=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_PORT_8082_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_HOST=10.106.47.218\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_REST_SERVICE_PORT_REST_PROXY=8082\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_HOST=10.110.197.204\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KAFKA_SERVICE_PORT_BROKER=9092\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP=tcp://10.99.60.81:8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_ADDR=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_PORT_8088_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_HOST=10.99.60.81\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT=8088\n[cp-kafka-connect-server] CONFLUENT_CP_KSQL_SERVER_SERVICE_PORT_KSQL_SERVER=8088\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP=tcp://10.98.197.240:8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_ADDR=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_PORT_8081_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_HOST=10.98.197.240\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT=8081\n[cp-kafka-connect-server] CONFLUENT_CP_SCHEMA_REGISTRY_SERVICE_PORT_SCHEMA_REGISTRY=8081\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP=tcp://10.108.153.121:2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_ADDR=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_PORT_2181_TCP_PROTO=tcp\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_HOST=10.108.153.121\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT=2181\n[cp-kafka-connect-server] CONFLUENT_CP_ZOOKEEPER_SERVICE_PORT_CLIENT=2181\n[cp-kafka-connect-server] CONFLUENT_DEB_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_MAJOR_VERSION=5\n[cp-kafka-connect-server] CONFLUENT_MINOR_VERSION=3\n[cp-kafka-connect-server] CONFLUENT_MVN_LABEL=\n[cp-kafka-connect-server] CONFLUENT_PATCH_VERSION=1\n[cp-kafka-connect-server] CONFLUENT_PLATFORM_LABEL=\n[cp-kafka-connect-server] CONFLUENT_VERSION=5.3.1\n[cp-kafka-connect-server] CONNECT_BOOTSTRAP_SERVERS=PLAINTEXT://confluent-cp-kafka-headless:9092\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_CONFIG_STORAGE_TOPIC=confluent-cp-kafka-connect-config\n[cp-kafka-connect-server] CONNECT_GROUP_ID=confluent\n[cp-kafka-connect-server] CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_OFFSET_STORAGE_TOPIC=confluent-cp-kafka-connect-offset\n[cp-kafka-connect-server] CONNECT_PLUGIN_PATH=/usr/share/java,/usr/share/confluent-hub-components\n[cp-kafka-connect-server] CONNECT_REST_ADVERTISED_HOST_NAME=10.1.0.6\n[cp-kafka-connect-server] CONNECT_REST_PORT=8083\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1\n[cp-kafka-connect-server] CONNECT_STATUS_STORAGE_TOPIC=confluent-cp-kafka-connect-status\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false\n[cp-kafka-connect-server] CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://confluent-cp-schema-registry:8081\n[cp-kafka-connect-server] CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar\n[cp-kafka-connect-server] HOME=/root\n[cp-kafka-connect-server] HOSTNAME=confluent-cp-kafka-connect-df6b4f496-p9rtm\n[cp-kafka-connect-server] KAFKA_ADVERTISED_LISTENERS=\n[cp-kafka-connect-server] KAFKA_HEAP_OPTS=-Xms512M -Xmx512M\n[cp-kafka-connect-server] KAFKA_JMX_PORT=5555\n[cp-kafka-connect-server] KAFKA_VERSION=5.3.1\n[cp-kafka-connect-server] KAFKA_ZOOKEEPER_CONNECT=\n[cp-kafka-connect-server] KUBERNETES_PORT=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PORT=443\n[cp-kafka-connect-server] KUBERNETES_PORT_443_TCP_PROTO=tcp\n[cp-kafka-connect-server] KUBERNETES_SERVICE_HOST=10.96.0.1\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT=443\n[cp-kafka-connect-server] KUBERNETES_SERVICE_PORT_HTTPS=443\n[cp-kafka-connect-server] LANG=C.UTF-8\n[cp-kafka-connect-server] PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n[cp-kafka-connect-server] PWD=/\n[cp-kafka-connect-server] PYTHON_PIP_VERSION=8.1.2\n[cp-kafka-connect-server] PYTHON_VERSION=2.7.9-1\n[cp-kafka-connect-server] SCALA_VERSION=2.12\n[cp-kafka-connect-server] SHLVL=1\n[cp-kafka-connect-server] ZULU_OPENJDK_VERSION=8=8.38.0.13\n[cp-kafka-connect-server] _=/usr/bin/env\n[cp-kafka-connect-server] ===> User\n[cp-kafka-connect-server] uid=0(root) gid=0(root) groups=0(root)\n[cp-kafka-connect-server] ===> Configuring ...\n[cp-kafka-connect-server] ===> Running preflight checks ... \n[cp-kafka-connect-server] ===> Check if Kafka is healthy ...\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: \n[cp-kafka-connect-server] \tbootstrap.servers = [PLAINTEXT://confluent-cp-kafka-headless:9092]\n[cp-kafka-connect-server] \tclient.dns.lookup = default\n[cp-kafka-connect-server] \tclient.id = \n[cp-kafka-connect-server] \tconnections.max.idle.ms = 300000\n[cp-kafka-connect-server] \tmetadata.max.age.ms = 300000\n[cp-kafka-connect-server] \tmetric.reporters = []\n[cp-kafka-connect-server] \tmetrics.num.samples = 2\n[cp-kafka-connect-server] \tmetrics.recording.level = INFO\n[cp-kafka-connect-server] \tmetrics.sample.window.ms = 30000\n[cp-kafka-connect-server] \treceive.buffer.bytes = 65536\n[cp-kafka-connect-server] \treconnect.backoff.max.ms = 1000\n[cp-kafka-connect-server] \treconnect.backoff.ms = 50\n[cp-kafka-connect-server] \trequest.timeout.ms = 120000\n[cp-kafka-connect-server] \tretries = 5\n[cp-kafka-connect-server] \tretry.backoff.ms = 100\n[cp-kafka-connect-server] \tsasl.client.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.jaas.config = null\n[cp-kafka-connect-server] \tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n[cp-kafka-connect-server] \tsasl.kerberos.min.time.before.relogin = 60000\n[cp-kafka-connect-server] \tsasl.kerberos.service.name = null\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.kerberos.ticket.renew.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.callback.handler.class = null\n[cp-kafka-connect-server] \tsasl.login.class = null\n[cp-kafka-connect-server] \tsasl.login.refresh.buffer.seconds = 300\n[cp-kafka-connect-server] \tsasl.login.refresh.min.period.seconds = 60\n[cp-kafka-connect-server] \tsasl.login.refresh.window.factor = 0.8\n[cp-kafka-connect-server] \tsasl.login.refresh.window.jitter = 0.05\n[cp-kafka-connect-server] \tsasl.mechanism = GSSAPI\n[cp-kafka-connect-server] \tsecurity.protocol = PLAINTEXT\n[cp-kafka-connect-server] \tsend.buffer.bytes = 131072\n[cp-kafka-connect-server] \tssl.cipher.suites = null\n[cp-kafka-connect-server] \tssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]\n[cp-kafka-connect-server] \tssl.endpoint.identification.algorithm = https\n[cp-kafka-connect-server] \tssl.key.password = null\n[cp-kafka-connect-server] \tssl.keymanager.algorithm = SunX509\n[cp-kafka-connect-server] \tssl.keystore.location = null\n[cp-kafka-connect-server] \tssl.keystore.password = null\n[cp-kafka-connect-server] \tssl.keystore.type = JKS\n[cp-kafka-connect-server] \tssl.protocol = TLS\n[cp-kafka-connect-server] \tssl.provider = null\n[cp-kafka-connect-server] \tssl.secure.random.implementation = null\n[cp-kafka-connect-server] \tssl.trustmanager.algorithm = PKIX\n[cp-kafka-connect-server] \tssl.truststore.location = null\n[cp-kafka-connect-server] \tssl.truststore.password = null\n[cp-kafka-connect-server] \tssl.truststore.type = JKS\n[cp-kafka-connect-server] \n[cp-kafka-connect-server] [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc\n[cp-kafka-connect-server] [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1571409302393\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (confluent-cp-kafka-headless/10.1.0.10:9092) could not be established. Broker may not be available.\n[cp-kafka-connect-server] ===> Launching ... \n[cp-kafka-connect-server] ===> Launching kafka-connect ... \n[cp-kafka-connect-server] [2019-10-18 14:35:33,474] INFO WorkerInfo values: \n[cp-kafka-connect-server] \tjvm.args = -Xms512M, -Xmx512M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Djava.rmi.server.hostname=10.1.0.6, -Dcom.sun.management.jmxremote.local.only=false, -Dcom.sun.management.jmxremote.rmi.port=5555, -Dcom.sun.management.jmxremote.port=5555, -Dcom.sun.management.jmxremote.port=5555, -Dkafka.logs.dir=/var/log/kafka, -Dlog4j.configuration=file:/etc/kafka/connect-log4j.properties\n[cp-kafka-connect-server] \tjvm.spec = Azul Systems, Inc., OpenJDK 64-Bit Server VM, 1.8.0_212, 25.212-b04\n[cp-kafka-connect-server] \tjvm.classpath = /etc/kafka-connect/jars/*:/usr/share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/share/java/kafka/httpclient-4.5.7.jar:/usr/share/java/kafka/audience-annotations-0.5.0.jar:/usr/share/java/kafka/reflections-0.9.11.jar:/usr/share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/share/java/kafka/javassist-3.22.0-CR2.jar:/usr/share/java/kafka/validation-api-2.0.1.Final.jar:/usr/share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/share/java/kafka/jsr305-3.0.2.jar:/usr/share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/share/java/kafka/paranamer-2.8.jar:/usr/share/java/kafka/paranamer-2.7.jar:/usr/share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/share/java/kafka/jersey-server-2.28.jar:/usr/share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/share/java/kafka/hk2-utils-2.5.0.jar:/usr/share/java/kafka/maven-artifact-3.6.1.jar:/usr/share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/share/java/kafka/commons-codec-1.11.jar:/usr/share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/share/java/kafka/hk2-locator-2.5.0.jar:/usr/share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/share/java/kafka/commons-logging-1.2.jar:/usr/share/java/kafka/jopt-simple-5.0.4.jar:/usr/share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/share/java/kafka/zookeeper-3.4.14.jar:/usr/share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/share/java/kafka/httpmime-4.5.7.jar:/usr/share/java/kafka/lz4-java-1.6.0.jar:/usr/share/java/kafka/argparse4j-0.7.0.jar:/usr/share/java/kafka/jersey-client-2.28.jar:/usr/share/java/kafka/jackson-annotations-2.9.9.jar:/usr/share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/share/java/kafka/jersey-hk2-2.28.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/share/java/kafka/avro-1.8.1.jar:/usr/share/java/kafka/slf4j-api-1.7.26.jar:/usr/share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-core-2.9.9.jar:/usr/share/java/kafka/httpcore-4.4.11.jar:/usr/share/java/kafka/plexus-utils-3.2.0.jar:/usr/share/java/kafka/commons-compress-1.8.1.jar:/usr/share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/share/java/kafka/hk2-api-2.5.0.jar:/usr/share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/share/java/kafka/metrics-core-2.2.0.jar:/usr/share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/share/java/kafka/scala-reflect-2.12.8.jar:/usr/share/java/kafka/snappy-java-1.1.7.3.jar:/usr/share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/share/java/kafka/jersey-container-servlet-2.28.jar:/usr/share/java/kafka/zkclient-0.11.jar:/usr/share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/share/java/kafka/kafka.jar:/usr/share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/share/java/kafka/log4j-1.2.17.jar:/usr/share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/share/java/kafka/guava-20.0.jar:/usr/share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/share/java/kafka/commons-lang3-3.8.1.jar:/usr/share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/share/java/kafka/jaxb-api-2.3.0.jar:/usr/share/java/kafka/rocksdbjni-5.18.3.jar:/usr/share/java/kafka/activation-1.1.1.jar:/usr/share/java/kafka/scala-library-2.12.8.jar:/usr/share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/share/java/kafka/xz-1.5.jar:/usr/share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/share/java/kafka/jakarta.inject-2.5.0.jar:/usr/share/java/kafka/jersey-common-2.28.jar:/usr/share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/share/java/confluent-common/common-utils-5.3.1.jar:/usr/share/java/confluent-common/audience-annotations-0.5.0.jar:/usr/share/java/confluent-common/spotbugs-annotations-3.1.8.jar:/usr/share/java/confluent-common/zkclient-0.10.jar:/usr/share/java/confluent-common/jsr305-3.0.2.jar:/usr/share/java/confluent-common/jline-0.9.94.jar:/usr/share/java/confluent-common/netty-3.10.6.Final.jar:/usr/share/java/confluent-common/common-metrics-5.3.1.jar:/usr/share/java/confluent-common/zookeeper-3.4.14.jar:/usr/share/java/confluent-common/slf4j-api-1.7.26.jar:/usr/share/java/confluent-common/build-tools-5.3.1.jar:/usr/share/java/confluent-common/common-config-5.3.1.jar:/usr/share/java/kafka-serde-tools/kafka-avro-serializer-5.3.1.jar:/usr/share/java/kafka-serde-tools/paranamer-2.7.jar:/usr/share/java/kafka-serde-tools/kafka-connect-avro-converter-5.3.1.jar:/usr/share/java/kafka-serde-tools/jackson-annotations-2.9.9.jar:/usr/share/java/kafka-serde-tools/avro-1.8.1.jar:/usr/share/java/kafka-serde-tools/jackson-core-2.9.9.jar:/usr/share/java/kafka-serde-tools/snappy-java-1.1.1.3.jar:/usr/share/java/kafka-serde-tools/commons-compress-1.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-json-serializer-5.3.1.jar:/usr/share/java/kafka-serde-tools/kafka-streams-avro-serde-5.3.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-5.3.1.jar:/usr/share/java/kafka-serde-tools/jackson-mapper-asl-1.9.13.jar:/usr/share/java/kafka-serde-tools/jackson-core-asl-1.9.13.jar:/usr/share/java/kafka-serde-tools/xz-1.5.jar:/usr/share/java/kafka-serde-tools/jackson-databind-2.9.9.3.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-5.3.1.jar:/usr/bin/../share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/httpclient-4.5.7.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/bin/../share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-server-2.28.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/usr/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-codec-1.11.jar:/usr/bin/../share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.14.jar:/usr/bin/../share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/bin/../share/java/kafka/httpmime-4.5.7.jar:/usr/bin/../share/java/kafka/lz4-java-1.6.0.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/jersey-client-2.28.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.28.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.26.jar:/usr/bin/../share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.9.jar:/usr/bin/../share/java/kafka/httpcore-4.4.11.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/scala-reflect-2.12.8.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/usr/bin/../share/java/kafka/zkclient-0.11.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/scala-library-2.12.8.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/usr/bin/../share/java/kafka/jersey-common-2.28.jar:/usr/bin/../share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/bin/../share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/bin/../support-metrics-client/build/dependant-libs-2.12/*:/usr/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/*\n[cp-kafka-connect-server] \tos.spec = Linux, amd64, 4.9.184-linuxkit\n[cp-kafka-connect-server] \tos.vcpus = 1\n[cp-kafka-connect-server]  (org.apache.kafka.connect.runtime.WorkerInfo)\n[cp-kafka-connect-server] [2019-10-18 14:35:33,704] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed)\n[cp-kafka-connect-server] [2019-10-18 14:35:34,208] INFO Loading plugin from: /usr/share/java/kafka-connect-s3 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,695] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-s3/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,782] INFO Added plugin 'io.confluent.connect.storage.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,783] INFO Added plugin 'io.confluent.connect.s3.S3SinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,783] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,783] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,863] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,863] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:19,863] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:20,242] INFO Loading plugin from: /usr/share/java/kafka-connect-storage-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:34,774] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-storage-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:34,789] INFO Loading plugin from: /usr/share/java/kafka-connect-jms (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:36,358] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jms/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:36,387] INFO Added plugin 'io.confluent.connect.jms.JmsSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:36,403] INFO Loading plugin from: /usr/share/java/kafka-connect-activemq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,805] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-activemq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,832] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,834] INFO Added plugin 'io.confluent.connect.activemq.ActiveMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,841] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,851] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,854] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,861] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,866] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,868] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,894] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,921] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,924] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,925] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,925] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,926] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,926] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,934] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,937] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:48,937] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,095] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,100] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,101] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,105] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,106] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,107] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,109] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,109] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:49,110] INFO Loading plugin from: /usr/share/java/kafka-connect-elasticsearch (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:51,281] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-elasticsearch/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:51,281] INFO Added plugin 'io.confluent.connect.elasticsearch.ElasticsearchSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:51,282] INFO Loading plugin from: /usr/share/java/kafka-connect-ibmmq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:57,689] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-ibmmq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:57,689] INFO Added plugin 'io.confluent.connect.ibm.mq.IbmMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:57,723] INFO Loading plugin from: /usr/share/java/kafka-connect-jdbc (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,284] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jdbc/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,291] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,292] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:36:59,401] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:02,110] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:02,193] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:16,462] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:37:16,472] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,145] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,163] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,191] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,234] INFO Added plugin 'io.confluent.kafka.secretregistry.client.config.provider.SecretConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,234] INFO Added plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:03,256] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:08,335] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:08,517] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:14,715] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:14,751] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:19,289] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:39:19,294] INFO Loading plugin from: /usr/share/java/confluent-rebalancer (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:18,923] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-rebalancer/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:18,928] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:19,540] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:19,567] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,178] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,186] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:40:28,187] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:42:04,776] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:42:04,788] INFO Loading plugin from: /usr/share/confluent-hub-components/confluentinc-kafka-connect-gcs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[prometheus-jmx-exporter] rpc error: code = DeadlineExceeded desc = context deadline exceeded[cp-kafka-connect-server] rpc error: code = DeadlineExceeded desc = context deadline exceeded[cp-kafka-connect-server] [2019-10-18 14:46:59,709] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/confluent-hub-components/confluentinc-kafka-connect-gcs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n[cp-kafka-connect-server] [2019-10-18 14:46:59,728] INFO Added plugin 'io.confluent.connect.gcs.GcsSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)\n",
      "CrashLog": ""
    },
    {
      "Name": "confluent-cp-kafka-rest",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:28.553728-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:27.56921-04:00",
          "FinishTime": "2019-10-18T10:29:28.553675-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-kafka-rest\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-rest:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-rest:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.983s\n\u001b[34m  │ \u001b[0mDone in: 0.983s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "confluent-cp-kafka-rest-5778c66498-fcvs6",
      "K8sResourceInfo": {
        "PodName": "confluent-cp-kafka-rest-5778c66498-fcvs6",
        "PodCreationTime": "2019-10-18T10:29:28-04:00",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "ContainerCreating",
        "PodStatusMessage": "",
        "AllContainersReady": false,
        "PodRestarts": 0,
        "PodLog": ""
      },
      "RuntimeStatus": "pending",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-kafka-rest\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-rest:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-rest:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.983s\n\u001b[34m  │ \u001b[0mDone in: 0.983s \n\n",
      "CrashLog": ""
    },
    {
      "Name": "confluent-cp-ksql-server",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:29.28983-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:28.554667-04:00",
          "FinishTime": "2019-10-18T10:29:29.289828-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-ksql-server\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.734s\n\u001b[34m  │ \u001b[0mDone in: 0.734s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "confluent-cp-ksql-server-647ccc5bfd-xwsgx",
      "K8sResourceInfo": {
        "PodName": "confluent-cp-ksql-server-647ccc5bfd-xwsgx",
        "PodCreationTime": "2019-10-18T10:29:29-04:00",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "ContainerCreating",
        "PodStatusMessage": "",
        "AllContainersReady": false,
        "PodRestarts": 0,
        "PodLog": ""
      },
      "RuntimeStatus": "pending",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-ksql-server\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 0.734s\n\u001b[34m  │ \u001b[0mDone in: 0.734s \n\n[K8s EVENT: Pod confluent-cp-ksql-server-647ccc5bfd-xwsgx (ns: testspace)] Back-off restarting failed container\n",
      "CrashLog": ""
    },
    {
      "Name": "confluent-cp-schema-registry",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:30.887255-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:29.290008-04:00",
          "FinishTime": "2019-10-18T10:29:30.887251-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-schema-registry\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-schema-registry:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-schema-registry:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 1.596s\n\u001b[34m  │ \u001b[0mDone in: 1.596s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "confluent-cp-schema-registry-c88899896-9f8z6",
      "K8sResourceInfo": {
        "PodName": "confluent-cp-schema-registry-c88899896-9f8z6",
        "PodCreationTime": "2019-10-18T10:29:30-04:00",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "ContainerCreating",
        "PodStatusMessage": "",
        "AllContainersReady": false,
        "PodRestarts": 0,
        "PodLog": ""
      },
      "RuntimeStatus": "pending",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-schema-registry\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-schema-registry:deployment\n\u001b[34m  │ \u001b[0m   confluent-cp-schema-registry:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 1.596s\n\u001b[34m  │ \u001b[0mDone in: 1.596s \n\n",
      "CrashLog": ""
    },
    {
      "Name": "confluent-cp-kafka",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:38.150698-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:30.887414-04:00",
          "FinishTime": "2019-10-18T10:29:38.150695-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-kafka\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka:statefulset\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-headless:service\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 7.262s\n\u001b[34m  │ \u001b[0mDone in: 7.262s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "confluent-cp-kafka-0",
      "K8sResourceInfo": {
        "PodName": "confluent-cp-kafka-0",
        "PodCreationTime": "2019-10-18T10:29:32-04:00",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "ContainerCreating",
        "PodStatusMessage": "",
        "AllContainersReady": false,
        "PodRestarts": 0,
        "PodLog": ""
      },
      "RuntimeStatus": "pending",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-kafka\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka:statefulset\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-headless:service\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 7.262s\n\u001b[34m  │ \u001b[0mDone in: 7.262s \n\n[K8s EVENT: Pod confluent-cp-kafka-0 (ns: testspace)] pod has unbound immediate PersistentVolumeClaims\n[K8s EVENT: Pod confluent-cp-kafka-0 (ns: testspace)] pod has unbound immediate PersistentVolumeClaims\n",
      "CrashLog": ""
    },
    {
      "Name": "confluent-cp-zookeeper",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:42.104051-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:38.150965-04:00",
          "FinishTime": "2019-10-18T10:29:42.104047-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-zookeeper\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper:statefulset\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper-headless:service\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 3.952s\n\u001b[34m  │ \u001b[0mDone in: 3.952s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "confluent-cp-zookeeper-0",
      "K8sResourceInfo": {
        "PodName": "confluent-cp-zookeeper-0",
        "PodCreationTime": "2019-10-18T10:29:40-04:00",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "ContainerCreating",
        "PodStatusMessage": "",
        "AllContainersReady": false,
        "PodRestarts": 0,
        "PodLog": ""
      },
      "RuntimeStatus": "pending",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mconfluent-cp-zookeeper\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper:statefulset\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper-headless:service\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper:service\n\n\u001b[34m  │ \u001b[0mStep 1 - 3.952s\n\u001b[34m  │ \u001b[0mDone in: 3.952s \n\n[K8s EVENT: Pod confluent-cp-zookeeper-0 (ns: testspace)] pod has unbound immediate PersistentVolumeClaims\n[K8s EVENT: Pod confluent-cp-zookeeper-0 (ns: testspace)] pod has unbound immediate PersistentVolumeClaims\n[K8s EVENT: Pod confluent-cp-zookeeper-0 (ns: testspace)] pod has unbound immediate PersistentVolumeClaims\n[K8s EVENT: Pod confluent-cp-zookeeper-0 (ns: testspace)] pod has unbound immediate PersistentVolumeClaims\n[K8s EVENT: Pod confluent-cp-zookeeper-0 (ns: testspace)] pod has unbound immediate PersistentVolumeClaims\n",
      "CrashLog": ""
    },
    {
      "Name": "release-name-faustdemo",
      "DirectoriesWatched": [
        "."
      ],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "0001-01-01T00:00:00Z",
      "TriggerMode": 0,
      "BuildHistory": [],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "2019-10-18T10:29:42.104341-04:00",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "\n\u001b[34m──┤ Building: \u001b[0mrelease-name-faustdemo\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/3 — \u001b[0mBuilding Dockerfile: [docker.io/library/faustdemo]\nBuilding Dockerfile:\n  FROM python:3.7-slim\n  \n  ENV DEBIAN_FRONTEND=noninteractive \\\n      DEBIAN_FRONTEND=teletype\n  \n  RUN echo 'deb [check-valid-until=no] http://archive.debian.org/debian jessie-backports main' >> /etc/apt/sources.list\n  RUN apt-get update \\\n      && apt-get install -y --no-install-recommends apt-utils \\\n      && apt-get install -y --no-install-recommends git gcc make g++ libgflags-dev libsnappy-dev zlib1g-dev libbz2-dev liblz4-dev libzstd-dev netcat\\\n      && apt-get autoremove -y && apt-get clean \\\n      && rm -rf /var/lib/apt/lists/*\n  \n  WORKDIR /tmp/rocksdb\n  \n  RUN git clone https://github.com/facebook/rocksdb.git /tmp/rocksdb \\\n      && make install-shared INSTALL_PATH=/usr \\\n      && rm -rf /tmp/rocksdb\n  \n  ENV STORE_URI=rocksdb://\n  \n  WORKDIR /faustdemo/\n  \n  COPY run.sh /faustdemo/\n  COPY wait_for_services.sh /faustdemo/\n  COPY poetry.lock /faustdemo/\n  COPY poetry.toml /faustdemo/\n  COPY pyproject.toml /faustdemo/\n  COPY Makefile /faustdemo/\n  \n  RUN pip3 install poetry==1.0.0b1 && poetry add python-rocksdb && poetry install\n  \n  COPY faustdemo /faustdemo/faustdemo\n  \n  ENTRYPOINT [\"./run.sh\"]\n\n\n\u001b[34m  │ \u001b[0mTarring context…\n\u001b[34m  │ \u001b[0mBuilding image\n    ╎ copy /context /\n    ╎ copy /context / done | 1.877s\n    ╎ [1/14] FROM docker.io/library/python:3.7-slim@sha256:9ad63b1cfda5f8ff1d4e4003e16b445fe4b5551db6a781e917f1672c65c3c900\n    ╎ [1/14] done | 18.549s\n    ╎ [2/14] RUN echo 'deb [check-valid-until=no] http://archive.debian.org/debian jessie-backports main' >> /etc/apt/sources.list\n    ╎ [2/14] RUN echo 'deb [check-valid-until=no] done | 818ms\n    ╎ [3/14] RUN apt-get update     && apt-get install -y --no-install-recommends apt-utils     && apt-get install -y --no-install-recommends git gcc make g++ libgflags-dev libsnappy-dev zlib1g-dev libbz2-dev liblz4-dev libzstd-dev netcat    && apt-get autoremove -y && apt-get clean     && rm -rf /var/lib/apt/lists/*\n    ╎   → Get:1 http://security.debian.org/debian-security buster/updates InRelease [39.1 kB]\n    ╎   → Get:2 http://deb.debian.org/debian buster InRelease [122 kB]\n    ╎   → Get:3 http://deb.debian.org/debian buster-updates InRelease [49.3 kB]\n    ╎   → Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [99.2 kB]\n    ╎   → Get:5 http://archive.debian.org/debian jessie-backports InRelease [166 kB]\n    ╎   → Get:6 http://deb.debian.org/debian buster/main amd64 Packages [7899 kB]\n    ╎   → Get:7 http://deb.debian.org/debian buster-updates/main amd64 Packages [5792 B]\n    ╎   → Get:8 http://archive.debian.org/debian jessie-backports/main amd64 Packages [911 kB]\n    ╎   → Fetched 9291 kB in 3s (2962 kB/s)\n    ╎   → Reading package lists...\n    ╎   → Reading package lists...\n    ╎   → Building dependency tree...\n    ╎   → Reading state information...\n    ╎   → The following additional packages will be installed:\n    ╎   →   libapt-inst2.0\n    ╎   → The following NEW packages will be installed:\n    ╎   →   apt-utils libapt-inst2.0\n    ╎   → 0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\n    ╎   → Need to get 625 kB of archives.\n    ╎   → After this operation, 1655 kB of additional disk space will be used.\n    ╎   → Get:1 http://deb.debian.org/debian buster/main amd64 libapt-inst2.0 amd64 1.8.2 [204 kB]\n    ╎   → Get:2 http://deb.debian.org/debian buster/main amd64 apt-utils amd64 1.8.2 [421 kB]\n    ╎   → debconf: delaying package configuration, since apt-utils is not installed\n    ╎   → Fetched 625 kB in 0s (6864 kB/s)\n    ╎   → Selecting previously unselected package libapt-inst2.0:amd64.\r\n    ╎   → (Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 6828 files and directories currently installed.)\r\n    ╎   → Preparing to unpack .../libapt-inst2.0_1.8.2_amd64.deb ...\r\n    ╎   → Unpacking libapt-inst2.0:amd64 (1.8.2) ...\r\n    ╎   → Selecting previously unselected package apt-utils.\r\n    ╎   → Preparing to unpack .../apt-utils_1.8.2_amd64.deb ...\r\n    ╎   → Unpacking apt-utils (1.8.2) ...\r\n    ╎   → Setting up libapt-inst2.0:amd64 (1.8.2) ...\r\n    ╎   → Setting up apt-utils (1.8.2) ...\r\n    ╎   → Processing triggers for libc-bin (2.28-10) ...\r\n    ╎   → Reading package lists...\n    ╎   → Building dependency tree...\n    ╎   → Reading state information...\n    ╎   → The following additional packages will be installed:\n    ╎   →   binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-8 g++-8 gcc-8\n    ╎   →   git-man libasan5 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0\n    ╎   →   libcurl3-gnutls liberror-perl libgcc-8-dev libgdbm-compat4 libgflags2.2\n    ╎   →   libgomp1 libgssapi-krb5-2 libisl19 libitm1 libk5crypto3 libkeyutils1\n    ╎   →   libkrb5-3 libkrb5support0 libldap-2.4-2 libldap-common liblsan0 libmpc3\n    ╎   →   libmpfr6 libmpx2 libnghttp2-14 libpcre2-8-0 libperl5.28 libpsl5 libquadmath0\n    ╎   →   librtmp1 libsasl2-2 libsasl2-modules-db libsnappy1v5 libssh2-1\n    ╎   →   libstdc++-8-dev libtsan0 libubsan1 linux-libc-dev netcat-traditional perl\n    ╎   →   perl-modules-5.28\n    ╎   → Suggested packages:\n    ╎   →   binutils-doc cpp-doc gcc-8-locales g++-multilib g++-8-multilib gcc-8-doc\n    ╎   →   libstdc++6-8-dbg gcc-multilib manpages-dev autoconf automake libtool flex\n    ╎   →   bison gdb gcc-doc gcc-8-multilib libgcc1-dbg libgomp1-dbg libitm1-dbg\n    ╎   →   libatomic1-dbg libasan5-dbg liblsan0-dbg libtsan0-dbg libubsan1-dbg\n    ╎   →   libmpx2-dbg libquadmath0-dbg gettext-base git-daemon-run\n    ╎   →   | git-daemon-sysvinit git-doc git-el git-email git-gui gitk gitweb git-cvs\n    ╎   →   git-mediawiki git-svn glibc-doc krb5-doc krb5-user sensible-utils\n    ╎   →   libstdc++-8-doc make-doc perl-doc libterm-readline-gnu-perl\n    ╎   →   | libterm-readline-perl-perl libb-debug-perl liblocale-codes-perl\n    ╎   → Recommended packages:\n    ╎   →   patch less ssh-client bzip2-doc manpages manpages-dev krb5-locales\n    ╎   →   publicsuffix libsasl2-modules\n    ╎   → The following NEW packages will be installed:\n    ╎   →   binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-8 g++ g++-8 gcc\n    ╎   →   gcc-8 git git-man libasan5 libatomic1 libbinutils libbz2-dev libc-dev-bin\n    ╎   →   libc6-dev libcc1-0 libcurl3-gnutls liberror-perl libgcc-8-dev\n    ╎   →   libgdbm-compat4 libgflags-dev libgflags2.2 libgomp1 libgssapi-krb5-2\n    ╎   →   libisl19 libitm1 libk5crypto3 libkeyutils1 libkrb5-3 libkrb5support0\n    ╎   →   libldap-2.4-2 libldap-common liblsan0 liblz4-dev libmpc3 libmpfr6 libmpx2\n    ╎   →   libnghttp2-14 libpcre2-8-0 libperl5.28 libpsl5 libquadmath0 librtmp1\n    ╎   →   libsasl2-2 libsasl2-modules-db libsnappy-dev libsnappy1v5 libssh2-1\n    ╎   →   libstdc++-8-dev libtsan0 libubsan1 libzstd-dev linux-libc-dev make netcat\n    ╎   →   netcat-traditional perl perl-modules-5.28 zlib1g-dev\n    ╎   → 0 upgraded, 61 newly installed, 0 to remove and 0 not upgraded.\n    ╎   → Need to get 60.8 MB of archives.\n    ╎   → After this operation, 269 MB of additional disk space will be used.\n    ╎   → Get:1 http://security.debian.org/debian-security buster/updates/main amd64 linux-libc-dev amd64 4.19.67-2+deb10u1 [1233 kB]\n    ╎   → Get:2 http://deb.debian.org/debian buster/main amd64 perl-modules-5.28 all 5.28.1-6 [2873 kB]\n    ╎   → Get:3 http://security.debian.org/debian-security buster/updates/main amd64 libnghttp2-14 amd64 1.36.0-2+deb10u1 [85.0 kB]\n    ╎   → Get:4 http://deb.debian.org/debian buster/main amd64 libgdbm-compat4 amd64 1.18.1-4 [44.1 kB]\n    ╎   → Get:5 http://deb.debian.org/debian buster/main amd64 libperl5.28 amd64 5.28.1-6 [3883 kB]\n    ╎   → Get:6 http://deb.debian.org/debian buster/main amd64 perl amd64 5.28.1-6 [204 kB]\n    ╎   → Get:7 http://deb.debian.org/debian buster/main amd64 netcat-traditional amd64 1.10-41.1 [66.9 kB]\n    ╎   → Get:8 http://deb.debian.org/debian buster/main amd64 binutils-common amd64 2.31.1-16 [2073 kB]\n    ╎   → Get:9 http://deb.debian.org/debian buster/main amd64 libbinutils amd64 2.31.1-16 [478 kB]\n    ╎   → Get:10 http://deb.debian.org/debian buster/main amd64 binutils-x86-64-linux-gnu amd64 2.31.1-16 [1823 kB]\n    ╎   → Get:11 http://deb.debian.org/debian buster/main amd64 binutils amd64 2.31.1-16 [56.8 kB]\n    ╎   → Get:12 http://deb.debian.org/debian buster/main amd64 libisl19 amd64 0.20-2 [587 kB]\n    ╎   → Get:13 http://deb.debian.org/debian buster/main amd64 libmpfr6 amd64 4.0.2-1 [775 kB]\n    ╎   → Get:14 http://deb.debian.org/debian buster/main amd64 libmpc3 amd64 1.1.0-1 [41.3 kB]\n    ╎   → Get:15 http://deb.debian.org/debian buster/main amd64 cpp-8 amd64 8.3.0-6 [8914 kB]\n    ╎   → Get:16 http://deb.debian.org/debian buster/main amd64 cpp amd64 4:8.3.0-1 [19.4 kB]\n    ╎   → Get:17 http://deb.debian.org/debian buster/main amd64 libcc1-0 amd64 8.3.0-6 [46.6 kB]\n    ╎   → Get:18 http://deb.debian.org/debian buster/main amd64 libgomp1 amd64 8.3.0-6 [75.8 kB]\n    ╎   → Get:19 http://deb.debian.org/debian buster/main amd64 libitm1 amd64 8.3.0-6 [27.7 kB]\n    ╎   → Get:20 http://deb.debian.org/debian buster/main amd64 libatomic1 amd64 8.3.0-6 [9032 B]\n    ╎   → Get:21 http://deb.debian.org/debian buster/main amd64 libasan5 amd64 8.3.0-6 [362 kB]\n    ╎   → Get:22 http://deb.debian.org/debian buster/main amd64 liblsan0 amd64 8.3.0-6 [131 kB]\n    ╎   → Get:23 http://deb.debian.org/debian buster/main amd64 libtsan0 amd64 8.3.0-6 [283 kB]\n    ╎   → Get:24 http://deb.debian.org/debian buster/main amd64 libubsan1 amd64 8.3.0-6 [120 kB]\n    ╎   → Get:25 http://deb.debian.org/debian buster/main amd64 libmpx2 amd64 8.3.0-6 [11.4 kB]\n    ╎   → Get:26 http://deb.debian.org/debian buster/main amd64 libquadmath0 amd64 8.3.0-6 [133 kB]\n    ╎   → Get:27 http://deb.debian.org/debian buster/main amd64 libgcc-8-dev amd64 8.3.0-6 [2298 kB]\n    ╎   → Get:28 http://deb.debian.org/debian buster/main amd64 gcc-8 amd64 8.3.0-6 [9452 kB]\n    ╎   → Get:29 http://deb.debian.org/debian buster/main amd64 gcc amd64 4:8.3.0-1 [5196 B]\n    ╎   → Get:30 http://deb.debian.org/debian buster/main amd64 libc-dev-bin amd64 2.28-10 [275 kB]\n    ╎   → Get:31 http://deb.debian.org/debian buster/main amd64 libc6-dev amd64 2.28-10 [2691 kB]\n    ╎   → Get:32 http://deb.debian.org/debian buster/main amd64 libstdc++-8-dev amd64 8.3.0-6 [1532 kB]\n    ╎   → Get:33 http://deb.debian.org/debian buster/main amd64 g++-8 amd64 8.3.0-6 [9752 kB]\n    ╎   → Get:34 http://deb.debian.org/debian buster/main amd64 g++ amd64 4:8.3.0-1 [1644 B]\n    ╎   → Get:35 http://deb.debian.org/debian buster/main amd64 libkeyutils1 amd64 1.6-6 [15.0 kB]\n    ╎   → Get:36 http://deb.debian.org/debian buster/main amd64 libkrb5support0 amd64 1.17-3 [65.6 kB]\n    ╎   → Get:37 http://deb.debian.org/debian buster/main amd64 libk5crypto3 amd64 1.17-3 [121 kB]\n    ╎   → Get:38 http://deb.debian.org/debian buster/main amd64 libkrb5-3 amd64 1.17-3 [370 kB]\n    ╎   → Get:39 http://deb.debian.org/debian buster/main amd64 libgssapi-krb5-2 amd64 1.17-3 [158 kB]\n    ╎   → Get:40 http://deb.debian.org/debian buster/main amd64 libsasl2-modules-db amd64 2.1.27+dfsg-1 [69.0 kB]\n    ╎   → Get:41 http://deb.debian.org/debian buster/main amd64 libsasl2-2 amd64 2.1.27+dfsg-1 [106 kB]\n    ╎   → Get:42 http://deb.debian.org/debian buster/main amd64 libldap-common all 2.4.47+dfsg-3+deb10u1 [89.6 kB]\n    ╎   → Get:43 http://deb.debian.org/debian buster/main amd64 libldap-2.4-2 amd64 2.4.47+dfsg-3+deb10u1 [225 kB]\n    ╎   → Get:44 http://deb.debian.org/debian buster/main amd64 libpsl5 amd64 0.20.2-2 [53.7 kB]\n    ╎   → Get:45 http://deb.debian.org/debian buster/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2 [60.5 kB]\n    ╎   → Get:46 http://deb.debian.org/debian buster/main amd64 libssh2-1 amd64 1.8.0-2.1 [140 kB]\n    ╎   → Get:47 http://deb.debian.org/debian buster/main amd64 libcurl3-gnutls amd64 7.64.0-4 [329 kB]\n    ╎   → Get:48 http://deb.debian.org/debian buster/main amd64 libpcre2-8-0 amd64 10.32-5 [213 kB]\n    ╎   → Get:49 http://deb.debian.org/debian buster/main amd64 liberror-perl all 0.17027-2 [30.9 kB]\n    ╎   → Get:50 http://deb.debian.org/debian buster/main amd64 git-man all 1:2.20.1-2 [1619 kB]\n    ╎   → Get:51 http://deb.debian.org/debian buster/main amd64 git amd64 1:2.20.1-2 [5621 kB]\n    ╎   → Get:52 http://deb.debian.org/debian buster/main amd64 libbz2-dev amd64 1.0.6-9.2~deb10u1 [30.2 kB]\n    ╎   → Get:53 http://deb.debian.org/debian buster/main amd64 libgflags2.2 amd64 2.2.2-1 [76.7 kB]\n    ╎   → Get:54 http://deb.debian.org/debian buster/main amd64 libgflags-dev amd64 2.2.2-1 [93.6 kB]\n    ╎   → Get:55 http://deb.debian.org/debian buster/main amd64 liblz4-dev amd64 1.8.3-1 [69.0 kB]\n    ╎   → Get:56 http://deb.debian.org/debian buster/main amd64 libsnappy1v5 amd64 1.1.7-1 [17.0 kB]\n    ╎   → Get:57 http://deb.debian.org/debian buster/main amd64 libsnappy-dev amd64 1.1.7-1 [29.2 kB]\n    ╎   → Get:58 http://deb.debian.org/debian buster/main amd64 libzstd-dev amd64 1.3.8+dfsg-3 [284 kB]\n    ╎   → Get:59 http://deb.debian.org/debian buster/main amd64 make amd64 4.2.1-1.2 [341 kB]\n    ╎   → Get:60 http://deb.debian.org/debian buster/main amd64 netcat all 1.10-41.1 [9034 B]\n    ╎   → Get:61 http://deb.debian.org/debian buster/main amd64 zlib1g-dev amd64 1:1.2.11.dfsg-1 [214 kB]\n    ╎   → dpkg-preconfigure: unable to re-open stdin: \n    ╎   → Fetched 60.8 MB in 5s (13.2 MB/s)\n    ╎   → Selecting previously unselected package perl-modules-5.28.\r\n    ╎   → (Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 6958 files and directories currently installed.)\r\n    ╎   → Preparing to unpack .../00-perl-modules-5.28_5.28.1-6_all.deb ...\r\n    ╎   → Unpacking perl-modules-5.28 (5.28.1-6) ...\r\n    ╎   → Selecting previously unselected package libgdbm-compat4:amd64.\r\n    ╎   → Preparing to unpack .../01-libgdbm-compat4_1.18.1-4_amd64.deb ...\r\n    ╎   → Unpacking libgdbm-compat4:amd64 (1.18.1-4) ...\r\n    ╎   → Selecting previously unselected package libperl5.28:amd64.\r\n    ╎   → Preparing to unpack .../02-libperl5.28_5.28.1-6_amd64.deb ...\r\n    ╎   → Unpacking libperl5.28:amd64 (5.28.1-6) ...\r\n    ╎   → Selecting previously unselected package perl.\r\n    ╎   → Preparing to unpack .../03-perl_5.28.1-6_amd64.deb ...\r\n    ╎   → Unpacking perl (5.28.1-6) ...\r\n    ╎   → Selecting previously unselected package netcat-traditional.\r\n    ╎   → Preparing to unpack .../04-netcat-traditional_1.10-41.1_amd64.deb ...\r\n    ╎   → Unpacking netcat-traditional (1.10-41.1) ...\r\n    ╎   → Selecting previously unselected package binutils-common:amd64.\r\n    ╎   → Preparing to unpack .../05-binutils-common_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking binutils-common:amd64 (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package libbinutils:amd64.\r\n    ╎   → Preparing to unpack .../06-libbinutils_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking libbinutils:amd64 (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package binutils-x86-64-linux-gnu.\r\n    ╎   → Preparing to unpack .../07-binutils-x86-64-linux-gnu_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking binutils-x86-64-linux-gnu (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package binutils.\r\n    ╎   → Preparing to unpack .../08-binutils_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking binutils (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package libisl19:amd64.\r\n    ╎   → Preparing to unpack .../09-libisl19_0.20-2_amd64.deb ...\r\n    ╎   → Unpacking libisl19:amd64 (0.20-2) ...\r\n    ╎   → Selecting previously unselected package libmpfr6:amd64.\r\n    ╎   → Preparing to unpack .../10-libmpfr6_4.0.2-1_amd64.deb ...\r\n    ╎   → Unpacking libmpfr6:amd64 (4.0.2-1) ...\r\n    ╎   → Selecting previously unselected package libmpc3:amd64.\r\n    ╎   → Preparing to unpack .../11-libmpc3_1.1.0-1_amd64.deb ...\r\n    ╎   → Unpacking libmpc3:amd64 (1.1.0-1) ...\r\n    ╎   → Selecting previously unselected package cpp-8.\r\n    ╎   → Preparing to unpack .../12-cpp-8_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking cpp-8 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package cpp.\r\n    ╎   → Preparing to unpack .../13-cpp_4%3a8.3.0-1_amd64.deb ...\r\n    ╎   → Unpacking cpp (4:8.3.0-1) ...\r\n    ╎   → Selecting previously unselected package libcc1-0:amd64.\r\n    ╎   → Preparing to unpack .../14-libcc1-0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libcc1-0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libgomp1:amd64.\r\n    ╎   → Preparing to unpack .../15-libgomp1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libgomp1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libitm1:amd64.\r\n    ╎   → Preparing to unpack .../16-libitm1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libitm1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libatomic1:amd64.\r\n    ╎   → Preparing to unpack .../17-libatomic1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libatomic1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libasan5:amd64.\r\n    ╎   → Preparing to unpack .../18-libasan5_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libasan5:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package liblsan0:amd64.\r\n    ╎   → Preparing to unpack .../19-liblsan0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking liblsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libtsan0:amd64.\r\n    ╎   → Preparing to unpack .../20-libtsan0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libtsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libubsan1:amd64.\r\n    ╎   → Preparing to unpack .../21-libubsan1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libubsan1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libmpx2:amd64.\r\n    ╎   → Preparing to unpack .../22-libmpx2_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libmpx2:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libquadmath0:amd64.\r\n    ╎   → Preparing to unpack .../23-libquadmath0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libquadmath0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libgcc-8-dev:amd64.\r\n    ╎   → Preparing to unpack .../24-libgcc-8-dev_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libgcc-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package gcc-8.\r\n    ╎   → Preparing to unpack .../25-gcc-8_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking gcc-8 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package gcc.\r\n    ╎   → Preparing to unpack .../26-gcc_4%3a8.3.0-1_amd64.deb ...\r\n    ╎   → Unpacking gcc (4:8.3.0-1) ...\r\n    ╎   → Selecting previously unselected package libc-dev-bin.\r\n    ╎   → Preparing to unpack .../27-libc-dev-bin_2.28-10_amd64.deb ...\r\n    ╎   → Unpacking libc-dev-bin (2.28-10) ...\r\n    ╎   → Selecting previously unselected package linux-libc-dev:amd64.\r\n    ╎   → Preparing to unpack .../28-linux-libc-dev_4.19.67-2+deb10u1_amd64.deb ...\r\n    ╎   → Unpacking linux-libc-dev:amd64 (4.19.67-2+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libc6-dev:amd64.\r\n    ╎   → Preparing to unpack .../29-libc6-dev_2.28-10_amd64.deb ...\r\n    ╎   → Unpacking libc6-dev:amd64 (2.28-10) ...\r\n    ╎   → Selecting previously unselected package libstdc++-8-dev:amd64.\r\n    ╎   → Preparing to unpack .../30-libstdc++-8-dev_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libstdc++-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package g++-8.\r\n    ╎   → Preparing to unpack .../31-g++-8_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking g++-8 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package g++.\r\n    ╎   → Preparing to unpack .../32-g++_4%3a8.3.0-1_amd64.deb ...\r\n    ╎   → Unpacking g++ (4:8.3.0-1) ...\r\n    ╎   → Selecting previously unselected package libkeyutils1:amd64.\r\n    ╎   → Preparing to unpack .../33-libkeyutils1_1.6-6_amd64.deb ...\r\n    ╎   → Unpacking libkeyutils1:amd64 (1.6-6) ...\r\n    ╎   → Selecting previously unselected package libkrb5support0:amd64.\r\n    ╎   → Preparing to unpack .../34-libkrb5support0_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libkrb5support0:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libk5crypto3:amd64.\r\n    ╎   → Preparing to unpack .../35-libk5crypto3_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libk5crypto3:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libkrb5-3:amd64.\r\n    ╎   → Preparing to unpack .../36-libkrb5-3_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libkrb5-3:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libgssapi-krb5-2:amd64.\r\n    ╎   → Preparing to unpack .../37-libgssapi-krb5-2_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libgssapi-krb5-2:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libsasl2-modules-db:amd64.\r\n    ╎   → Preparing to unpack .../38-libsasl2-modules-db_2.1.27+dfsg-1_amd64.deb ...\r\n    ╎   → Unpacking libsasl2-modules-db:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Selecting previously unselected package libsasl2-2:amd64.\r\n    ╎   → Preparing to unpack .../39-libsasl2-2_2.1.27+dfsg-1_amd64.deb ...\r\n    ╎   → Unpacking libsasl2-2:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Selecting previously unselected package libldap-common.\r\n    ╎   → Preparing to unpack .../40-libldap-common_2.4.47+dfsg-3+deb10u1_all.deb ...\r\n    ╎   → Unpacking libldap-common (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libldap-2.4-2:amd64.\r\n    ╎   → Preparing to unpack .../41-libldap-2.4-2_2.4.47+dfsg-3+deb10u1_amd64.deb ...\r\n    ╎   → Unpacking libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libnghttp2-14:amd64.\r\n    ╎   → Preparing to unpack .../42-libnghttp2-14_1.36.0-2+deb10u1_amd64.deb ...\r\n    ╎   → Unpacking libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libpsl5:amd64.\r\n    ╎   → Preparing to unpack .../43-libpsl5_0.20.2-2_amd64.deb ...\r\n    ╎   → Unpacking libpsl5:amd64 (0.20.2-2) ...\r\n    ╎   → Selecting previously unselected package librtmp1:amd64.\r\n    ╎   → Preparing to unpack .../44-librtmp1_2.4+20151223.gitfa8646d.1-2_amd64.deb ...\r\n    ╎   → Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\r\n    ╎   → Selecting previously unselected package libssh2-1:amd64.\r\n    ╎   → Preparing to unpack .../45-libssh2-1_1.8.0-2.1_amd64.deb ...\r\n    ╎   → Unpacking libssh2-1:amd64 (1.8.0-2.1) ...\r\n    ╎   → Selecting previously unselected package libcurl3-gnutls:amd64.\r\n    ╎   → Preparing to unpack .../46-libcurl3-gnutls_7.64.0-4_amd64.deb ...\r\n    ╎   → Unpacking libcurl3-gnutls:amd64 (7.64.0-4) ...\r\n    ╎   → Selecting previously unselected package libpcre2-8-0:amd64.\r\n    ╎   → Preparing to unpack .../47-libpcre2-8-0_10.32-5_amd64.deb ...\r\n    ╎   → Unpacking libpcre2-8-0:amd64 (10.32-5) ...\r\n    ╎   → Selecting previously unselected package liberror-perl.\r\n    ╎   → Preparing to unpack .../48-liberror-perl_0.17027-2_all.deb ...\r\n    ╎   → Unpacking liberror-perl (0.17027-2) ...\r\n    ╎   → Selecting previously unselected package git-man.\r\n    ╎   → Preparing to unpack .../49-git-man_1%3a2.20.1-2_all.deb ...\r\n    ╎   → Unpacking git-man (1:2.20.1-2) ...\r\n    ╎   → Selecting previously unselected package git.\r\n    ╎   → Preparing to unpack .../50-git_1%3a2.20.1-2_amd64.deb ...\r\n    ╎   → Unpacking git (1:2.20.1-2) ...\r\n    ╎   → Selecting previously unselected package libbz2-dev:amd64.\r\n    ╎   → Preparing to unpack .../51-libbz2-dev_1.0.6-9.2~deb10u1_amd64.deb ...\r\n    ╎   → Unpacking libbz2-dev:amd64 (1.0.6-9.2~deb10u1) ...\r\n    ╎   → Selecting previously unselected package libgflags2.2.\r\n    ╎   → Preparing to unpack .../52-libgflags2.2_2.2.2-1_amd64.deb ...\r\n    ╎   → Unpacking libgflags2.2 (2.2.2-1) ...\r\n    ╎   → Selecting previously unselected package libgflags-dev.\r\n    ╎   → Preparing to unpack .../53-libgflags-dev_2.2.2-1_amd64.deb ...\r\n    ╎   → Unpacking libgflags-dev (2.2.2-1) ...\r\n    ╎   → Selecting previously unselected package liblz4-dev:amd64.\r\n    ╎   → Preparing to unpack .../54-liblz4-dev_1.8.3-1_amd64.deb ...\r\n    ╎   → Unpacking liblz4-dev:amd64 (1.8.3-1) ...\r\n    ╎   → Selecting previously unselected package libsnappy1v5:amd64.\r\n    ╎   → Preparing to unpack .../55-libsnappy1v5_1.1.7-1_amd64.deb ...\r\n    ╎   → Unpacking libsnappy1v5:amd64 (1.1.7-1) ...\r\n    ╎   → Selecting previously unselected package libsnappy-dev:amd64.\r\n    ╎   → Preparing to unpack .../56-libsnappy-dev_1.1.7-1_amd64.deb ...\r\n    ╎   → Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\r\n    ╎   → Selecting previously unselected package libzstd-dev:amd64.\r\n    ╎   → Preparing to unpack .../57-libzstd-dev_1.3.8+dfsg-3_amd64.deb ...\r\n    ╎   → Unpacking libzstd-dev:amd64 (1.3.8+dfsg-3) ...\r\n    ╎   → Selecting previously unselected package make.\r\n    ╎   → Preparing to unpack .../58-make_4.2.1-1.2_amd64.deb ...\r\n    ╎   → Unpacking make (4.2.1-1.2) ...\r\n    ╎   → Selecting previously unselected package netcat.\r\n    ╎   → Preparing to unpack .../59-netcat_1.10-41.1_all.deb ...\r\n    ╎   → Unpacking netcat (1.10-41.1) ...\r\n    ╎   → Selecting previously unselected package zlib1g-dev:amd64.\r\n    ╎   → Preparing to unpack .../60-zlib1g-dev_1%3a1.2.11.dfsg-1_amd64.deb ...\r\n    ╎   → Unpacking zlib1g-dev:amd64 (1:1.2.11.dfsg-1) ...\r\n    ╎   → Setting up perl-modules-5.28 (5.28.1-6) ...\r\n    ╎   → Setting up libkeyutils1:amd64 (1.6-6) ...\r\n    ╎   → Setting up libpsl5:amd64 (0.20.2-2) ...\r\n    ╎   → Setting up libzstd-dev:amd64 (1.3.8+dfsg-3) ...\r\n    ╎   → Setting up netcat-traditional (1.10-41.1) ...\r\n    ╎   → update-alternatives: using /bin/nc.traditional to provide /bin/nc (nc) in auto mode\r\n    ╎   → update-alternatives: warning: skip creation of /usr/share/man/man1/nc.1.gz because associated file /usr/share/man/man1/nc.traditional.1.gz (of link group nc) doesn't exist\r\n    ╎   → update-alternatives: warning: skip creation of /usr/share/man/man1/netcat.1.gz because associated file /usr/share/man/man1/nc.traditional.1.gz (of link group nc) doesn't exist\r\n    ╎   → Setting up binutils-common:amd64 (2.31.1-16) ...\r\n    ╎   → Setting up libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\r\n    ╎   → Setting up linux-libc-dev:amd64 (4.19.67-2+deb10u1) ...\r\n    ╎   → Setting up netcat (1.10-41.1) ...\r\n    ╎   → Setting up libgomp1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libldap-common (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Setting up libsnappy1v5:amd64 (1.1.7-1) ...\r\n    ╎   → Setting up libkrb5support0:amd64 (1.17-3) ...\r\n    ╎   → Setting up libsasl2-modules-db:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Setting up libasan5:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up make (4.2.1-1.2) ...\r\n    ╎   → Setting up libmpfr6:amd64 (4.0.2-1) ...\r\n    ╎   → Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\r\n    ╎   → Setting up libquadmath0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libmpc3:amd64 (1.1.0-1) ...\r\n    ╎   → Setting up libatomic1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up liblz4-dev:amd64 (1.8.3-1) ...\r\n    ╎   → Setting up libgdbm-compat4:amd64 (1.18.1-4) ...\r\n    ╎   → Setting up libpcre2-8-0:amd64 (10.32-5) ...\r\n    ╎   → Setting up libk5crypto3:amd64 (1.17-3) ...\r\n    ╎   → Setting up libsasl2-2:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Setting up libperl5.28:amd64 (5.28.1-6) ...\r\n    ╎   → Setting up libmpx2:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libubsan1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libisl19:amd64 (0.20-2) ...\r\n    ╎   → Setting up git-man (1:2.20.1-2) ...\r\n    ╎   → Setting up libssh2-1:amd64 (1.8.0-2.1) ...\r\n    ╎   → Setting up libkrb5-3:amd64 (1.17-3) ...\r\n    ╎   → Setting up libbinutils:amd64 (2.31.1-16) ...\r\n    ╎   → Setting up cpp-8 (8.3.0-6) ...\r\n    ╎   → Setting up libc-dev-bin (2.28-10) ...\r\n    ╎   → Setting up libcc1-0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up liblsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libitm1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up binutils-x86-64-linux-gnu (2.31.1-16) ...\r\n    ╎   → Setting up libgflags2.2 (2.2.2-1) ...\r\n    ╎   → Setting up libtsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libsnappy-dev:amd64 (1.1.7-1) ...\r\n    ╎   → Setting up libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Setting up binutils (2.31.1-16) ...\r\n    ╎   → Setting up perl (5.28.1-6) ...\r\n    ╎   → Setting up libgssapi-krb5-2:amd64 (1.17-3) ...\r\n    ╎   → Setting up libgflags-dev (2.2.2-1) ...\r\n    ╎   → Setting up libgcc-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up cpp (4:8.3.0-1) ...\r\n    ╎   → Setting up libc6-dev:amd64 (2.28-10) ...\r\n    ╎   → Setting up libstdc++-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libbz2-dev:amd64 (1.0.6-9.2~deb10u1) ...\r\n    ╎   → Setting up gcc-8 (8.3.0-6) ...\r\n    ╎   → Setting up libcurl3-gnutls:amd64 (7.64.0-4) ...\r\n    ╎   → Setting up gcc (4:8.3.0-1) ...\r\n    ╎   → Setting up liberror-perl (0.17027-2) ...\r\n    ╎   → Setting up git (1:2.20.1-2) ...\r\n    ╎   → Setting up zlib1g-dev:amd64 (1:1.2.11.dfsg-1) ...\r\n    ╎   → Setting up g++-8 (8.3.0-6) ...\r\n    ╎   → Setting up g++ (4:8.3.0-1) ...\r\n    ╎   → update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\r\n    ╎   → Processing triggers for libc-bin (2.28-10) ...\r\n    ╎   → Reading package lists...\n    ╎   → Building dependency tree...\n    ╎   → Reading state information...\n    ╎   → 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n    ╎ [3/14] done | 43.693s\n    ╎ [4/14] WORKDIR /tmp/rocksdb\n    ╎ [5/14] RUN git clone https://github.com/facebook/rocksdb.git /tmp/rocksdb     && make install-shared INSTALL_PATH=/usr     && rm -rf /tmp/rocksdb\n    ╎   → Cloning into '/tmp/rocksdb'...\n    ╎   → $DEBUG_LEVEL is 0\n    ╎   →   GEN      util/build_version.cc\n    ╎   → $DEBUG_LEVEL is 0\n    ╎   →   GEN      util/build_version.cc\n    ╎   → install -d /usr/lib\n    ╎   → for header_dir in `find \"include/rocksdb\" -type d`; do \\\n    ╎   → \tinstall -d /usr/$header_dir; \\\n    ╎   → done\n    ╎   → for header in `find \"include/rocksdb\" -type f -name *.h`; do \\\n    ╎   → \tinstall -C -m 644 $header /usr/$header; \\\n    ╎   → done\n    ╎   →   CC       shared-objects/cache/clock_cache.o\n    ╎   →   CC       shared-objects/cache/lru_cache.o\n    ╎   →   CC       shared-objects/cache/sharded_cache.o\n    ╎   →   CC       shared-objects/db/arena_wrapped_db_iter.o\n    ╎   →   CC       shared-objects/db/builder.o\n    ╎   →   CC       shared-objects/db/c.o\n    ╎   →   CC       shared-objects/db/column_family.o\n    ╎   →   CC       shared-objects/db/compacted_db_impl.o\n    ╎   →   CC       shared-objects/db/compaction/compaction.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_iterator.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_job.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker_fifo.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker_level.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker_universal.o\n    ╎   →   CC       shared-objects/db/convenience.o\n    ╎   →   CC       shared-objects/db/db_filesnapshot.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_compaction_flush.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_debug.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_experimental.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_files.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_open.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_readonly.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_secondary.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_write.o\n    ╎   →   CC       shared-objects/db/db_info_dumper.o\n    ╎   →   CC       shared-objects/db/db_iter.o\n    ╎   →   CC       shared-objects/db/dbformat.o\n    ╎   →   CC       shared-objects/db/error_handler.o\n    ╎   →   CC       shared-objects/db/event_helpers.o\n    ╎   →   CC       shared-objects/db/experimental.o\n    ╎   →   CC       shared-objects/db/external_sst_file_ingestion_job.o\n    ╎   →   CC       shared-objects/db/file_indexer.o\n    ╎   →   CC       shared-objects/db/flush_job.o\n    ╎   →   CC       shared-objects/db/flush_scheduler.o\n    ╎   →   CC       shared-objects/db/forward_iterator.o\n    ╎   →   CC       shared-objects/db/import_column_family_job.o\n    ╎   →   CC       shared-objects/db/internal_stats.o\n    ╎   →   CC       shared-objects/db/logs_with_prep_tracker.o\n    ╎   →   CC       shared-objects/db/log_reader.o\n    ╎   →   CC       shared-objects/db/log_writer.o\n    ╎   →   CC       shared-objects/db/malloc_stats.o\n    ╎   →   CC       shared-objects/db/memtable.o\n    ╎   →   CC       shared-objects/db/memtable_list.o\n    ╎   →   CC       shared-objects/db/merge_helper.o\n    ╎   →   CC       shared-objects/db/merge_operator.o\n    ╎   →   CC       shared-objects/db/range_del_aggregator.o\n    ╎   →   CC       shared-objects/db/range_tombstone_fragmenter.o\n    ╎   →   CC       shared-objects/db/repair.o\n    ╎   →   CC       shared-objects/db/snapshot_impl.o\n    ╎   →   CC       shared-objects/db/table_cache.o\n    ╎   →   CC       shared-objects/db/table_properties_collector.o\n    ╎   →   CC       shared-objects/db/transaction_log_impl.o\n    ╎   →   CC       shared-objects/db/trim_history_scheduler.o\n    ╎   →   CC       shared-objects/db/version_builder.o\n    ╎   →   CC       shared-objects/db/version_edit.o\n    ╎   →   CC       shared-objects/db/version_set.o\n",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 1,
      "PendingBuildEdits": [
        ".Dockerfile.swpx",
        ".Tiltfile.swpx",
        ".docker.swpx"
      ],
      "PendingBuildSince": "2019-10-18T10:50:40.665356-04:00",
      "HasPendingChanges": true,
      "Endpoints": [
        "http://localhost:8088/"
      ],
      "PodID": "",
      "K8sResourceInfo": {
        "PodName": "",
        "PodCreationTime": "0001-01-01T00:00:00Z",
        "PodUpdateStartTime": "0001-01-01T00:00:00Z",
        "PodStatus": "",
        "PodStatusMessage": "",
        "AllContainersReady": true,
        "PodRestarts": 0,
        "PodLog": ""
      },
      "RuntimeStatus": "pending",
      "IsTiltfile": false,
      "ShowBuildStatus": true,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0mrelease-name-faustdemo\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/3 — \u001b[0mBuilding Dockerfile: [docker.io/library/faustdemo]\nBuilding Dockerfile:\n  FROM python:3.7-slim\n  \n  ENV DEBIAN_FRONTEND=noninteractive \\\n      DEBIAN_FRONTEND=teletype\n  \n  RUN echo 'deb [check-valid-until=no] http://archive.debian.org/debian jessie-backports main' >> /etc/apt/sources.list\n  RUN apt-get update \\\n      && apt-get install -y --no-install-recommends apt-utils \\\n      && apt-get install -y --no-install-recommends git gcc make g++ libgflags-dev libsnappy-dev zlib1g-dev libbz2-dev liblz4-dev libzstd-dev netcat\\\n      && apt-get autoremove -y && apt-get clean \\\n      && rm -rf /var/lib/apt/lists/*\n  \n  WORKDIR /tmp/rocksdb\n  \n  RUN git clone https://github.com/facebook/rocksdb.git /tmp/rocksdb \\\n      && make install-shared INSTALL_PATH=/usr \\\n      && rm -rf /tmp/rocksdb\n  \n  ENV STORE_URI=rocksdb://\n  \n  WORKDIR /faustdemo/\n  \n  COPY run.sh /faustdemo/\n  COPY wait_for_services.sh /faustdemo/\n  COPY poetry.lock /faustdemo/\n  COPY poetry.toml /faustdemo/\n  COPY pyproject.toml /faustdemo/\n  COPY Makefile /faustdemo/\n  \n  RUN pip3 install poetry==1.0.0b1 && poetry add python-rocksdb && poetry install\n  \n  COPY faustdemo /faustdemo/faustdemo\n  \n  ENTRYPOINT [\"./run.sh\"]\n\n\n\u001b[34m  │ \u001b[0mTarring context…\n\u001b[34m  │ \u001b[0mBuilding image\n    ╎ copy /context /\n    ╎ copy /context / done | 1.877s\n    ╎ [1/14] FROM docker.io/library/python:3.7-slim@sha256:9ad63b1cfda5f8ff1d4e4003e16b445fe4b5551db6a781e917f1672c65c3c900\n    ╎ [1/14] done | 18.549s\n    ╎ [2/14] RUN echo 'deb [check-valid-until=no] http://archive.debian.org/debian jessie-backports main' >> /etc/apt/sources.list\n    ╎ [2/14] RUN echo 'deb [check-valid-until=no] done | 818ms\n    ╎ [3/14] RUN apt-get update     && apt-get install -y --no-install-recommends apt-utils     && apt-get install -y --no-install-recommends git gcc make g++ libgflags-dev libsnappy-dev zlib1g-dev libbz2-dev liblz4-dev libzstd-dev netcat    && apt-get autoremove -y && apt-get clean     && rm -rf /var/lib/apt/lists/*\n    ╎   → Get:1 http://security.debian.org/debian-security buster/updates InRelease [39.1 kB]\n    ╎   → Get:2 http://deb.debian.org/debian buster InRelease [122 kB]\n    ╎   → Get:3 http://deb.debian.org/debian buster-updates InRelease [49.3 kB]\n    ╎   → Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [99.2 kB]\n    ╎   → Get:5 http://archive.debian.org/debian jessie-backports InRelease [166 kB]\n    ╎   → Get:6 http://deb.debian.org/debian buster/main amd64 Packages [7899 kB]\n    ╎   → Get:7 http://deb.debian.org/debian buster-updates/main amd64 Packages [5792 B]\n    ╎   → Get:8 http://archive.debian.org/debian jessie-backports/main amd64 Packages [911 kB]\n    ╎   → Fetched 9291 kB in 3s (2962 kB/s)\n    ╎   → Reading package lists...\n    ╎   → Reading package lists...\n    ╎   → Building dependency tree...\n    ╎   → Reading state information...\n    ╎   → The following additional packages will be installed:\n    ╎   →   libapt-inst2.0\n    ╎   → The following NEW packages will be installed:\n    ╎   →   apt-utils libapt-inst2.0\n    ╎   → 0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\n    ╎   → Need to get 625 kB of archives.\n    ╎   → After this operation, 1655 kB of additional disk space will be used.\n    ╎   → Get:1 http://deb.debian.org/debian buster/main amd64 libapt-inst2.0 amd64 1.8.2 [204 kB]\n    ╎   → Get:2 http://deb.debian.org/debian buster/main amd64 apt-utils amd64 1.8.2 [421 kB]\n    ╎   → debconf: delaying package configuration, since apt-utils is not installed\n    ╎   → Fetched 625 kB in 0s (6864 kB/s)\n    ╎   → Selecting previously unselected package libapt-inst2.0:amd64.\r\n    ╎   → (Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 6828 files and directories currently installed.)\r\n    ╎   → Preparing to unpack .../libapt-inst2.0_1.8.2_amd64.deb ...\r\n    ╎   → Unpacking libapt-inst2.0:amd64 (1.8.2) ...\r\n    ╎   → Selecting previously unselected package apt-utils.\r\n    ╎   → Preparing to unpack .../apt-utils_1.8.2_amd64.deb ...\r\n    ╎   → Unpacking apt-utils (1.8.2) ...\r\n    ╎   → Setting up libapt-inst2.0:amd64 (1.8.2) ...\r\n    ╎   → Setting up apt-utils (1.8.2) ...\r\n    ╎   → Processing triggers for libc-bin (2.28-10) ...\r\n    ╎   → Reading package lists...\n    ╎   → Building dependency tree...\n    ╎   → Reading state information...\n    ╎   → The following additional packages will be installed:\n    ╎   →   binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-8 g++-8 gcc-8\n    ╎   →   git-man libasan5 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0\n    ╎   →   libcurl3-gnutls liberror-perl libgcc-8-dev libgdbm-compat4 libgflags2.2\n    ╎   →   libgomp1 libgssapi-krb5-2 libisl19 libitm1 libk5crypto3 libkeyutils1\n    ╎   →   libkrb5-3 libkrb5support0 libldap-2.4-2 libldap-common liblsan0 libmpc3\n    ╎   →   libmpfr6 libmpx2 libnghttp2-14 libpcre2-8-0 libperl5.28 libpsl5 libquadmath0\n    ╎   →   librtmp1 libsasl2-2 libsasl2-modules-db libsnappy1v5 libssh2-1\n    ╎   →   libstdc++-8-dev libtsan0 libubsan1 linux-libc-dev netcat-traditional perl\n    ╎   →   perl-modules-5.28\n    ╎   → Suggested packages:\n    ╎   →   binutils-doc cpp-doc gcc-8-locales g++-multilib g++-8-multilib gcc-8-doc\n    ╎   →   libstdc++6-8-dbg gcc-multilib manpages-dev autoconf automake libtool flex\n    ╎   →   bison gdb gcc-doc gcc-8-multilib libgcc1-dbg libgomp1-dbg libitm1-dbg\n    ╎   →   libatomic1-dbg libasan5-dbg liblsan0-dbg libtsan0-dbg libubsan1-dbg\n    ╎   →   libmpx2-dbg libquadmath0-dbg gettext-base git-daemon-run\n    ╎   →   | git-daemon-sysvinit git-doc git-el git-email git-gui gitk gitweb git-cvs\n    ╎   →   git-mediawiki git-svn glibc-doc krb5-doc krb5-user sensible-utils\n    ╎   →   libstdc++-8-doc make-doc perl-doc libterm-readline-gnu-perl\n    ╎   →   | libterm-readline-perl-perl libb-debug-perl liblocale-codes-perl\n    ╎   → Recommended packages:\n    ╎   →   patch less ssh-client bzip2-doc manpages manpages-dev krb5-locales\n    ╎   →   publicsuffix libsasl2-modules\n    ╎   → The following NEW packages will be installed:\n    ╎   →   binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-8 g++ g++-8 gcc\n    ╎   →   gcc-8 git git-man libasan5 libatomic1 libbinutils libbz2-dev libc-dev-bin\n    ╎   →   libc6-dev libcc1-0 libcurl3-gnutls liberror-perl libgcc-8-dev\n    ╎   →   libgdbm-compat4 libgflags-dev libgflags2.2 libgomp1 libgssapi-krb5-2\n    ╎   →   libisl19 libitm1 libk5crypto3 libkeyutils1 libkrb5-3 libkrb5support0\n    ╎   →   libldap-2.4-2 libldap-common liblsan0 liblz4-dev libmpc3 libmpfr6 libmpx2\n    ╎   →   libnghttp2-14 libpcre2-8-0 libperl5.28 libpsl5 libquadmath0 librtmp1\n    ╎   →   libsasl2-2 libsasl2-modules-db libsnappy-dev libsnappy1v5 libssh2-1\n    ╎   →   libstdc++-8-dev libtsan0 libubsan1 libzstd-dev linux-libc-dev make netcat\n    ╎   →   netcat-traditional perl perl-modules-5.28 zlib1g-dev\n    ╎   → 0 upgraded, 61 newly installed, 0 to remove and 0 not upgraded.\n    ╎   → Need to get 60.8 MB of archives.\n    ╎   → After this operation, 269 MB of additional disk space will be used.\n    ╎   → Get:1 http://security.debian.org/debian-security buster/updates/main amd64 linux-libc-dev amd64 4.19.67-2+deb10u1 [1233 kB]\n    ╎   → Get:2 http://deb.debian.org/debian buster/main amd64 perl-modules-5.28 all 5.28.1-6 [2873 kB]\n    ╎   → Get:3 http://security.debian.org/debian-security buster/updates/main amd64 libnghttp2-14 amd64 1.36.0-2+deb10u1 [85.0 kB]\n    ╎   → Get:4 http://deb.debian.org/debian buster/main amd64 libgdbm-compat4 amd64 1.18.1-4 [44.1 kB]\n    ╎   → Get:5 http://deb.debian.org/debian buster/main amd64 libperl5.28 amd64 5.28.1-6 [3883 kB]\n    ╎   → Get:6 http://deb.debian.org/debian buster/main amd64 perl amd64 5.28.1-6 [204 kB]\n    ╎   → Get:7 http://deb.debian.org/debian buster/main amd64 netcat-traditional amd64 1.10-41.1 [66.9 kB]\n    ╎   → Get:8 http://deb.debian.org/debian buster/main amd64 binutils-common amd64 2.31.1-16 [2073 kB]\n    ╎   → Get:9 http://deb.debian.org/debian buster/main amd64 libbinutils amd64 2.31.1-16 [478 kB]\n    ╎   → Get:10 http://deb.debian.org/debian buster/main amd64 binutils-x86-64-linux-gnu amd64 2.31.1-16 [1823 kB]\n    ╎   → Get:11 http://deb.debian.org/debian buster/main amd64 binutils amd64 2.31.1-16 [56.8 kB]\n    ╎   → Get:12 http://deb.debian.org/debian buster/main amd64 libisl19 amd64 0.20-2 [587 kB]\n    ╎   → Get:13 http://deb.debian.org/debian buster/main amd64 libmpfr6 amd64 4.0.2-1 [775 kB]\n    ╎   → Get:14 http://deb.debian.org/debian buster/main amd64 libmpc3 amd64 1.1.0-1 [41.3 kB]\n    ╎   → Get:15 http://deb.debian.org/debian buster/main amd64 cpp-8 amd64 8.3.0-6 [8914 kB]\n    ╎   → Get:16 http://deb.debian.org/debian buster/main amd64 cpp amd64 4:8.3.0-1 [19.4 kB]\n    ╎   → Get:17 http://deb.debian.org/debian buster/main amd64 libcc1-0 amd64 8.3.0-6 [46.6 kB]\n    ╎   → Get:18 http://deb.debian.org/debian buster/main amd64 libgomp1 amd64 8.3.0-6 [75.8 kB]\n    ╎   → Get:19 http://deb.debian.org/debian buster/main amd64 libitm1 amd64 8.3.0-6 [27.7 kB]\n    ╎   → Get:20 http://deb.debian.org/debian buster/main amd64 libatomic1 amd64 8.3.0-6 [9032 B]\n    ╎   → Get:21 http://deb.debian.org/debian buster/main amd64 libasan5 amd64 8.3.0-6 [362 kB]\n    ╎   → Get:22 http://deb.debian.org/debian buster/main amd64 liblsan0 amd64 8.3.0-6 [131 kB]\n    ╎   → Get:23 http://deb.debian.org/debian buster/main amd64 libtsan0 amd64 8.3.0-6 [283 kB]\n    ╎   → Get:24 http://deb.debian.org/debian buster/main amd64 libubsan1 amd64 8.3.0-6 [120 kB]\n    ╎   → Get:25 http://deb.debian.org/debian buster/main amd64 libmpx2 amd64 8.3.0-6 [11.4 kB]\n    ╎   → Get:26 http://deb.debian.org/debian buster/main amd64 libquadmath0 amd64 8.3.0-6 [133 kB]\n    ╎   → Get:27 http://deb.debian.org/debian buster/main amd64 libgcc-8-dev amd64 8.3.0-6 [2298 kB]\n    ╎   → Get:28 http://deb.debian.org/debian buster/main amd64 gcc-8 amd64 8.3.0-6 [9452 kB]\n    ╎   → Get:29 http://deb.debian.org/debian buster/main amd64 gcc amd64 4:8.3.0-1 [5196 B]\n    ╎   → Get:30 http://deb.debian.org/debian buster/main amd64 libc-dev-bin amd64 2.28-10 [275 kB]\n    ╎   → Get:31 http://deb.debian.org/debian buster/main amd64 libc6-dev amd64 2.28-10 [2691 kB]\n    ╎   → Get:32 http://deb.debian.org/debian buster/main amd64 libstdc++-8-dev amd64 8.3.0-6 [1532 kB]\n    ╎   → Get:33 http://deb.debian.org/debian buster/main amd64 g++-8 amd64 8.3.0-6 [9752 kB]\n    ╎   → Get:34 http://deb.debian.org/debian buster/main amd64 g++ amd64 4:8.3.0-1 [1644 B]\n    ╎   → Get:35 http://deb.debian.org/debian buster/main amd64 libkeyutils1 amd64 1.6-6 [15.0 kB]\n    ╎   → Get:36 http://deb.debian.org/debian buster/main amd64 libkrb5support0 amd64 1.17-3 [65.6 kB]\n    ╎   → Get:37 http://deb.debian.org/debian buster/main amd64 libk5crypto3 amd64 1.17-3 [121 kB]\n    ╎   → Get:38 http://deb.debian.org/debian buster/main amd64 libkrb5-3 amd64 1.17-3 [370 kB]\n    ╎   → Get:39 http://deb.debian.org/debian buster/main amd64 libgssapi-krb5-2 amd64 1.17-3 [158 kB]\n    ╎   → Get:40 http://deb.debian.org/debian buster/main amd64 libsasl2-modules-db amd64 2.1.27+dfsg-1 [69.0 kB]\n    ╎   → Get:41 http://deb.debian.org/debian buster/main amd64 libsasl2-2 amd64 2.1.27+dfsg-1 [106 kB]\n    ╎   → Get:42 http://deb.debian.org/debian buster/main amd64 libldap-common all 2.4.47+dfsg-3+deb10u1 [89.6 kB]\n    ╎   → Get:43 http://deb.debian.org/debian buster/main amd64 libldap-2.4-2 amd64 2.4.47+dfsg-3+deb10u1 [225 kB]\n    ╎   → Get:44 http://deb.debian.org/debian buster/main amd64 libpsl5 amd64 0.20.2-2 [53.7 kB]\n    ╎   → Get:45 http://deb.debian.org/debian buster/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2 [60.5 kB]\n    ╎   → Get:46 http://deb.debian.org/debian buster/main amd64 libssh2-1 amd64 1.8.0-2.1 [140 kB]\n    ╎   → Get:47 http://deb.debian.org/debian buster/main amd64 libcurl3-gnutls amd64 7.64.0-4 [329 kB]\n    ╎   → Get:48 http://deb.debian.org/debian buster/main amd64 libpcre2-8-0 amd64 10.32-5 [213 kB]\n    ╎   → Get:49 http://deb.debian.org/debian buster/main amd64 liberror-perl all 0.17027-2 [30.9 kB]\n    ╎   → Get:50 http://deb.debian.org/debian buster/main amd64 git-man all 1:2.20.1-2 [1619 kB]\n    ╎   → Get:51 http://deb.debian.org/debian buster/main amd64 git amd64 1:2.20.1-2 [5621 kB]\n    ╎   → Get:52 http://deb.debian.org/debian buster/main amd64 libbz2-dev amd64 1.0.6-9.2~deb10u1 [30.2 kB]\n    ╎   → Get:53 http://deb.debian.org/debian buster/main amd64 libgflags2.2 amd64 2.2.2-1 [76.7 kB]\n    ╎   → Get:54 http://deb.debian.org/debian buster/main amd64 libgflags-dev amd64 2.2.2-1 [93.6 kB]\n    ╎   → Get:55 http://deb.debian.org/debian buster/main amd64 liblz4-dev amd64 1.8.3-1 [69.0 kB]\n    ╎   → Get:56 http://deb.debian.org/debian buster/main amd64 libsnappy1v5 amd64 1.1.7-1 [17.0 kB]\n    ╎   → Get:57 http://deb.debian.org/debian buster/main amd64 libsnappy-dev amd64 1.1.7-1 [29.2 kB]\n    ╎   → Get:58 http://deb.debian.org/debian buster/main amd64 libzstd-dev amd64 1.3.8+dfsg-3 [284 kB]\n    ╎   → Get:59 http://deb.debian.org/debian buster/main amd64 make amd64 4.2.1-1.2 [341 kB]\n    ╎   → Get:60 http://deb.debian.org/debian buster/main amd64 netcat all 1.10-41.1 [9034 B]\n    ╎   → Get:61 http://deb.debian.org/debian buster/main amd64 zlib1g-dev amd64 1:1.2.11.dfsg-1 [214 kB]\n    ╎   → dpkg-preconfigure: unable to re-open stdin: \n    ╎   → Fetched 60.8 MB in 5s (13.2 MB/s)\n    ╎   → Selecting previously unselected package perl-modules-5.28.\r\n    ╎   → (Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 6958 files and directories currently installed.)\r\n    ╎   → Preparing to unpack .../00-perl-modules-5.28_5.28.1-6_all.deb ...\r\n    ╎   → Unpacking perl-modules-5.28 (5.28.1-6) ...\r\n    ╎   → Selecting previously unselected package libgdbm-compat4:amd64.\r\n    ╎   → Preparing to unpack .../01-libgdbm-compat4_1.18.1-4_amd64.deb ...\r\n    ╎   → Unpacking libgdbm-compat4:amd64 (1.18.1-4) ...\r\n    ╎   → Selecting previously unselected package libperl5.28:amd64.\r\n    ╎   → Preparing to unpack .../02-libperl5.28_5.28.1-6_amd64.deb ...\r\n    ╎   → Unpacking libperl5.28:amd64 (5.28.1-6) ...\r\n    ╎   → Selecting previously unselected package perl.\r\n    ╎   → Preparing to unpack .../03-perl_5.28.1-6_amd64.deb ...\r\n    ╎   → Unpacking perl (5.28.1-6) ...\r\n    ╎   → Selecting previously unselected package netcat-traditional.\r\n    ╎   → Preparing to unpack .../04-netcat-traditional_1.10-41.1_amd64.deb ...\r\n    ╎   → Unpacking netcat-traditional (1.10-41.1) ...\r\n    ╎   → Selecting previously unselected package binutils-common:amd64.\r\n    ╎   → Preparing to unpack .../05-binutils-common_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking binutils-common:amd64 (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package libbinutils:amd64.\r\n    ╎   → Preparing to unpack .../06-libbinutils_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking libbinutils:amd64 (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package binutils-x86-64-linux-gnu.\r\n    ╎   → Preparing to unpack .../07-binutils-x86-64-linux-gnu_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking binutils-x86-64-linux-gnu (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package binutils.\r\n    ╎   → Preparing to unpack .../08-binutils_2.31.1-16_amd64.deb ...\r\n    ╎   → Unpacking binutils (2.31.1-16) ...\r\n    ╎   → Selecting previously unselected package libisl19:amd64.\r\n    ╎   → Preparing to unpack .../09-libisl19_0.20-2_amd64.deb ...\r\n    ╎   → Unpacking libisl19:amd64 (0.20-2) ...\r\n    ╎   → Selecting previously unselected package libmpfr6:amd64.\r\n    ╎   → Preparing to unpack .../10-libmpfr6_4.0.2-1_amd64.deb ...\r\n    ╎   → Unpacking libmpfr6:amd64 (4.0.2-1) ...\r\n    ╎   → Selecting previously unselected package libmpc3:amd64.\r\n    ╎   → Preparing to unpack .../11-libmpc3_1.1.0-1_amd64.deb ...\r\n    ╎   → Unpacking libmpc3:amd64 (1.1.0-1) ...\r\n    ╎   → Selecting previously unselected package cpp-8.\r\n    ╎   → Preparing to unpack .../12-cpp-8_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking cpp-8 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package cpp.\r\n    ╎   → Preparing to unpack .../13-cpp_4%3a8.3.0-1_amd64.deb ...\r\n    ╎   → Unpacking cpp (4:8.3.0-1) ...\r\n    ╎   → Selecting previously unselected package libcc1-0:amd64.\r\n    ╎   → Preparing to unpack .../14-libcc1-0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libcc1-0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libgomp1:amd64.\r\n    ╎   → Preparing to unpack .../15-libgomp1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libgomp1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libitm1:amd64.\r\n    ╎   → Preparing to unpack .../16-libitm1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libitm1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libatomic1:amd64.\r\n    ╎   → Preparing to unpack .../17-libatomic1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libatomic1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libasan5:amd64.\r\n    ╎   → Preparing to unpack .../18-libasan5_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libasan5:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package liblsan0:amd64.\r\n    ╎   → Preparing to unpack .../19-liblsan0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking liblsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libtsan0:amd64.\r\n    ╎   → Preparing to unpack .../20-libtsan0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libtsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libubsan1:amd64.\r\n    ╎   → Preparing to unpack .../21-libubsan1_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libubsan1:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libmpx2:amd64.\r\n    ╎   → Preparing to unpack .../22-libmpx2_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libmpx2:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libquadmath0:amd64.\r\n    ╎   → Preparing to unpack .../23-libquadmath0_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libquadmath0:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package libgcc-8-dev:amd64.\r\n    ╎   → Preparing to unpack .../24-libgcc-8-dev_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libgcc-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package gcc-8.\r\n    ╎   → Preparing to unpack .../25-gcc-8_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking gcc-8 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package gcc.\r\n    ╎   → Preparing to unpack .../26-gcc_4%3a8.3.0-1_amd64.deb ...\r\n    ╎   → Unpacking gcc (4:8.3.0-1) ...\r\n    ╎   → Selecting previously unselected package libc-dev-bin.\r\n    ╎   → Preparing to unpack .../27-libc-dev-bin_2.28-10_amd64.deb ...\r\n    ╎   → Unpacking libc-dev-bin (2.28-10) ...\r\n    ╎   → Selecting previously unselected package linux-libc-dev:amd64.\r\n    ╎   → Preparing to unpack .../28-linux-libc-dev_4.19.67-2+deb10u1_amd64.deb ...\r\n    ╎   → Unpacking linux-libc-dev:amd64 (4.19.67-2+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libc6-dev:amd64.\r\n    ╎   → Preparing to unpack .../29-libc6-dev_2.28-10_amd64.deb ...\r\n    ╎   → Unpacking libc6-dev:amd64 (2.28-10) ...\r\n    ╎   → Selecting previously unselected package libstdc++-8-dev:amd64.\r\n    ╎   → Preparing to unpack .../30-libstdc++-8-dev_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking libstdc++-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package g++-8.\r\n    ╎   → Preparing to unpack .../31-g++-8_8.3.0-6_amd64.deb ...\r\n    ╎   → Unpacking g++-8 (8.3.0-6) ...\r\n    ╎   → Selecting previously unselected package g++.\r\n    ╎   → Preparing to unpack .../32-g++_4%3a8.3.0-1_amd64.deb ...\r\n    ╎   → Unpacking g++ (4:8.3.0-1) ...\r\n    ╎   → Selecting previously unselected package libkeyutils1:amd64.\r\n    ╎   → Preparing to unpack .../33-libkeyutils1_1.6-6_amd64.deb ...\r\n    ╎   → Unpacking libkeyutils1:amd64 (1.6-6) ...\r\n    ╎   → Selecting previously unselected package libkrb5support0:amd64.\r\n    ╎   → Preparing to unpack .../34-libkrb5support0_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libkrb5support0:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libk5crypto3:amd64.\r\n    ╎   → Preparing to unpack .../35-libk5crypto3_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libk5crypto3:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libkrb5-3:amd64.\r\n    ╎   → Preparing to unpack .../36-libkrb5-3_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libkrb5-3:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libgssapi-krb5-2:amd64.\r\n    ╎   → Preparing to unpack .../37-libgssapi-krb5-2_1.17-3_amd64.deb ...\r\n    ╎   → Unpacking libgssapi-krb5-2:amd64 (1.17-3) ...\r\n    ╎   → Selecting previously unselected package libsasl2-modules-db:amd64.\r\n    ╎   → Preparing to unpack .../38-libsasl2-modules-db_2.1.27+dfsg-1_amd64.deb ...\r\n    ╎   → Unpacking libsasl2-modules-db:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Selecting previously unselected package libsasl2-2:amd64.\r\n    ╎   → Preparing to unpack .../39-libsasl2-2_2.1.27+dfsg-1_amd64.deb ...\r\n    ╎   → Unpacking libsasl2-2:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Selecting previously unselected package libldap-common.\r\n    ╎   → Preparing to unpack .../40-libldap-common_2.4.47+dfsg-3+deb10u1_all.deb ...\r\n    ╎   → Unpacking libldap-common (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libldap-2.4-2:amd64.\r\n    ╎   → Preparing to unpack .../41-libldap-2.4-2_2.4.47+dfsg-3+deb10u1_amd64.deb ...\r\n    ╎   → Unpacking libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libnghttp2-14:amd64.\r\n    ╎   → Preparing to unpack .../42-libnghttp2-14_1.36.0-2+deb10u1_amd64.deb ...\r\n    ╎   → Unpacking libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\r\n    ╎   → Selecting previously unselected package libpsl5:amd64.\r\n    ╎   → Preparing to unpack .../43-libpsl5_0.20.2-2_amd64.deb ...\r\n    ╎   → Unpacking libpsl5:amd64 (0.20.2-2) ...\r\n    ╎   → Selecting previously unselected package librtmp1:amd64.\r\n    ╎   → Preparing to unpack .../44-librtmp1_2.4+20151223.gitfa8646d.1-2_amd64.deb ...\r\n    ╎   → Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\r\n    ╎   → Selecting previously unselected package libssh2-1:amd64.\r\n    ╎   → Preparing to unpack .../45-libssh2-1_1.8.0-2.1_amd64.deb ...\r\n    ╎   → Unpacking libssh2-1:amd64 (1.8.0-2.1) ...\r\n    ╎   → Selecting previously unselected package libcurl3-gnutls:amd64.\r\n    ╎   → Preparing to unpack .../46-libcurl3-gnutls_7.64.0-4_amd64.deb ...\r\n    ╎   → Unpacking libcurl3-gnutls:amd64 (7.64.0-4) ...\r\n    ╎   → Selecting previously unselected package libpcre2-8-0:amd64.\r\n    ╎   → Preparing to unpack .../47-libpcre2-8-0_10.32-5_amd64.deb ...\r\n    ╎   → Unpacking libpcre2-8-0:amd64 (10.32-5) ...\r\n    ╎   → Selecting previously unselected package liberror-perl.\r\n    ╎   → Preparing to unpack .../48-liberror-perl_0.17027-2_all.deb ...\r\n    ╎   → Unpacking liberror-perl (0.17027-2) ...\r\n    ╎   → Selecting previously unselected package git-man.\r\n    ╎   → Preparing to unpack .../49-git-man_1%3a2.20.1-2_all.deb ...\r\n    ╎   → Unpacking git-man (1:2.20.1-2) ...\r\n    ╎   → Selecting previously unselected package git.\r\n    ╎   → Preparing to unpack .../50-git_1%3a2.20.1-2_amd64.deb ...\r\n    ╎   → Unpacking git (1:2.20.1-2) ...\r\n    ╎   → Selecting previously unselected package libbz2-dev:amd64.\r\n    ╎   → Preparing to unpack .../51-libbz2-dev_1.0.6-9.2~deb10u1_amd64.deb ...\r\n    ╎   → Unpacking libbz2-dev:amd64 (1.0.6-9.2~deb10u1) ...\r\n    ╎   → Selecting previously unselected package libgflags2.2.\r\n    ╎   → Preparing to unpack .../52-libgflags2.2_2.2.2-1_amd64.deb ...\r\n    ╎   → Unpacking libgflags2.2 (2.2.2-1) ...\r\n    ╎   → Selecting previously unselected package libgflags-dev.\r\n    ╎   → Preparing to unpack .../53-libgflags-dev_2.2.2-1_amd64.deb ...\r\n    ╎   → Unpacking libgflags-dev (2.2.2-1) ...\r\n    ╎   → Selecting previously unselected package liblz4-dev:amd64.\r\n    ╎   → Preparing to unpack .../54-liblz4-dev_1.8.3-1_amd64.deb ...\r\n    ╎   → Unpacking liblz4-dev:amd64 (1.8.3-1) ...\r\n    ╎   → Selecting previously unselected package libsnappy1v5:amd64.\r\n    ╎   → Preparing to unpack .../55-libsnappy1v5_1.1.7-1_amd64.deb ...\r\n    ╎   → Unpacking libsnappy1v5:amd64 (1.1.7-1) ...\r\n    ╎   → Selecting previously unselected package libsnappy-dev:amd64.\r\n    ╎   → Preparing to unpack .../56-libsnappy-dev_1.1.7-1_amd64.deb ...\r\n    ╎   → Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\r\n    ╎   → Selecting previously unselected package libzstd-dev:amd64.\r\n    ╎   → Preparing to unpack .../57-libzstd-dev_1.3.8+dfsg-3_amd64.deb ...\r\n    ╎   → Unpacking libzstd-dev:amd64 (1.3.8+dfsg-3) ...\r\n    ╎   → Selecting previously unselected package make.\r\n    ╎   → Preparing to unpack .../58-make_4.2.1-1.2_amd64.deb ...\r\n    ╎   → Unpacking make (4.2.1-1.2) ...\r\n    ╎   → Selecting previously unselected package netcat.\r\n    ╎   → Preparing to unpack .../59-netcat_1.10-41.1_all.deb ...\r\n    ╎   → Unpacking netcat (1.10-41.1) ...\r\n    ╎   → Selecting previously unselected package zlib1g-dev:amd64.\r\n    ╎   → Preparing to unpack .../60-zlib1g-dev_1%3a1.2.11.dfsg-1_amd64.deb ...\r\n    ╎   → Unpacking zlib1g-dev:amd64 (1:1.2.11.dfsg-1) ...\r\n    ╎   → Setting up perl-modules-5.28 (5.28.1-6) ...\r\n    ╎   → Setting up libkeyutils1:amd64 (1.6-6) ...\r\n    ╎   → Setting up libpsl5:amd64 (0.20.2-2) ...\r\n    ╎   → Setting up libzstd-dev:amd64 (1.3.8+dfsg-3) ...\r\n    ╎   → Setting up netcat-traditional (1.10-41.1) ...\r\n    ╎   → update-alternatives: using /bin/nc.traditional to provide /bin/nc (nc) in auto mode\r\n    ╎   → update-alternatives: warning: skip creation of /usr/share/man/man1/nc.1.gz because associated file /usr/share/man/man1/nc.traditional.1.gz (of link group nc) doesn't exist\r\n    ╎   → update-alternatives: warning: skip creation of /usr/share/man/man1/netcat.1.gz because associated file /usr/share/man/man1/nc.traditional.1.gz (of link group nc) doesn't exist\r\n    ╎   → Setting up binutils-common:amd64 (2.31.1-16) ...\r\n    ╎   → Setting up libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\r\n    ╎   → Setting up linux-libc-dev:amd64 (4.19.67-2+deb10u1) ...\r\n    ╎   → Setting up netcat (1.10-41.1) ...\r\n    ╎   → Setting up libgomp1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libldap-common (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Setting up libsnappy1v5:amd64 (1.1.7-1) ...\r\n    ╎   → Setting up libkrb5support0:amd64 (1.17-3) ...\r\n    ╎   → Setting up libsasl2-modules-db:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Setting up libasan5:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up make (4.2.1-1.2) ...\r\n    ╎   → Setting up libmpfr6:amd64 (4.0.2-1) ...\r\n    ╎   → Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\r\n    ╎   → Setting up libquadmath0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libmpc3:amd64 (1.1.0-1) ...\r\n    ╎   → Setting up libatomic1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up liblz4-dev:amd64 (1.8.3-1) ...\r\n    ╎   → Setting up libgdbm-compat4:amd64 (1.18.1-4) ...\r\n    ╎   → Setting up libpcre2-8-0:amd64 (10.32-5) ...\r\n    ╎   → Setting up libk5crypto3:amd64 (1.17-3) ...\r\n    ╎   → Setting up libsasl2-2:amd64 (2.1.27+dfsg-1) ...\r\n    ╎   → Setting up libperl5.28:amd64 (5.28.1-6) ...\r\n    ╎   → Setting up libmpx2:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libubsan1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libisl19:amd64 (0.20-2) ...\r\n    ╎   → Setting up git-man (1:2.20.1-2) ...\r\n    ╎   → Setting up libssh2-1:amd64 (1.8.0-2.1) ...\r\n    ╎   → Setting up libkrb5-3:amd64 (1.17-3) ...\r\n    ╎   → Setting up libbinutils:amd64 (2.31.1-16) ...\r\n    ╎   → Setting up cpp-8 (8.3.0-6) ...\r\n    ╎   → Setting up libc-dev-bin (2.28-10) ...\r\n    ╎   → Setting up libcc1-0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up liblsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libitm1:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up binutils-x86-64-linux-gnu (2.31.1-16) ...\r\n    ╎   → Setting up libgflags2.2 (2.2.2-1) ...\r\n    ╎   → Setting up libtsan0:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libsnappy-dev:amd64 (1.1.7-1) ...\r\n    ╎   → Setting up libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u1) ...\r\n    ╎   → Setting up binutils (2.31.1-16) ...\r\n    ╎   → Setting up perl (5.28.1-6) ...\r\n    ╎   → Setting up libgssapi-krb5-2:amd64 (1.17-3) ...\r\n    ╎   → Setting up libgflags-dev (2.2.2-1) ...\r\n    ╎   → Setting up libgcc-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up cpp (4:8.3.0-1) ...\r\n    ╎   → Setting up libc6-dev:amd64 (2.28-10) ...\r\n    ╎   → Setting up libstdc++-8-dev:amd64 (8.3.0-6) ...\r\n    ╎   → Setting up libbz2-dev:amd64 (1.0.6-9.2~deb10u1) ...\r\n    ╎   → Setting up gcc-8 (8.3.0-6) ...\r\n    ╎   → Setting up libcurl3-gnutls:amd64 (7.64.0-4) ...\r\n    ╎   → Setting up gcc (4:8.3.0-1) ...\r\n    ╎   → Setting up liberror-perl (0.17027-2) ...\r\n    ╎   → Setting up git (1:2.20.1-2) ...\r\n    ╎   → Setting up zlib1g-dev:amd64 (1:1.2.11.dfsg-1) ...\r\n    ╎   → Setting up g++-8 (8.3.0-6) ...\r\n    ╎   → Setting up g++ (4:8.3.0-1) ...\r\n    ╎   → update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\r\n    ╎   → Processing triggers for libc-bin (2.28-10) ...\r\n    ╎   → Reading package lists...\n    ╎   → Building dependency tree...\n    ╎   → Reading state information...\n    ╎   → 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n    ╎ [3/14] done | 43.693s\n    ╎ [4/14] WORKDIR /tmp/rocksdb\n    ╎ [5/14] RUN git clone https://github.com/facebook/rocksdb.git /tmp/rocksdb     && make install-shared INSTALL_PATH=/usr     && rm -rf /tmp/rocksdb\n    ╎   → Cloning into '/tmp/rocksdb'...\n    ╎   → $DEBUG_LEVEL is 0\n    ╎   →   GEN      util/build_version.cc\n    ╎   → $DEBUG_LEVEL is 0\n    ╎   →   GEN      util/build_version.cc\n    ╎   → install -d /usr/lib\n    ╎   → for header_dir in `find \"include/rocksdb\" -type d`; do \\\n    ╎   → \tinstall -d /usr/$header_dir; \\\n    ╎   → done\n    ╎   → for header in `find \"include/rocksdb\" -type f -name *.h`; do \\\n    ╎   → \tinstall -C -m 644 $header /usr/$header; \\\n    ╎   → done\n    ╎   →   CC       shared-objects/cache/clock_cache.o\n    ╎   →   CC       shared-objects/cache/lru_cache.o\n    ╎   →   CC       shared-objects/cache/sharded_cache.o\n    ╎   →   CC       shared-objects/db/arena_wrapped_db_iter.o\n    ╎   →   CC       shared-objects/db/builder.o\n    ╎   →   CC       shared-objects/db/c.o\n    ╎   →   CC       shared-objects/db/column_family.o\n    ╎   →   CC       shared-objects/db/compacted_db_impl.o\n    ╎   →   CC       shared-objects/db/compaction/compaction.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_iterator.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_job.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker_fifo.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker_level.o\n    ╎   →   CC       shared-objects/db/compaction/compaction_picker_universal.o\n    ╎   →   CC       shared-objects/db/convenience.o\n    ╎   →   CC       shared-objects/db/db_filesnapshot.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_compaction_flush.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_debug.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_experimental.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_files.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_open.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_readonly.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_secondary.o\n    ╎   →   CC       shared-objects/db/db_impl/db_impl_write.o\n    ╎   →   CC       shared-objects/db/db_info_dumper.o\n    ╎   →   CC       shared-objects/db/db_iter.o\n    ╎   →   CC       shared-objects/db/dbformat.o\n    ╎   →   CC       shared-objects/db/error_handler.o\n    ╎   →   CC       shared-objects/db/event_helpers.o\n    ╎   →   CC       shared-objects/db/experimental.o\n    ╎   →   CC       shared-objects/db/external_sst_file_ingestion_job.o\n    ╎   →   CC       shared-objects/db/file_indexer.o\n    ╎   →   CC       shared-objects/db/flush_job.o\n    ╎   →   CC       shared-objects/db/flush_scheduler.o\n    ╎   →   CC       shared-objects/db/forward_iterator.o\n    ╎   →   CC       shared-objects/db/import_column_family_job.o\n    ╎   →   CC       shared-objects/db/internal_stats.o\n    ╎   →   CC       shared-objects/db/logs_with_prep_tracker.o\n    ╎   →   CC       shared-objects/db/log_reader.o\n    ╎   →   CC       shared-objects/db/log_writer.o\n    ╎   →   CC       shared-objects/db/malloc_stats.o\n    ╎   →   CC       shared-objects/db/memtable.o\n    ╎   →   CC       shared-objects/db/memtable_list.o\n    ╎   →   CC       shared-objects/db/merge_helper.o\n    ╎   →   CC       shared-objects/db/merge_operator.o\n    ╎   →   CC       shared-objects/db/range_del_aggregator.o\n    ╎   →   CC       shared-objects/db/range_tombstone_fragmenter.o\n    ╎   →   CC       shared-objects/db/repair.o\n    ╎   →   CC       shared-objects/db/snapshot_impl.o\n    ╎   →   CC       shared-objects/db/table_cache.o\n    ╎   →   CC       shared-objects/db/table_properties_collector.o\n    ╎   →   CC       shared-objects/db/transaction_log_impl.o\n    ╎   →   CC       shared-objects/db/trim_history_scheduler.o\n    ╎   →   CC       shared-objects/db/version_builder.o\n    ╎   →   CC       shared-objects/db/version_edit.o\n    ╎   →   CC       shared-objects/db/version_set.o\n",
      "CrashLog": ""
    },
    {
      "Name": "uncategorized",
      "DirectoriesWatched": [],
      "PathsWatched": [
        "Tiltfile"
      ],
      "LastDeployTime": "2019-10-18T10:29:26.262584-04:00",
      "TriggerMode": 0,
      "BuildHistory": [
        {
          "Edits": null,
          "Error": null,
          "Warnings": null,
          "StartTime": "2019-10-18T10:29:25.249367-04:00",
          "FinishTime": "2019-10-18T10:29:26.26257-04:00",
          "Log": "\n\u001b[34m──┤ Building: \u001b[0muncategorized\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   testspace:namespace\n\u001b[34m  │ \u001b[0m   quota:resourcequota:default::1\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper-pdb:poddisruptionbudget\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-connect-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-rest-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server-ksql-queries-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-schema-registry-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   quota:resourcequota:default::10\n\n\u001b[34m  │ \u001b[0mStep 1 - 1.012s\n\u001b[34m  │ \u001b[0mDone in: 1.012s \n\n",
          "IsCrashRebuild": false
        }
      ],
      "CurrentBuild": {
        "Edits": null,
        "Error": null,
        "Warnings": null,
        "StartTime": "0001-01-01T00:00:00Z",
        "FinishTime": "0001-01-01T00:00:00Z",
        "Log": "",
        "IsCrashRebuild": false
      },
      "PendingBuildReason": 0,
      "PendingBuildEdits": null,
      "PendingBuildSince": "0001-01-01T00:00:00Z",
      "HasPendingChanges": false,
      "Endpoints": null,
      "PodID": "",
      "YAMLResourceInfo": {
        "K8sResources": [
          "testspace:namespace",
          "quota:resourcequota:default::1",
          "confluent-cp-zookeeper-pdb:poddisruptionbudget",
          "confluent-cp-kafka-connect-jmx-configmap:configmap",
          "confluent-cp-kafka-rest-jmx-configmap:configmap",
          "confluent-cp-kafka-jmx-configmap:configmap",
          "confluent-cp-ksql-server-jmx-configmap:configmap",
          "confluent-cp-ksql-server-ksql-queries-configmap:configmap",
          "confluent-cp-schema-registry-jmx-configmap:configmap",
          "confluent-cp-zookeeper-jmx-configmap:configmap",
          "quota:resourcequota:default::10"
        ]
      },
      "RuntimeStatus": "ok",
      "IsTiltfile": false,
      "ShowBuildStatus": false,
      "CombinedLog": "\n\u001b[34m──┤ Building: \u001b[0muncategorized\u001b[34m ├──────────────────────────────────────────────\u001b[0m\n\u001b[34mSTEP 1/1 — \u001b[0mDeploying\n\u001b[34m  │ \u001b[0mInjecting images into Kubernetes YAML\n\u001b[34m  │ \u001b[0mApplying via kubectl:\n\u001b[34m  │ \u001b[0m   testspace:namespace\n\u001b[34m  │ \u001b[0m   quota:resourcequota:default::1\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper-pdb:poddisruptionbudget\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-connect-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-rest-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-kafka-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-ksql-server-ksql-queries-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-schema-registry-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   confluent-cp-zookeeper-jmx-configmap:configmap\n\u001b[34m  │ \u001b[0m   quota:resourcequota:default::10\n\n\u001b[34m  │ \u001b[0mStep 1 - 1.012s\n\u001b[34m  │ \u001b[0mDone in: 1.012s \n\n",
      "CrashLog": ""
    }
  ],
  "LogTimestamps": false,
  "FeatureFlags": {
    "events": true,
    "multiple_containers_per_pod": true,
    "snapshot_highlights": false,
    "snapshots": true,
    "update_history": false
  },
  "NeedsAnalyticsNudge": false,
  "RunningTiltBuild": {
    "Version": "0.10.13",
    "CommitSHA": "195d4433da039237eaea897c490009227465dc96",
    "Date": "2019-10-17",
    "Dev": true
  },
  "LatestTiltBuild": {
    "Version": "",
    "CommitSHA": "",
    "Date": "",
    "Dev": false
  },
  "TiltCloudUsername": "landism",
  "TiltCloudSchemeHost": "https://cloud.tilt.dev",
  "TiltCloudTeamID": "",
  "FatalError": ""
}
